Learning to identify cracks on wind turbine blade
surfaces using drone-based inspection images
Akshay Iyer
SkySpecs Inc.
akshay.iyer@skyspecs.comLinh Nguyen
SkySpecs Inc.
linh.nguyen@skyspecs.comShweta Khushu
SkySpecs Inc.
shweta.khushu@skyspecs.com
Abstract
Wind energy is expected to be one of the leading ways to achieve the goals of
the Paris Agreement but it in turn heavily depends on effective management of its
operations and maintenance (O&M) costs. Blade failures account for one-third
of all O&M costs thus making accurate detection of blade damages, especially
cracks, very important for sustained operations and cost savings. Traditionally,
damage inspection has been a completely manual process thus making it subjective,
error-prone, and time-consuming. Hence in this work, we bring more objectivity,
scalability, and repeatability in our damage inspection process, using deep learning,
to miss fewer cracks. We build a deep learning model trained on a large dataset of
blade damages, collected by our drone-based inspection, to correctly detect cracks.
Our model is already in production and has processed more than a million damages
with a recall of 0.96. We also focus on model interpretability using class activation
maps to get a peek into the model workings. The model not only performs as good
as human experts but also better in certain tricky cases. Thus, in this work, we
aim to increase wind energy adoption by decreasing one of its major hurdles - the
O&M costs resulting from missing blade failures like cracks.
1 Introduction
While the year 2020 saw one of the most stunning declines in global CO 2emissions due to the
pandemic [ 11], the economic recovery post-pandemic is set to reverse 80% of that drop and global
energy demand is set to increase by 4.6% in 2021 [ 12]. However, renewables remain the hope
with projections of 30% contributions to electricity generation - the highest ever since the industrial
revolution [ 12]. Wind alone is expected to be the prominent energy source by 2050 but for that to
happen requires signiﬁcant technological advancements to reduce the costs of wind power [ 13]. O&M
costs account for 20-24% of the total Levelized Cost of Energy (LCOE) of current wind systems
[8,25] with blade failures being the major contributor to the costs as the turbines operate in harsh
environmental conditions and are made up of complex, expensive materials [ 7,16]. Damages on wind
turbine blades, especially cracks on the surface, could indicate severe internal structural damages [ 6]
and if left to grow can cause serious damages [ 2] to the blades. Additionally, missing cracks result in
repair expenses ranging in multiple hundreds of thousands of dollars, making it highly important to
catch these damages at the earliest to better operate the turbines and avoid heavy losses. [15, 1]
There are a variety of sub-types in cracks like longitudinal, transverse, diagonal, buckling, etc., and
can have very different visual appearances. At the same time, there are damage types other than
cracks like chips, ﬂaking, scratches, etc. which can at times look very similar to cracks but are not as
severe as cracks. Thus, the problem becomes not only to correctly identify all the different sub-types
of cracks but also to not confuse the other similar-looking damages to be cracks. Figure 1 shows how
some other types of damages can look very similar to cracks and thus requires one to carefully discern
the differences. Typically, this process is carried out manually making it very labor-heavy, subjective,
35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia.and error-prone. This is where deep learning can improve upon human analysts and classical image
processing methods. Since, with large enough data, deep learning models can identify discriminative,
visual/non-visual features to distinguish cracks from the other very similar-looking damages and
iteratively optimize that. In this work, we focus on creating an accurate, fast, and reliable deep
learning-based method to identify cracks on wind turbine blades. Our goal is to include deep learning
as a part of our Quality Check (QC) process to miss fewer cracks. In recent times, drone-based
inspections of turbines have shown great promise as they avoid signiﬁcant turbine downtimes and
reduce the human risk in inspection[ 9,22]. We perform drone-based inspections for wind farms
capturing images in a variety of orientations, lighting, and weather conditions. From this, we carefully
curate a dataset of 71k images and train a ResNet-50 on it, with speciﬁc training strategies. We then
test the model on real-world data and take it to production. Our model is added as a layer in our QC
process and the disagreements between the model and the human analyst are reviewed as a ﬁnal step.
Related Work : There are some experimental works done in this domain like [ 2,26,27] use classical
methods to detect certain cracks but can’t distinguish them from similar-looking damages and are
sensitive to noise and uneven illumination. Deep learning has garnered a lot of attention recently for
tasks related to surface damages like on concrete [ 4], steel [ 17], wood [ 14], etc. But very limited work
is done when it comes to this particular problem. Works like [ 20,21] use a CNN to classify if a blade
image contains any kind of damage. However, they suffer from having just a few hundred images and
resulting in false-positive-rates as high as 90% [ 20]. [23] considers a few categories but not cracks
and achieves an mAP of 81%. So most of these works either treat all damages the same or don’t
include cracks which have one of the most severe failure impacts. Thus, these works target related
but slightly different aspects of the problem and also lack the data and surrounding infrastructure to
get translated from an experimental stage to realize a real-world climate change impact.
Our contributions : Our work is the ﬁrst commercial product to create a crack-damage classiﬁer
trained on such a large amount of real-world data. Our model reports very high precision and recall
on live production data and correctly identiﬁes even very tricky cracks where trained analysts fail.
We have laid special emphasis on the interpretability of results using Grad-CAM++ [ 5] to increase
trust in the predictions. The model runs very fast even on a CPU and unlike other works which are
still in experimental stages, this one is already deployed to production bringing real-world value. Our
model brings in repeatability, accuracy, and objectivity in our QC process. This would help human
analysts make more informed decisions, miss fewer cracks, and result in better management of the
turbines and their O&M costs.
Figure 1: Blade damages - crack, chip, scratch, ﬂaking. One can see how certain types of damages
can be very faint and can sometimes look very similar to a crack
2 Materials and Methods
2.1 Data
Our drones perform turbine inspections across the globe, capturing images of turbine blades in
a variety of weather conditions thereby resulting in an information-rich dataset. So far we have
performed around 90k inspections across 26 countries. The data then goes through a rigorous, manual
QC process. In the initial round of QC, analysts identify damage locations, types, sub-types, and
categorize them into ﬁve levels of severity based on factors like type, size, location, etc. of the
damage. These annotations then go through a couple of QC rounds of review. We bring in our model
at this stage as an auditor , to give out its predictions on the images before they go to the last QC
2round where the experts would take the ﬁnal call on the damages, especially cracks and high severity
damages. Thus, our model becomes another round of QC to ensure that we miss fewer cracks.
For this work, we curate a dataset of 71k images of cropped damages that have gone through our
complete QC pipeline. We speciﬁcally focus on categories most often confused with cracks and vice
versa by analysts, i.e. chips, ﬂaking, scratch. The target labels were [ ’Crack’, ’Not a crack’ ]. We
ensure to have a wide representation of the important sub-types of cracks. We perform a train-val split
resulting in around 64k training images and 7k validation images. We perform data augmentation -
both geometric and lighting-oriented to bring invariance to rotation and unfavorable lighting.
2.2 Experiments
Network : A ResNet50[ 10] was initialized with ImageNet weights for the task and the last layer
was replaced with a custom head consisting of fully connected layers, ReLU, and dropout for a
binary prediction. An Adam optimizer was used with the learning rate found by using Leslie Smith’s
learning rate range test [ 24] and a hyperparameter grid search. The network was implemented in
PyTorch [19] and trained on a g4dn.xlarge GPU EC2 instance.
Training Strategies : A weighted BCEWithLogits loss was used to compensate for the class imbalance
between cracks and no-cracks. An initial round of training from scratch was performed with the
conﬁguration. But since there are higher severity damages present in the data as well, which are
more important to detect, we perform a second round of training to ﬁnetune the model to pay special
attention to higher severity images. The higher severity damages (4 and 5) were present in a lesser
proportion in the dataset (around 16%). For this, we created a dataloader with custom stratiﬁed
sampling to sample higher severity images much more such that they were not under-represented
in batches. To take a peek into the workings of the network, Grad-CAM++ was used to generate a
heatmap showing which parts of the input image were most responsible for the network prediction.
The visualization and the interpretation can be seen in Fig. 2a. While it is deﬁnitely most important to
minimize Type II errors, it is also important not to have a large number of Type I errors else that shall
result in a large number of unnecessary reviews in the QC process. Thus, it was most natural to use
precision andrecall as our machine learning metrics, and also since increasing these metrics imply
fewer damages go undetected and propagate, thus directly corresponding with reduced O&M costs.
2.3 Evaluation
Feedback loop with business : To translate the ML performance to business value, there were several
review rounds with the QC team. Here, the model was tested on images from production data
i.e. real-world inspections. Then the class labels post the ﬁnal round of QC were compared with
the model predictions. This helped identify places where the model labeled incorrectly as well as
cases when the model caught cracks that even the analyst missed. These catches along with the
Grad-CAM++ visualization of the model helped the business trust the model.
Deployment Pipeline : Once the model reached the desired performance, model deployment began.
For the same, the model was ﬁrst optimized using the jit torchscript compiler. The model is served
using torchserve and hosted on a Sagemaker endpoint. The entire pipeline is built using AWS to
ensure scalability and high availability. The model prediction is visible in the Analyst app used in the
QC process for each image (see Fig. 3)
Table 1: Model performance on the test set and effect of including severity sampling. We observe the
model has both high recall and precision. Also, severity sampling helps improve the performance
Data Recall Precision F1-Score
Complete test data 0:96 0 :85 0 :90
Only high severity images (before severity sampling) 0:92 0 :98 0 :95
Only high severity images (after severity sampling) 0:96 0 :98 0 :97
3 Results and Discussion
Table 1 shows how the model performs in production on around 46k images. It can be seen that on
the complete test data, the model has a very high recall of 0.96 correctly identifying 23.2k cracks
3(a) Grad-CAM++ visualization
 (b) Propagation of cracks over time
Figure 2: Results. Fig.2a shows Grad-CAM++ visualization for the model. The model mostly looks
correctly at the damage (HITs) while making the predictions. Fig. 2b shows how a very faint crack
grew in size (shown with arrows) over four years. However, the model caught the crack in each case.
Figure 3: Model prediction on every damage visible to analysts to use in the QC process
out of 24.2k cracks. The model results in not just very high recall but also high precision, thus not
only helping analysts miss fewer cracks but also not adding to their burden of inspecting many false
positives. Not only that, the model even caught several tricky cracks that even trained analysts had
missed. So the model is not just performing similar to a human analyst, it has also started to perform
better in some cases. Table 1 also shows the effects of the custom sampling on the model performance
on higher severity samples from a test set. Clearly, including stratiﬁed sampling for severity images
helped the performance, the recall jumped four points while maintaining near-perfect precision. Tests
revealed that this change was statistically signiﬁcant with a p-value of 4e-7. Additionally, Fig. 2b,
shows a faint crack in 2018 which grew in size in successive years. On running the model, we found
that the model caught it in all four years including the very ﬁrst year while it still was a small and faint
damage. Thus, the model catching such damages in very early stages will save hundreds of thousands
of dollars spent on repairing larger cracks down the line. With more production data coming in and
our pipeline in place to iteratively improve the model based on its failures, the performance can
only increase. Also, to increase the trust in the model predictions, we used GradCAM++ for results
interpretation. Fig. 2a shows a heatmap overlaid on the image, with redindicating regions where
model focuses most and blue indicating least. We observed that the model, without being explicitly
taught, still focuses correctly on the damage to make the decision. This was used to increase trust in
the predictions as well as debug model failures. Apart from accuracy, the model is also optimized for
deployment, thereby yielding very fast inference times of 0.15 secs on a CPU (c4 instance). This
enables us to have cheap and high availability. The model performs inspections on several thousand
images within a few minutes which takes human analysts several hours. Fig.3 shows how the model
prediction is shown to the analysts for each image and gets updated in real-time.
Thus, in this work, we create one of the ﬁrst at-scale, in-production crack-damage classiﬁers to help
reduce the O&M costs of wind turbines and thereby increase wind energy adoption. The model,
with its high scores and interpretability, brings in accuracy and reliability. It improves the damage
inspection process thereby resulting in fewer missed cracks and potentially preventing signiﬁcant
expenses down the line. However, there is still scope to increase accuracy which we plan to do by
monitoring the model in production and using tools like Grad-CAM++ and curriculum learning [ 3] to
investigate and improve the model. Also, the current focus is only on cracks but we are in talks with
the business to identify important ﬁne-grained sub-types of cracks. We eventually plan to combine
this damage classifer with our other work on using deep learning to localize damages.[18]
44 Acknowledgements
Much of this work was made possible by the SkySpecs internal analyst team. We would also like to
thank the anonymous reviewers for their insightful comments and feedback.
References
[1]Yassine Amirat, Mohamed El Hachemi Benbouzid, Elie Al-Ahmar, Bachir Bensaker, and Sylvie
Turri. A brief status on condition monitoring and fault diagnosis in wind energy conversion
systems. Renewable and sustainable energy reviews , 13(9):2629–2636, 2009.
[2]C Babu and K Meena. Structural health monitoring & fault detection in wind turbine using
image processing techniques. TAGA J. , 14:1967–1977, 2018.
[3]Yoshua Bengio, Jérôme Louradour, Ronan Collobert, and Jason Weston. Curriculum learning.
InProceedings of the 26th annual international conference on machine learning , pages 41–48,
2009.
[4]Young-Jin Cha, Wooram Choi, and Oral Büyüköztürk. Deep learning-based crack damage
detection using convolutional neural networks. Computer-Aided Civil and Infrastructure
Engineering , 32(5):361–378, 2017.
[5]Aditya Chattopadhay, Anirban Sarkar, Prantik Howlader, and Vineeth N Balasubramanian.
Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks.
In2018 IEEE winter conference on applications of computer vision (WACV) , pages 839–847.
IEEE, 2018.
[6]Xiao Chen. Fracture of wind turbine blades in operation—part i: A comprehensive forensic
investigation. Wind Energy , 21(11):1046–1063, 2018.
[7]Jui-Sheng Chou, Chien-Kuo Chiu, I-Kui Huang, and Kai-Ning Chi. Failure analysis of wind
turbine blade under critical wind loads. Engineering Failure Analysis , 27:99–118, 2013.
[8]Ángel M Costa, José A Orosa, Diego Vergara, and Pablo Fernández-Arias. New tendencies in
wind energy operation and maintenance. Applied Sciences , 11(4):1386, 2021.
[9]Dimitri Denhof, Benjamin Staar, Michael Lütjen, and Michael Freitag. Automatic optical
surface inspection of wind turbine rotor blades using convolutional neural networks. Procedia
CIRP , 81:1166–1170, 2019.
[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition ,
pages 770–778, 2016.
[11] InternationalEnergyAgency. Global energy review 2020. IEA, Paris , 2020.
[12] InternationalEnergyAgency. Global energy review 2021. IEA, Paris , 2021.
[13] IREA IRENA. Future of wind: Deployment, investment, technology, grid integration and
socio-economic aspects. 2019.
[14] Shing Yun Jung, Ya-Hui Tsai, Wei-Yao Chiu, Jwu-Sheng Hu, and Chuen-Tsai Sun. Defect
detection on randomly textured surfaces by convolutional neural networks. In 2018 IEEE/ASME
International Conference on Advanced Intelligent Mechatronics (AIM) , pages 1456–1461. IEEE,
2018.
[15] Dongsheng Li, Siu-Chun M Ho, Gangbing Song, Liang Ren, and Hongnan Li. A review of dam-
age detection methods for wind turbine blades. Smart Materials and Structures , 24(3):033001,
2015.
[16] WY Liu, BP Tang, JG Han, XN Lu, NN Hu, and ZZ He. The structure healthy condition
monitoring and fault diagnosis methods in wind turbines: A review. Renewable and Sustainable
Energy Reviews , 44:466–472, 2015.
5[17] Jonathan Masci, Ueli Meier, Dan Ciresan, Jürgen Schmidhuber, and Gabriel Fricout. Steel
defect classiﬁcation with max-pooling convolutional neural networks. In The 2012 international
joint conference on neural networks (IJCNN) , pages 1–6. IEEE, 2012.
[18] Linh V Nguyen, Shweta Khushu, and Akshay B Iyer. An automated system for detecting visual
damages of wind turbine blades. 2021.
[19] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas
Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,
Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-
performance deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d 'Alché-
Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32 ,
pages 8024–8035. Curran Associates, Inc., 2019.
[20] Juhi Patel, Lagan Sharma, and Harsh S Dhiman. Wind turbine blade surface damage detection
based on aerial imagery and vgg16-rcnn framework. arXiv preprint arXiv:2108.08636 , 2021.
[21] Abhishek Reddy, V Indragandhi, Logesh Ravi, and V Subramaniyaswamy. Detection of
cracks and damage in wind turbine blades using artiﬁcial intelligence-based image analytics.
Measurement , 147:106823, 2019.
[22] ASM Shihavuddin, Xiao Chen, Vladimir Fedorov, Anders Nymark Christensen, Nicolai Andre
Brogaard Riis, Kim Branner, Anders Bjorholm Dahl, and Rasmus Reinhold Paulsen. Wind
turbine surface damage detection by deep learning aided drone inspection analysis. Energies ,
12(4):676, 2019.
[23] ASM Shihavuddin, Xiao Chen, Vladimir Fedorov, Anders Nymark Christensen, Nicolai Andre
Brogaard Riis, Kim Branner, Anders Bjorholm Dahl, and Rasmus Reinhold Paulsen. Wind
turbine surface damage detection by deep learning aided drone inspection analysis. Energies ,
12(4):676, 2019.
[24] Leslie N Smith. Cyclical learning rates for training neural networks. In 2017 IEEE winter
conference on applications of computer vision (WACV) , pages 464–472. IEEE, 2017.
[25] Bjarne Steffen, Martin Beuse, Paul Tautorat, and Tobias S Schmidt. Experience curves for
operations and maintenance costs of renewable energy technologies. Joule , 4(2):359–375, 2020.
[26] Long Wang and Zijun Zhang. Automatic detection of wind turbine blade surface cracks based
on uav-taken images. IEEE Transactions on Industrial Electronics , 64(9):7293–7303, 2017.
[27] Huiyi Zhang and John Jackman. A feasibility study of wind turbine blade surface crack detection
using an optical inspection method. In 2013 International Conference on Renewable Energy
Research and Applications (ICRERA) , pages 847–852. IEEE, 2013.
6