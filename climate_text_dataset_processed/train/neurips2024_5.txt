Temporal sequence transformer to advance long-term
streamflow prediction
Ruhaan Singh
Farragut High School
Farragut, TN, USA
risruh@gmail.comDan Lu∗
Oak Ridge National Laboratory
Oak Ridge, TN, USA
lud1@ornl.govKshitij Tayal
University of Minnesota
Minneapolis, MN, USA
tayal@umn.edu
Abstract
Accurate streamflow prediction is crucial for understanding climate change impacts
on water resources and for effective management of extreme hydrological events.
While Long Short-Term Memory (LSTM) networks have been the dominant data-
driven approach for streamflow forecasting, recent advancements in transformer
architectures for time series tasks have shown promise in outperforming traditional
LSTM models. This study introduces a transformer-based model that integrates
historical streamflow data with climatic variables to enhance streamflow prediction
accuracy. We evaluated our transformer model against a benchmark LSTM across
five diverse basins in the United States. Results demonstrate that the transformer
architecture consistently outperforms the LSTM model across all evaluation metrics,
highlighting its potential as a more effective tool for hydrological forecasting. This
research contributes to the ongoing development of advanced AI techniques for
improved water resource management and climate change adaptation strategies.
1 Introduction
Accurate streamflow prediction is crucial for effective water resource management[ 1], especially
in the face of increasing climate variability[ 2][3]. Current approaches to streamflow forecasting,
while valuable, face significant limitations[ 4]. Large scale process based hydrologic models like
the Variable Infiltration Capacity (VIC)[ 5] and Precipitation Runoff Modeling System (PRMS)[ 6],
provide detailed simulations of the water cycle but are computationally intensive and often struggle
to capture the complex, non-linear relationships in hydrological systems[ 7]. Data-driven methods,
particularly LSTM networks[ 8], have gained popularity for their ability to model long-term dependen-
cies. However, LSTMs can struggle with very long sequences and may not fully capture the intricate
temporal dynamics of streamflow patterns for a long-term forecasting[9][10]. Transformer architec-
tures, originally developed for natural language processing tasks, offer a promising solution to these
challenges[ 11]. Their self-attention mechanism allows for more efficient modeling of long-range
dependencies and can potentially capture complex seasonal and inter-annual patterns in streamflow
data more effectively than LSTMs[ 12]. Moreover, transformers have shown superior performance
in various time series forecasting tasks[ 13], suggesting they could improve streamflow prediction
accuracy. In this study, we introduce a transformer-based model, FutureTST, to forecast streamflow
up to 30 days ahead across diverse basins in the United States. By leveraging the transformer’s
ability to process long sequences and identify subtle patterns, we aim to address the limitations of
current physics-based and LSTM models. This research is particularly timely given the increasing
hydrological uncertainties brought about by climate change. Improved streamflow forecasting can
enhance our ability to manage water resources, mitigate flood and drought risks, and support climate
change adaptation strategies.
∗Corresponding author
38th Conference on Neural Information Processing Systems (NeurIPS 2024).2 Data description
In this research, data was taken from the Catchment Attributes and Meteorology for Large-sample
Studies (CAMELS)[ 14] dataset. This dataset consisted of daily precipitation, vapor pressure, maxi-
mum temperature, snow water equivalent, short-wave radiation, daylight, and streamflow data from
1980-2014 for over 500 basins in the United States. Data from 1980-2000 was used as training data
while data from 2001-2007 was used as validation data, and data from 2008-2014 was used as testing
data. To rigorously assess our transformer model’s performance and versatility, we conducted evalua-
tions across five diverse basins in the United States (locations were shown in Figure 1). These basins
were carefully selected to represent a wide range of hydrometeorological conditions and catchment
attributes, allowing us to test the model’s transferability and generalizability. This diverse testing
ground enables us to evaluate how well the transformer model adapts to varying climate patterns,
land use characteristics, and hydrological regimes. Furthermore, we extended our analysis to multiple
forecasting horizons, predicting streamflow at 1-day, 14-day, and 30-day intervals. This multi-horizon
approach allows us to assess the model’s capability in both short-term operational forecasting and
longer-term water resource planning scenarios. By examining performance across these different
temporal scales, we can gauge the transformer’s ability to capture both immediate fluctuations and
longer-term trends in streamflow patterns, providing valuable insights into its potential for enhancing
both day-to-day water management decisions and longer-term climate adaptation strategies.
Figure 1: Location of the selected basins with their site identification numbers.
3 Methodology
The goal of our research is to predict future streamflow ( yfuture) by using previous streamflow records
(ypast) as well as climatic variables ( Xpast) and ( Xfuture). Mathematically, this forecasting problem
is formulated as yfuture =f(ypast, Xpast, Xfuture ). We use a transformer model, called FutureTST, to
address this problem. FutureTST has an encoder-decoder architecture, as shown in Figure 2. First
climatic variables, Xpast, Xfuture, are transformed into embeddings through a linear layer. This helps
the model understand and identify relationships between climatic variables. These embeddings are
then passed through the encoder block. Meanwhile, previous streamflow records, ypast, is broken up
into overlapping patches. This helps capture temporal dependencies present within the data. This
patched sequence is first fed through multi-headed attention and normalization in the decoder similar
to the climatic variables in the encoder. However, then cross attention between the output from the
encoder and the transformed past streamflow records is applied. This helps capture the relationship
between both previous climatic variables and streamflow. Finally, a linear head is used to turn the
output from the decoder into future streamflow predictions.
4 Results
We compare the prediction performance of the FutureTST model with that of the traditional LSTM
networks. Both models trained for 20 epochs with mean squared error (MSE) loss and ADAM
optimizer using a learning rate of 0.001. Each model was trained and evaluated with three different
2Figure 2: FutureTST architecture
look-ahead windows: 1 day, 7 days, and 30 days. Key metrics including Kling Gupta Efficiency
(KGE)[ 15], Nash Sutlciffe Efficiency (NSE)[ 16], and MSE[ 17] were used in this research to evaluate
the model performances. KGE combines the correlation coefficient, variability ratio, and bias
ratio into a singular metric that measures the performance of hydrological models. NSE is another
normalized statistic which depicts how well the model fits to the data. In both these metrics, the
target value is one and lower values show worse performance. Average statistics for all the metrics
across all the five basins for the different forecasting windows is shown in Table 1. Additionally,
basin comparisons for NSE values for the LSTM and FutureTST across all look-ahead periods is
shown in Figure 3. FutureTST outperforms the LSTM model across all prediction tasks highlighting
its superior performance. Figure 6 shows how the prediction window affects NSE values for both
FutureTST and the LSTM model. FutureTST starts out with a higher NSE value and doesn’t decline
as quickly as the LSTM model did.
Table 1: Average metrics for different models and timeframes
Model/Timeframe KGE NSE MSE
30 Day LSTM -0.004 0.107 7.724
30 Day FutureTST 0.345 0.428 4.480
7 Day LSTM 0.149 0.191 6.880
7 Day FutureTST 0.393 0.375 5.079
1 Day LSTM 0.441 0.431 4.422
1 Day FutureTST 0.597 0.534 3.614
Figure 3: FutureTST vs LSTM performance by basin
3Figure 4: Example streamflow predictions for 1 basin (left) and FutureTST vs LSTM model perfor-
mance over varying intervals (right)
5 Conclusions and impacts
In this study, we introduced a novel transformer architecture, FutureTST, for streamflow prediction,
demonstrating its superior performance over traditional LSTM models across diverse hydrological set-
tings. Our comprehensive evaluation across five basins with varying hydrometeorological conditions
and catchment attributes revealed the model’s robust transferability and generalizability. FutureTST
consistently outperformed LSTM models across all tested metrics and forecasting horizons (1-day,
14-day, and 30-day). The success of FutureTST can be attributed to its unique features, including
specialized encodings, multi-headed attention mechanisms, and cross-attention capabilities. These
characteristics enable the model to capture complex temporal dependencies and spatial relationships
in hydrological data more effectively than traditional approaches. The model’s ability to generalize
across different climatic zones suggests its potential for wide-scale application in diverse geographical
contexts.
The implications of this work extend far beyond mere technical improvements. As climate change
continues to alter hydrological patterns globally, the need for accurate and adaptable streamflow
prediction tools becomes increasingly critical. FutureTST’s capability to integrate future climate
simulations for various climatic variables positions it as a powerful tool for long-term water resource
planning and climate change adaptation strategies. This advanced forecasting ability can significantly
enhance our capacity to predict and manage floods and droughts, monitor water levels, and inform
agricultural planning - all of which are pivotal in the face of our changing climate.
6 Future work
In the future, we aim to increase this study to hundreds of basins across the United States in order
to explore whether FutureTST is able to generalize as well increasing the reliability of our results.
Additionally, testing FutureTST where future climatic variables have manually added noise since the
climate simulations for future climatic data would not be completely accurate.
Acknowledgment
This research is supported by Dan Lu’s Early Career Project, sponsored by the Office of Biological
and Environmental Research in the U.S. Department of Energy (DOE). The work was performed at
Oak Ridge National Laboratory which is operated by UT Battelle, LLC, for the DOE under Contract
DE-AC05-00OR22725.
4References
[1]D. P. Lettenmaier, A. W. Wood, R. N. Palmer, E. F. Wood, and E. Z. Stakhiv, “Water resources
implications of global warming: A us regional perspective,” Climatic Change , vol. 43, no. 3,
pp. 537–579, 1999.
[2]M. Jha, Z. Pan, E. S. Takle, and R. Gu, “Impacts of climate change on streamflow in the
upper mississippi river basin: A regional climate model perspective,” Journal of Geophysical
Research: Atmospheres , vol. 109, no. D9, 2004.
[3]B. S. Naz, S.-C. Kao, M. Ashfaq, H. Gao, D. Rastogi, and S. Gangrade, “Effects of climate
change on streamflow extremes and implications for reservoir inflow in the united states,”
Journal of Hydrology , vol. 556, pp. 359–370, 2018.
[4]Z. M. Yaseen, A. El-Shafie, O. Jaafar, H. A. Afan, and K. N. Sayl, “Artificial intelligence based
models for stream-flow forecasting: 2000–2015,” Journal of Hydrology , vol. 530, pp. 829–844,
2015.
[5]X. Liang, D. P. Lettenmaier, E. F. Wood, and S. J. Burges, “A simple hydrologically based model
of land surface water and energy fluxes for general circulation models,” Journal of Geophysical
Research: Atmospheres , vol. 99, no. D7, pp. 14415–14428, 1994.
[6]S. L. Markstrom, R. S. Regan, L. E. Hay, R. J. Viger, R. M. Webb, R. A. Payn, and J. H.
LaFontaine, “Prms-iv, the precipitation-runoff modeling system, version 4,” tech. rep., US
Geological Survey, 2015.
[7]M. Cheng, F. Fang, T. Kinouchi, I. Navon, and C. Pain, “Long lead-time daily and monthly
streamflow forecasting using machine learning methods,” Journal of Hydrology , vol. 590,
p. 125376, 2020.
[8]S. Ghimire, Z. M. Yaseen, A. A. Farooque, R. C. Deo, J. Zhang, and X. Tao, “Streamflow
prediction using an integrated methodology based on convolutional neural network and long
short-term memory networks,” Scientific Reports , vol. 11, no. 1, p. 17497, 2021.
[9]K. M. Hunt, G. R. Matthews, F. Pappenberger, and C. Prudhomme, “Using a long short-term
memory (lstm) neural network to boost river streamflow forecasts over the western united states,”
Hydrology and Earth System Sciences , vol. 26, no. 21, pp. 5449–5472, 2022.
[10] Q. Yu, B. A. Tolson, H. Shen, M. Han, J. Mai, and J. Lin, “Enhancing long short-term memory
(lstm)-based streamflow prediction with a spatially distributed approach,” Hydrology and Earth
System Sciences , vol. 28, no. 9, pp. 2107–2122, 2024.
[11] U. Kamath, K. Graham, and W. Emara, Transformers for machine learning: a deep dive .
Chapman and Hall/CRC, 2022.
[12] I. Sonata and Y . Heryadi, “Comparison of lstm and transformer for time series data forecasting,”
in2024 7th International Conference on Informatics and Computational Sciences (ICICoS) ,
pp. 491–495, IEEE, 2024.
[13] A. Zeng, M. Chen, L. Zhang, and Q. Xu, “Are transformers effective for time series forecasting?,”
inProceedings of the AAAI conference on artificial intelligence , vol. 37, pp. 11121–11128,
2023.
[14] N. Addor, A. J. Newman, N. Mizukami, and M. P. Clark, “The camels data set: catchment
attributes and meteorology for large-sample studies,” Hydrology and Earth System Sciences ,
vol. 21, no. 10, pp. 5293–5313, 2017.
[15] H. V . Gupta and H. Kling, “On typical range, sensitivity, and normalization of mean squared
error and nash-sutcliffe efficiency type metrics,” Water Resources Research , vol. 47, no. 10,
2011.
[16] J. E. Nash and J. V . Sutcliffe, “River flow forecasting through conceptual models part i—a
discussion of principles,” Journal of hydrology , vol. 10, no. 3, pp. 282–290, 1970.
[17] T. Chai, R. R. Draxler, et al. , “Root mean square error (rmse) or mean absolute error (mae),”
Geoscientific model development discussions , vol. 7, no. 1, pp. 1525–1534, 2014.
5A Appendix
A.1 Static characteristics
The following table lists the static features used in the model
6A.2 Detailed results
The following table lists the complete set of metrics for every basin for each forecasting period.
Basin ID Metric Forecasting Horizon LSTM Transformer
02465493KGE 1 day 0.2549 0.4011
7 days -0.045 0.1881
30 days -0.1608 0.2368
NSE 1 day 0.1314 0.2874
7 days 0.0433 0.1796
30 days 0.0399 0.202
MSE 1 day 3.4954 2.8675
7 days 3.8593 3.3097
30 days 3.9118 3.2514
11143000KGE 1 day 0.3018 0.4306
7 days -0.0043 0.2455
30 days -0.207 0.331
NSE 1 day 0.2321 0.3276
7 days 0.0594 0.2442
30 days 0.0209 0.2937
MSE 1 day 2.4857 2.1767
7 days 3.0527 2.453
30 days 3.2015 2.3095
01666500KGE 1 day 0.1905 0.4744
7 days -0.2438 0.2411
30 days -0.3119 -0.0239
NSE 1 day 0.3 0.4025
7 days 0.0146 0.2786
30 days 0.0091 0.4525
MSE 1 day 10.7957 9.2147
7 days 15.2367 11.1553
30 days 15.4795 8.5534
12488500KGE 1 day 0.7574 0.9281
7 days 0.664 0.673
30 days 0.5023 0.6352
NSE 1 day 0.808 0.9349
7 days 0.5832 0.6091
30 days 0.3408 0.6004
MSE 1 day 1.6752 0.5681
7 days 3.6416 3.4153
30 days 5.7925 3.5113
7184000KGE 1 day 0.7014 0.7488
7 days 0.376 0.6175
30 days 0.1579 0.5466
NSE 1 day 0.683 0.719
7 days 0.2558 0.5626
30 days 0.1235 0.5913
MSE 1 day 3.6594 3.2442
7 days 8.6113 5.0611
30 days 10.2351 4.773
7