MethaNet - an AI-driven approach to quantifying methane
point-source emission from high-resolution 2-D plume imagery
Siraput Jongaramrungruang1Christian Frankenberg1 2Andrew K. Thorpe2Georgios Matheou3
Abstract
Methane (CH 4) is one of the most powerful an-
thropogenic greenhouse gases with a signiﬁcant
impact on global warming trajectory and tropo-
spheric air quality. Quantifying an emission rate
of observed CH 4plumes from aerial or satellite
images is a critical step for understanding the local
distributions and subsequently prioritizing mitiga-
tion target sites. However, there exists no method
that can reliably predict emission rates from de-
tected plumes in real-time without ancillary data.
Here, we trained a convolutional neural network
model, called MethaNet, to predict methane point-
source emission directly from high-resolution 2-
D plume images without relying on other local
measurements such as background wind speeds.
Our results support the basis for the applicabil-
ity of using deep learning techniques to quantify
CH4point sources in an automated manner over
large geographical areas. MethaNet opens the
way for real-time monitoring systems, not only
for present and future airborne ﬁeld campaigns
but also for upcoming space-based observations
in this decade.
1. Introduction
Methane is the second strongest anthropogenic greenhouse
gases overall in the Earth climate system. Due to its much
shorter lifetime compared to that of CO 2, methane emission
could be a target for emission reduction efforts to help mit-
igate climate impacts on a signiﬁcantly shorter timescale
(Montzka et al., 2011; Prather et al., 2012; Shindell et al.,
2012). In fact, the 2018 NASA Decadal Survey has indi-
*Equal contribution1Division of Geological and Planetary Sci-
ences, California Institute of Technology, Pasadena, CA, USA
2NASA Jet Propulsion Laboratory, California Institute of Technol-
ogy, Pasadena, CA, USA3Department of Mechanical Engineering,
University of Connecticut, Storrs, CT, USA. Correspondence to:
Siraput Jongaramrungruang <siraput@caltech.edu >.
Proceedings of the 38thInternational Conference on Machine
Learning , PMLR 139, 2021. Copyright 2021 by the author(s).cated the identiﬁcation and understanding of methane emis-
sions as one of the top priorities in the efforts to improve the
future climate projection, and help lead the way in emission
reduction (National Academies of Sciences, Engineering &
Medicine, 2018).
Despite relatively well-constrained total global emissions,
regional and local emission estimates have been challenging
due to uncertainties in the process understanding and lack
of sufﬁciently ﬁne resolution observations that can also
simultaneously cover large geographical areas. This hinders
the ability to conduct mitigation efforts in the most effective
manner since policy and remedy actions often take place
at regional and local scales. Improved measurements of
localized CH 4point sources (e.g. 10 - 100 m scale) are
integral to this effort.
One potential to ﬁll this gap is remote-sensing imaging ab-
sorption spectrometry. This technique has opened the way
for quantitative CH 4measurements at sufﬁciently high res-
olution needed to differentiate various local sources over
large areas at regional scale (Duren et al., 2019; Franken-
berg et al., 2016). Using absorption features of CH 4in
the short-wave infrared around 2.3 m, column integrated
CH4concentration can be retrieved at a spatial resolution as
ﬁne as 1 m, allowing for the detection of CH 4point sources
from airborne spectrometers such as the next-generation Air-
borne Visible/Infrared Imaging Spectrometer (A VIRIS-NG)
(Thorpe et al., 2017). Studies have utilized this technique
for several ﬁeld campaigns in the Western U.S. where more
than 500 strong point sources have been detected (Duren
et al., 2019; Frankenberg et al., 2016). Figure 1 shows
examples of representative methane plumes from different
sectors. Sources of various emission rates observed under
varying wind speeds would lead to a diverse set of plume
spatial distributions. Despite the progress in the detection
algorithm of methane plumes, high uncertainties still exist
in converting the observed concentration ﬁelds to source
ﬂux rates.
Many ﬂux inversion methods have been proposed such as
the Gaussian plume inversion (Bovensmann et al., 2010;
Krings et al., 2013), source pixel estimate (Jacob et al.,
2016), cross-sectional ﬂux estimate (Cambaliza et al., 2015;
2014; Conley et al., 2016), and residence time of methaneMethaNet - an AI-driven approach to quantifying methane emission
Figure 1. A map showing detected methane sources from the Cali-
fornia Methane Source Finder project. Background image shows
A VIRIS-NG ﬂight lines conducted in 2016 and 2017 (white stripes)
and locations of detected CH 4sources (purple circles). The in-
set images show examples of methane plume enhancement from
A VIRIS-NG observations over (a) a landﬁll, (b) diary manure area,
(c) an oil and gas facility, and (d) a natural gas storage ﬁeld.
plume enhancement (Duren et al., 2019; Varon et al., 2018).
All of these techniques, however, require the knowledge of
local wind speed. This hinders fast and accurate ﬂux inver-
sions since in situ wind measurements cannot be planned
when the location of the plume is not known a priori. Due to
these limitations, accurate and fast ﬂux inversions of point
sources have been challenging. Jongaramrungruang et al.
(2019) tackled this challenge by utilizing plume morphology
to constrain corresponding wind speed and thus ﬂux rate. It
provides evidence that the morphology of methane plumes,
as observed from remote sensing images, contains useful
information about the background wind speed during the
ﬂight overpass, which, in turn, is a critical component of
predicting accurate ﬂux estimates. In that work, a plume
angular width is constructed as a simple metric to represent
the geometry of observed methane plumes. Essentially, the
2D pattern of the plume is simply reduced into one dimen-
sion, which was an ad hoc choice. However, the full spatial
structure of the plume morphology can potentially be uti-
lized such that emission rates are predicted at even higher
accuracy, as well as in a more automated and objective
manner.
Modern machine learning techniques are designed for prob-
lems as this task. Convolutional Neural Network (CNN) is
a model architecture that has shown tremendous success in
image recognition tasks (He et al., 2016; Krizhevsky et al.,
2012; Simonyan & Zisserman, 2015; Szegedy et al., 2014).
It has been shown to be capable of learning relevant spa-
tial patterns from an image with location invariant featuressimilar to how a human brain understands an image. Here
in this work, we build a customized CNN model and apply
it to a large training dataset derived from Large Eddy Sim-
ulation (LES) (Matheou et al., 2014) output and realistic
background noise over agricultural, desert and urban envi-
ronments. We train our model, named MethaNet, to predict
ﬂux rates directly from 2D methane plume images. To our
knowledge, this is the ﬁrst time that CNN has been used for
a regression task to quantify methane plume emission from
2D high-resolution imagery.
Section 2 illustrates the method on preparing the dataset,
and the details on MethaNet CNN architecture. Model
performance and error analyses are provided in Section 3,
followed by concluding remarks in the ﬁnal section.
2. Methodology
2.1. Data
To train a model capable of quantifying an emission rate
from a given 2D image, a realistic modelling of CH 4plumes
is a prerequisite, as the actual plume observations with
known ﬂux rates are extremely limited. The training data is
a set of simulated plume images, each with one channel rep-
resenting CH 4concentration and each has a source emission
rate as a label. The LES is used to generate the time-resolved
three-dimensional CH 4distribution in the boundary layer,
over a range of 1-10 m/s wind speeds. This enables a re-
alistic simulation of how methane concentrations from a
point source evolve in space, given various background
wind speeds and source ﬂux rates. The full description of
the LES model setup can be found in Jongaramrungruang
et al. (2019).
This allows us to efﬁciently create synthetic plumes originat-
ing from sources spanning orders of magnitudes in ﬂux rates.
In this work, we focus on plume emission rates between
0 and 2000 kg/hr which is the range in which the major-
ity of typical methane point sources were observed (Duren
et al., 2019). Each of these 2D images is then augmented
by continuous random rotation between -170 °to 170 °and
translation between -30 to +30 pixels, to generate a diverse
set of possible plume orientations and center locations. Ad-
ditionally, superposed on each an image is a noise matrix
with the same size as the plume image. The illustration of
this synthetic plume generation is shown in Figure 2. The
noise matrix is taken from retrieval background variations
from actual A VIRIS-NG scenes in the absence of plumes.
In our work, we obtained scenes over a variety of surfaces,
including urban, desert, and agricultural areas.
Building a successful neural network model generally re-
quires large data samples. These data are separated into
training, validation and test sets that share a similar distribu-
tion but are distinct from one another. Our training data isMethaNet - an AI-driven approach to quantifying methane emission
Figure 2. An example of a plume image from a simulated plume superposed on a realistic retrieval noise background based on an
A VIRIS-NG observation over agricultural area.
a set images of plumes of different sizes and shapes under
various wind speeds and background noise. In our study,
we assign images from independent LES runs for training,
validation and test sets ( 300K, 10K, and 3K samples respec-
tively). We also assign background noise scenes into three
buckets, each to be used exclusively in each of the three
sets to ensure no data contamination among them. After
MethaNet is trained, validated, and tested in the simulation
world, the best model is also applied to make a prediction
on a few available actual plume observations from a ground
controlled-release experiment.
2.2. Model
Machine learning methods have been used extensively in
many ﬁelds to predictive problems. One particular model in
machine learning that has found a great success in computer
vision tasks is CNN (He et al., 2016; Krizhevsky et al.,
2012; Simonyan & Zisserman, 2015; Szegedy et al., 2014).
It has been the primary building blocks for tasks such as
face recognition, image classiﬁcation, autonomous driving.
Because of its versatility, recently it has been adopted in
tackling environmental science-related problems such as
gas leak classiﬁcation and wild ﬁre classiﬁcation based on
remote-sensing images (Kumar et al., 2020; Pan et al., 2020;
Wang et al., 2020). However, most of the CNN applications
in environmental science has been primarily limited to a
classiﬁcation problem. Here, for the ﬁrst time, we applied
CNN to predict methane quantiﬁcation directly from a 2D
image as a regression task. We develop a customized CNN
model, named MethaNet, based on a basic building block
where a convolutional layer with a non-linear activation
function is followed by a max pooling layer, then combining
with a few fully-connected layers before the last output layer
that determines the ﬂux rate a scalar value.
In our case, an image dimension of 300*300 pixels is suit-
able, as it covers a range of 1.5*1.5 km2, which can fully
capture typical plume dimensions of less than 1 km. The
input image has only 1 channel representing a value of re-
trieved CH 4enhancement (this value is not bounded by 255as typical in RGB). The architecture consists of a series
of convolutional layers each with different numbers of ﬁl-
ters and sizes, and each has a Rectiﬁed Linear Unit (ReLu)
activation function. Max pooling layers are also applied
after certain convolutional layers, and a dropout layer is in-
cluded as a regularization to reduce overﬁtting. After these
combined layers, the output is then ﬂattened and passed to
fully-connected layers with 64 and 32 neurons with ReLU
activations. Finally, the output layer contains one neuron
with a scaler output for a regression task to quantify methane
emission rate from the input image.
3. Results and Analysis
In this section, we show the performance of MethaNet on
predicting methane emission rates. The comparison between
the true and predicted ﬂuxes from the test set are shown in
Figure 3. A key metric that is widely used to characterize
the effectiveness of plume emission estimates in the ﬁeld is
the mean absolute percentage error.
Generally, MethaNet predictions align well with the true
values as indicated by the concentration of points close to
the 1:1 line. For plumes with emission rates above 40 kg/hr,
our model can predict with the mean absolute percentage
error of under 17%.
We see some outliers for some plumes at very low ﬂuxes,
especially under 30 kg/hr. Inspection on the data points
with low ﬂuxes and high prediction error reveals that these
scenes have bright surface features (high correlated noise
levels), which interfere with how the network perceives and
predict the actual ﬂuxes from the images. For these scenes,
it is hard for even human eyes to distinguish plumes from
the noise. Thus, it is hard for the model to perform well
on scenes in such an extreme case. Predictions for plumes
under high background wind speeds (8-10 m/s) also tend
to underestimate the true ﬂux rates. This could be because
plumes have more elongated structures under such high
wind speeds; these structures were seen less often in the
training data compared to typical more-rounded structuresMethaNet - an AI-driven approach to quantifying methane emission
0 400 800 1200 1600 2000
True flux (kg/hr)0400800120016002000Predicted flux (kg/hr)
Figure 3. A plot showing a comparison between true ﬂuxes and
predicted ﬂuxes by MethaNet trained from all LES runs with
realistic background noise to predict unseen plumes in test set. A
solid line shows a 1:1 relationship.
Figure 4. Controlled release experiment conducted at Victorville,
CA. The scenes represent 3 overpasses with a controlled ﬂux rate
of 39 kg/hr. The enhancement in color is used for MethaNet input;
the background RGB is shown only for visual reference.
under lower wind speed regimes. Overall, it is evident that
our model can predict the emission rate of methane plumes
accurately without the need for wind speed information.
Over the same range of ﬂux rates, this level of accuracy
surpasses other previous methods, which even require wind
speeds to estimate emission rates. This is a signiﬁcant part
in deploying the model for a real-time application during
ﬁeld campaigns and future monitoring systems. This level
of performance at a mean absolute percentage error of 17%
is a state-of-the-art achievement for a model that does not
even rely on wind speed information.To further demonstrate the validity of this method, we apply
our model to actual 2D scenes of a methane plume from a
controlled-release experiment from a natural gas pipeline
located at Victorville, CA (34.8, -117.3), on 15-17 June,
2017, with a ﬂux release of 39 ±5 kg/hr. The three snap-
shots of the same plume from this source is shown in Figure
4. Based on each snapshot, we feed the 2D image into our
trained model and directly obtain a prediction of emission
rate of the source. The predicted ﬂux rates are 33, 26, and
32 kg/hr. The mean and standard deviation is 31 and 3, re-
spectively. This is consistent with the actual rate within one
standard deviation. The mean prediction is approximately
20% deviated from the true value.
4. Conclusion
In this study, we demonstrated a novel approach using deep
learning to quantify methane gas emission based on high-
resolution airborne imagery. Our method demonstrates that
an accurate estimate of methane emission rates can be ob-
tained directly from CH 4enhancement image without the
need of simultaneous wind speed measurement. We build a
Convolutional Neural Network model to learn the mapping
between 2D plume images and theirs corresponding source
emission rates under various wind speed conditions. The
training data are derived from realistic plume simulation
using LES and realistic retrieval noise from A VIRIS-NG
ﬁeld observations. Our simulated CH 4images represent
a diverse set of realistic plumes of various emission rates
between 0-2000 kg/hr in different landscape ranging from
urban, desert to agriculture areas. Our error analysis based
on the model prediction of a hold-out set of unseen scenes
shows an error of around 17% on average. This level of
error is a signiﬁcant improvement from other pre-existing
approaches, while it completely removes the dependence on
meteorological wind speed data which might not be reliable
or available at high spatial resolution everywhere on the
globe. An independent test on a controlled release experi-
ment data over Victorville, CA, also validates a consistent
prediction performance for MethaNet in real observations.
We have shown that this model can be applied to quantifying
methane point-source emission in a quick and automated
manner based directly on plume images alone. While the
range of methane emissions prescribed in this study was be-
tween 0 and 2000 kg/hr, we believe that the same approach
can be applied to plumes with even higher ﬂuxes as the
plume enhancement in such case will be even more promi-
nent compared to the surrounding noise background. With
the level of performance of MethaNet, we believe it could
be applied to recent large-scale ﬂight campaigns to improve
previous emission rate estimates. This also has immediate
implications for future aerial campaigns and space-baed ob-
servations from anticipated satellites that will be launched
in this decade.MethaNet - an AI-driven approach to quantifying methane emission
References
Bovensmann, H., Buchwitz, M., Burrows, J. P., Reuter, M.,
Krings, T., Gerilowski, K., Schneising, O., Heymann, J.,
Tretner, A., and Erzinger, J. A remote sensing technique
for global monitoring of power plant CO 2 emissions from
space and related applications. Atmospheric Measurement
Techniques , 3(4):781–811, 2010. ISSN 18671381. doi:
10.5194/amt-3-781-2010.
Cambaliza, M. O., Shepson, P. B., Caulton, D. R., Stirm, B.,
Samarov, D., Gurney, K. R., Turnbull, J., Davis, K. J., Pos-
solo, A., Karion, A., Sweeney, C., Moser, B., Hendricks,
A., Lauvaux, T., Mays, K., Whetstone, J., Huang, J.,
Razlivanov, I., Miles, N. L., and Richardson, S. J. Assess-
ment of uncertainties of an aircraft-based mass balance
approach for quantifying urban greenhouse gas emissions.
Atmospheric Chemistry and Physics , 14(17):9029–9050,
2014. ISSN 16807324. doi: 10.5194/acp-14-9029-2014.
Cambaliza, M. O., Shepson, P. B., Bogner, J., Caulton, D. R.,
Stirm, B., Sweeney, C., Montzka, S. A., Gurney, K. R.,
Spokas, K., Salmon, O. E., Lavoie, T. N., Hendricks, A.,
Mays, K., Turnbull, J., Miller, B. R., Lauvaux, T., Davis,
K., Karion, A., Moser, B., Miller, C., Obermeyer, C.,
Whetstone, J., Prasad, K., Miles, N., and Richardson, S.
Quantiﬁcation and source apportionment of the methane
emission ﬂux from the city of Indianapolis. Elementa ,
3:1–18, 2015. ISSN 23251026. doi: 10.12952/journal.
elementa.000037.
Conley, S., Franco, G., Faloona, I., Blake, D. R., Peischl,
J., and Ryerson, T. B. Methane emissions from the 2015
Aliso Canyon blowout in Los Angeles, CA. Science , 351
(6279):1317–1320, 2016. ISSN 10959203. doi: 10.1126/
science.aaf2348.
Duren, R. M., Thorpe, A. K., Foster, K. T., Raﬁq, T., Hop-
kins, F. M., Yadav, V ., Bue, B. D., Thompson, D. R.,
Conley, S., Colombi, N. K., Frankenberg, C., McCub-
bin, I. B., Eastwood, M. L., Falk, M., Herner, J. D.,
Croes, B. E., Green, R. O., and Miller, C. E. Cal-
ifornia’s methane super-emitters. Nature , 575(7781):
180–184, 2019. ISSN 14764687. doi: 10.1038/
s41586-019-1720-3. URL http://dx.doi.org/
10.1038/s41586-019-1720-3 .
Frankenberg, C., Thorpe, A. K., Thompson, D. R., Hul-
ley, G., Kort, E. A., Vance, N., Borchardt, J., Krings,
T., Gerilowski, K., Sweeney, C., Conley, S., Bue, B. D.,
Aubrey, A. D., Hook, S., and Green, R. O. Airborne
methane remote measurements reveal heavy-tail ﬂux
distribution in Four Corners region. Proceedings of
the National Academy of Sciences , 113(35):9734–9739,
2016. ISSN 0027-8424. doi: 10.1073/pnas.1605617113.
URL http://www.pnas.org/lookup/doi/10.
1073/pnas.1605617113 .He, K., Zhang, X., Ren, S., and Sun, J. Deep residual
learning for image recognition. Proceedings of the IEEE
Computer Society Conference on Computer Vision and
Pattern Recognition , 2016-Decem:770–778, 2016. ISSN
10636919. doi: 10.1109/CVPR.2016.90.
Jacob, D., Turner, A., Maasakkers, J., Sheng, J., Sun, K.,
Liu, X., Chance, K., Aben, I., McKeever, J., and Franken-
berg, C. Satellite observations of atmospheric methane
and their value for quantifying methane emissions. At-
mospheric Chemistry and Physics , 16(22), 2016. ISSN
16807324. doi: 10.5194/acp-16-14371-2016.
Jongaramrungruang, S., Frankenberg, C., Matheou, G.,
Thorpe, A., Thompson, D., Kuai, L., and Duren, R. To-
wards accurate methane point-source quantiﬁcation from
high-resolution 2-D plume imagery. Atmospheric Mea-
surement Techniques , 12(12), 2019. ISSN 18678548. doi:
10.5194/amt-12-6667-2019.
Krings, T., Gerilowski, K., Buchwitz, M., Hartmann,
J. M., Sachs, T., Erzinger, J., Burrows, J. P., and
Bovensmann, H. Quantiﬁcation of methane emis-
sion rates from coal mine ventilation shafts using
airborne remote sensing data. Atmospheric Mea-
surement Techniques , 6(1):151–166, jan 2013. URL
http://www.atmos-meas-tech.net/6/
151/2013/http://file//localhost(null)
papers3://publication/doi/10.5194/
amt-6-151-2013 .
Krizhevsky, B. A., Sutskever, I., and Hinton, G. E. ImageNet
Classiﬁcation with Deep Convolutional Neural Networks.
Communications of the ACM , 60(6):84–90, 2012.
Kumar, S., Torres, C., Ulutan, O., Ayasse, A., Roberts, D.,
and Manjunath, B. S. Deep remote sensing methods
for methane detection in overhead hyperspectral imagery.
Proceedings - 2020 IEEE Winter Conference on Applica-
tions of Computer Vision, WACV 2020 , pp. 1765–1774,
2020. doi: 10.1109/WACV45572.2020.9093600.
Matheou, G., Chung, D., Matheou, G., and Chung,
D. Large-Eddy Simulation of Stratiﬁed Turbulence.
Part II: Application of the Stretched-V ortex Model to
the Atmospheric Boundary Layer. Journal of the
Atmospheric Sciences , 71(12):4439–4460, dec 2014.
ISSN 0022-4928. doi: 10.1175/JAS-D-13-0306.
1. URL http://journals.ametsoc.org/doi/
abs/10.1175/JAS-D-13-0306.1 .
Montzka, S. A., Krol, M., Dlugokencky, E., Hall, B., and
Jo, P. Small Interannual Variability of. Science , 331
(January):67–69, 2011.
National Academies of Sciences, Engineering and Medicine.
Thriving on Our Changing Planet: A Decadal Strategy forMethaNet - an AI-driven approach to quantifying methane emission
Earth Observation from Space. The National Academies
Press. , 2018. doi: 10.17226/24938.
Pan, H., Badawi, D., and Cetin, A. E. Computationally
efﬁcient wildﬁre detection method using a deep con-
volutional network pruned via fourier analysis. Sen-
sors (Switzerland) , 20(10), 2020. ISSN 14248220. doi:
10.3390/s20102891.
Prather, M. J., Holmes, C. D., and Hsu, J. Reactive green-
house gas scenarios: Systematic exploration of uncer-
tainties and the role of atmospheric chemistry. Geo-
physical Research Letters , 2012. ISSN 00948276. doi:
10.1029/2012GL051440.
Shindell, D., Kuylenstierna, J. C., Vignati, E., Van Dingenen,
R., Amann, M., Klimont, Z., Anenberg, S. C., Muller, N.,
Janssens-Maenhout, G., Raes, F., Schwartz, J., Faluvegi,
G., Pozzoli, L., Kupiainen, K., H ¨oglund-Isaksson, L.,
Emberson, L., Streets, D., Ramanathan, V ., Hicks, K.,
Oanh, N. T., Milly, G., Williams, M., Demkine, V ., and
Fowler, D. Simultaneously mitigating near-term climate
change and improving human health and food security.
Science , 335(6065):183–189, 2012. ISSN 10959203. doi:
10.1126/science.1210026.
Simonyan, K. and Zisserman, A. Very deep convolutional
networks for large-scale image recognition. 3rd Inter-
national Conference on Learning Representations, ICLR
2015 - Conference Track Proceedings , pp. 1–14, 2015.
Szegedy, C., Vanhoucke, V ., Shlens, J., and Wojna, Z. Re-
thinking the Inception Architecture for Computer Vision.
CoRR , abs/1512.00567, 2014.
Thorpe, A. K., Frankenberg, C., Thompson, D. R., Duren,
R. M., Aubrey, A. D., Bue, B. D., Green, R. O., Ger-
ilowski, K., Krings, T., Borchardt, J., Kort, E. A.,
Sweeney, C., Conley, S., Roberts, D. A., and Dennison,
P. E. Airborne DOAS retrievals of methane, carbon diox-
ide, and water vapor concentrations at high spatial reso-
lution: Application to A VIRIS-NG. Atmospheric Mea-
surement Techniques , 10(10):3833–3850, 2017. ISSN
18678548. doi: 10.5194/amt-10-3833-2017.
Varon, D. J., Jacob, D. J., McKeever, J., Jervis, D., Durak,
B. O., Xia, Y ., and Huang, Y . Quantifying methane
point sources from ﬁne-scale satellite observations of
atmospheric methane plumes. Atmospheric Measurement
Techniques , 11(10):5673–5686, 2018. ISSN 18678548.
doi: 10.5194/amt-11-5673-2018.
Wang, J., Tchapmi, L. P., Ravikumar, A. P., McGuire, M.,
Bell, C. S., Zimmerle, D., Savarese, S., and Brandt, A. R.
Machine vision for natural gas methane emissions de-
tection using an infrared camera. Applied Energy , 257
(September 2019):113998, 2020. ISSN 03062619. doi:10.1016/j.apenergy.2019.113998. URL https://doi.
org/10.1016/j.apenergy.2019.113998 .