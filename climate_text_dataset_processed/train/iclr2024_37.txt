Published as a workshop paper at ”Tackling Climate Change with Machine Learning”, ICLR 2024
MODEL FAILURE OR DATA CORRUPTION ? E XPLOR -
ING INCONSISTENCIES IN BUILDING ENERGY RAT-
INGS WITH SELF-SUPERVISED CONTRASTIVE LEARN -
ING
Qian Xiao, Dan Liu & Kevin Credit
ADAPT Centre
O’Reilly Institute, Trinity College 25 Westland Row, Dublin, D02 PN40
{qian.xiao, dan.liu, kevin.credit }@adaptcentre.ie
ABSTRACT
Building Energy Rating (BER) stands as a pivotal metric, enabling building own-
ers, policymakers, and urban planners to understand the energy-saving potential
through improving building energy efficiency. As such, enhancing buildings’
BER levels is expected to directly contribute to the reduction of carbon emissions
and promote climate improvement. Nonetheless, the BER assessment process
is vulnerable to missing and inaccurate measurements. In this study, we intro-
duceCLEAR , a data-driven approach designed to scrutinize the inconsistencies in
BER assessments through self-supervised contrastive learning. We validated the
effectiveness of CLEAR using a dataset representing Irish building stocks. Our
experiments uncovered evidence of inconsistent BER assessments, highlighting
measurement data corruption within this real-world dataset.
1 I NTRODUCTION
The building sector is responsible for nearly 40% of energy-related CO2 emissions (Dahlstr ¨om et al.,
2022). Improving building energy efficiency, especially for existing ones, is key to combating cli-
mate change for many countries (Egan et al., 2023). Building energy efficiency assessment plays
a pivotal role in guiding decisions for both retrofitting existing buildings and designing new ones
(Coyne & Denny, 2021; Energy & Engineers). The assessment results stand as cornerstone metrics
in shaping various policies for guiding the public to address energy poverty and steer climate action.
For example, in Europe, buildings’ energy efficiency is factored into mortgage interests rates for the
homeowners (Billio et al., 2022). New dwellings in many EU countries are also required to comply
with strict energy efficiency regulations (Energy & Engineers). Despite its significance, the assess-
ment process of building energy efficiency in which professionals involved is susceptible to missing
values and faulty measurements as the result of negligent errors (Ali et al., 2020). Consequently,
such processes are prone to partial data corruption, leading to potential substantial inaccuracies in
the assigned energy ratings.
Ensuring the reliability and transparency of the Building Energy Rating (BER) process is crucial for
upholding the integrity of energy efficiency assessments. To tackle this challenge, previous research
on Ireland’s BER data has emphasized the potential benefits of integrating data-driven approaches
(Ali et al., 2020). While such approach is promising, the machine learning models examined in
(Ali et al., 2020) exhibited a significant performance drop when predicting fine-grained rating level
categories. Table 1 presents such performance drops observed in both the Random Forest model and
the MLP (multi-layer perceptron) deep learning model. Various factors could potentially contribute
to these performance drops, including models’ limited generalizability, sparsity of data distribution,
or poor data quality. Currently, there is still a lack of understanding of the actual reasons behind
such observations, which, in turn, hamper the potential of data-driven approaches to facilitate the
BER assessment process.
This study aims to investigate such observations using self-supervised deep learning approaches.
Specifically, we propose CLEAR , a self-supervised learning approach that employs Contrastive
1Published as a workshop paper at ”Tackling Climate Change with Machine Learning”, ICLR 2024
BER Levels Performance Measure Random Forest MLP
A1, A2, ..., E1, E2, F, GAccuracy (%) 62.8 69.5
Macro F1 (%) 63.1 63.9
A, B, C, D, EFGAccuracy (%) 76.1 88.6
Macro F1 (%) 75.8 88.9
Table 1: Performance Comparison of Models for BER Prediction with Different Level Granularity
(a) Five BER Levels
 (b) Fifteen BER Levels
Figure 1: 2D PCA Representations in the Latent Spaces of Scarf Models
Learning for Energy Assessment Rating evaluation, aiming to provide explainability and improve
the reliability of assessment data. Our approach’s training process relies entirely on building mea-
surement data, eliminating the need for assessment labels in training. This approach is preferable
for our investigation, because the modelling process doesn’t require assessment labels that are sub-
jective to individual assessors’ judgment. Moreover, our approach utilizes the SCARF model (Bahri
et al., 2021) for contrastive learning, providing an advantage in mitigating the potential presence of
data noise in modeling. In the modeling process, potential existing data corruption is leveraged to
facilitate the randomized feature corruption process. This, in turn, may even enhance the model’s
generalizability and result in better representations of buildings.
With a Irish building stocks dataset, we discovered evidence of clear inconsistencies in energy rat-
ings. The results demonstrate that buildings with similar feature values were given very different
rating levels for their BER assessments in this dataset. By revealing these inconsistencies in building
energy assessments, we identified significant faulty values in the building features. Consequently,
such data corruption may largely limit the potential of data-driven approaches for BER assessment.
This explains the observation that most of these approaches failed to achieve satisfactory predictions
when the rating was at a fine-grained level.
2 A PPROACH
Our approach CLEAR consists of two steps. First, we adopt self-supervised contrastive learning
via SCARF modelling (Bahri et al., 2021) to extract representations for buildings. For contrastive
learning, we generate positive pairs by randomly selecting and corrupting a subset of features. The
negative pairs are generated by contrasting them with other records in a batch. After training, we
extract the latent representation of each building with SCARF’s encoder. Second, we explore the
model’s latent space to examine the rating inconsistency based on latent representations. Specifi-
cally, we visualize latent representations via PCA compression in 2D or 3D space. Close proximity
of building representations in the latent space indicates similarities in their measured feature values.
We can visually identify rating inconsistencies by observing close representations with different
BER rating levels in the compressed PCA space. Once the reference buildings are located, we
proceed to calculate the nearest neighboring buildings in the derived high-dimensional latent space.
3 E XPERIMENTS
2Published as a workshop paper at ”Tackling Climate Change with Machine Learning”, ICLR 2024
(a) Buildings with BER ranging from A3 to D1
 (b) Buildings with BER ranging from A3 to C3
Figure 2: Inconsistent Ratings & Measurement Data Corruption
Identifying Rating Inconsistency in the Latent Space. For each building in the dataset1, we ex-
tract the latent representation in a 32-dimensional vector. Subsequently, we derive a 2D visualization
by compressing the latent representations further to two dimensions using PCA. Figure 1 displays
the 2D visualization of latent spaces for different BER granularities. As shown in Figure 1a, build-
ings with five coarse BER levels are spread across the latent space in sequence, aligned with the
order of BER levels. Those with the same BER level are predominantly clustered together. How-
ever, in Figure 1b, the distribution of latent representations reveals that buildings with adjacent BER
levels mix together, and the boundaries of fine-grained rating levels for each coarse level (e.g., ‘B1’,
‘B2’, ‘B3’ for coarse rating ‘B’) are not clear. This indicates inconsistent ratings for buildings with
similar feature values, especially evident in neighboring levels such as the group (‘B1’, ‘B2’, ‘B3’),
the group (‘C1’, ‘C2’, ‘C3’), and the group (‘D1’, ‘D2’). This observation aligns with the findings
in the confusion matrix shown in Figure 4 in the appendix for the MLP model.
Data Corruption in the Inconsistent BER Rating Records. The positioning of buildings’ repre-
sentations in the latent space reveals the distribution of buildings with different features. Proximity
in the latent space signifies similarity in features between two buildings. Consequently, identifying
similar buildings with different BER levels becomes evident in the latent space. For instance, Fig-
ure 2a showcases ten buildings resembling the reference building with BER level ‘A3’ (the first row
in the table). These buildings are derived by calculating the top ten closest representations in the
32-dimensional latent space. It is notable that these buildings share very similar feature values for U-
values of the wall, roof, door, window, and floor—features among those of top importance identified
by the decision tree algorithm. Additionally, their heating systems possess identical specifications.
However, their ratings range from ‘A3’ to ‘D1’ in the assessment. In addition, we also found out
substantial abnormal values in lighting and water storage highlight potential data corruption in their
measurements. As another example, Figure 2a presents another group of similar buildings, with a
specific focus on two buildings (2nd row and 5th row) that exhibit almost identical feature values
across all dimensions but are assessed differently as ‘C2’ and ‘A3’, respectively. The five buildings
at the bottom also display similar U-values in all aspects. For reference purpose, details of value
ranges for U-values can be presented in the box-plots (see Figure 3 in the appendix).
4 C ONCLUSION
In this study, we introduce a data-driven approach based on self-supervised contrastive learning to
identify inconsistencies in BER assessments. Using an Irish building stock dataset, our experiments
show the effectiveness of the proposed approach in detecting rating inconsistency as well as mea-
surement data corruption in the BER assessment process.
1The description of the dataset we use and our experiments configuration can be found in the appendix.
3Published as a workshop paper at ”Tackling Climate Change with Machine Learning”, ICLR 2024
ACKNOWLEDGMENTS
This work has received funding from the Science Foundation Ireland’s Future Digital Challenge
programme for the project entitled “Exploring realistic pathways to the decarbonization of buildings
in the urban context” under the grant No. 22/NCF/FD/10985.
REFERENCES
Usman Ali, Mohammad Haris Shamsi, Mark Bohacek, Karl Purcell, Cathal Hoare, Eleni Mangina,
and James O’Donnell. A data-driven approach for multi-scale gis-based building energy modeling
for analysis, planning and support decision making. Applied Energy , 279:115834, 2020.
Dara Bahri, Heinrich Jiang, Yi Tay, and Donald Metzler. Scarf: Self-supervised contrastive learning
using random feature corruption. In International Conference on Learning Representations , 2021.
Monica Billio, Michele Costola, Loriana Pelizzon, and Max Riedel. Buildings’ energy efficiency
and the probability of mortgage default: The dutch case. The Journal of Real Estate Finance and
Economics , 65(3):419–450, 2022.
Bryan Coyne and Eleanor Denny. Mind the energy performance gap: testing the accuracy of building
energy performance certificates in ireland. Energy efficiency , 14(6):57, 2021.
Lukas Dahlstr ¨om, Tor Brostr ¨om, and Joakim Wid ´en. Advancing urban building energy modelling
through new model components and applications: A review. Energy and Buildings , 266, 2022.
Hilary Egan, Clement Fouquet, and Chioke Harris. Machine learning for advanced building con-
struction. In ICLR 2023 Workshop on Tackling Climate Change with Machine Learning , 2023.
Emerald Energy and Esbensen Consulting Engineers. Energy efficiency regulations for new
dwellings and options for improvement.
A A PPENDIX
A.1 D ATA PREPROCESSING & F EATURE EXTRACTION
The data preprocessing consists of three steps. The first step is data cleaning. In this step, we use
the interquartile range (IQR) technique to identify and address outliers. We then group the data by
building type. For numerical features, missing values are imputed with the mean value specific to
each building type. For categorical features, we utilized the most frequent value in each category
for fill-ins. In the second step, we selected 40 features from the total 211 features in the original
dataset. The selection is based on the feature importance analysis with decision tree algorithm,
which identified the features with the most significant impact on energy ratings. During this pro-
cess, we excluded compound features that can be derived by the actual energy ratings, such as total
primary energy use for the dwelling and the dwelling’s carbon dioxide emissions (known as CO2
emissions). These 40 features are categorised into distinct groups, each describing different aspects
of a building. These categories include building envelope features (e.g., the area of the wall, roof,
and door), building fabric features (e.g., the U-values for the wall, roof, and door), characteristics of
the heating system (e.g., the main heating system efficiency), hot water-related attributes (e.g., water
storage volume), and spatial features (e.g., the county code). Lastly, in the third step, we applied
standard scalers to standardize the numerical features and one-hot encoders to transform categorical
features.
A.2 D ATASET
We use the Energy Performance Certificates (EPC) dataset2in this study, collected by the Sustain-
able Energy Authority of Ireland. This dataset contains 112,528 building assessment records. There
are 15 different BER levels in total, ranging from A1 as the highest level to G as the lowest level.
4Published as a workshop paper at ”Tackling Climate Change with Machine Learning”, ICLR 2024
Figure 3: Box-plots of U-Values
 Figure 4: Confusion Matrix for MLP Predictions
A.3 E XPERIMENTS CONFIGURATION
In our experiments, the SCARF model was trained for 15 epochs, with a batch size of 16 and a
learning rate of 0.001. The model used in the experiments consists of three MLP blocks, each with
a linear layer followed by ReLU activation. We set the dimension of the model’s encoder to be 32.
The proportion of randomly selected feature corruption is set to be 30%. We split the dataset into
train, validation, and test sets by the ratio 80%, 10%, and 10%.
2https://ndber.seai.ie/BERResearchTool/ber/search.aspx
5