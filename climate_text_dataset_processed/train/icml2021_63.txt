Wildﬁre Smoke Plume Segmentation Using
Geostationary Satellite Imagery
Jeff Wen1Marshall Burke1 2
Abstract
Wildﬁres have increased in frequency and sever-
ity over the past two decades, especially in the
Western United States. Beyond physical infras-
tructure damage caused by these wildﬁre events,
researchers have increasingly identiﬁed harmful
impacts of particulate matter generated by wildﬁre
smoke on respiratory, cardiovascular, and cogni-
tive health. This inference is difﬁcult due to the
spatial and temporal uncertainty regarding how
much particulate matter is speciﬁcally attributable
to wildﬁre smoke. One factor contributing to
this challenge is the reliance on manually drawn
smoke plume annotations, which are often noisy
representations limited to the United States. This
work uses deep convolutional neural networks to
segment smoke plumes from geostationary satel-
lite imagery. We compare the performance of
predicted plume segmentations versus the noisy
annotations using causal inference methods to
estimate the amount of variation each explains
in Environmental Protection Agency (EPA) mea-
sured surface level particulate matter <2.5µmin
diameter (PM 2:5).
1. Introduction
Since the early 1980s, scientists at the National Environ-
mental Satellite, Data and Information Service (NESDIS)
have explored the use of environmental satellites to detect
ﬁres while other researchers identiﬁed the potential of using
satellite imagery for wildﬁre smoke detection (McNamara
et al., 2004; Chung & Le, 1984; Svejkovsky, 1985). Al-
though NESDIS implemented algorithmic ﬁre detection
with the introduction of the Hazard Mapping System (HMS)
in 2002, wildﬁre smoke is still manually annotated by ana-
lysts using multi-frame animations of Geostationary Opera-
1Earth System Science, Stanford University, Stanford, Califor-
nia, USA2Deputy Director, Center on Food Security and the Envi-
ronment. Correspondence to: Jeff Wen <jlwen@stanford.edu >.
Tackling Climate Change with Machine Learning workshop at
ICML 2021 , Copyright 2021 by the author(s).tional Environmental Satellite (GOES) imagery (McNamara
et al., 2004; Ruminski et al., 2007). We combine the meth-
ods being developed in computer vision with geostationary
satellite imagery to identify wildﬁre smoke plumes in near
real-time, providing a method to improve analysis with more
accurate identiﬁcation of smoke and potentially extend anal-
ysis beyond the US.
Researchers have applied machine learning techniques to
related problems with mixed results. Speciﬁcally, Wan et
al. (2011) used unsupervised learning approaches to clus-
ter smoke in RGB color images using both a sharpening
and mixture model approach (Wan et al., 2011). Their ex-
ploratory results showed that it was possible to identify
smoke plumes by analyzing satellite imagery, but the un-
supervised approach limited opportunities to examine the
out-of-sample performance of the models. Wolters and
Dean present two approaches to smoke segmentation by
combining labeled hyperspectral images with logistic re-
gression models (Wolters & Dean, 2015; 2017). Their more
recent work illustrates the ability of auto-logistic regression
models to capture the spatial association between neigh-
boring pixels, which allows for smoothing over predictions.
However, while the results are positive, the model’s error
rates are still relatively high.
More recent literature illustrates the potential of using neu-
ral networks to estimate local pollution levels (Li et al.,
2017; Hong et al., 2019). Similarly, researchers have de-
signed custom neural network architectures for classifying
different classes of aerosol including smoke, but the classiﬁ-
cation does not isolate and segment plumes, which makes
it challenging to quantify the contribution wildﬁre smoke
versus other sources of aerosol in downstream analysis (Ba
et al., 2019). Filonenko et al. (2017) compares the perfor-
mance of different CNN architectures for smoke detection
but does not consider segmentation of plumes in the images
(Filonenko et al., 2017).
Neural networks have been successfully applied in varied
image segmentation tasks such as street-level scene labeling,
neural structure labeling in biomedical electron microscopy
images, road network segmentation, and aerial image seg-
mentation (Badrinarayanan et al., 2015; Ronneberger et al.,
2015; Mnih, 2013; Marmanis et al., 2016). These techniquesWildﬁre Smoke Plume Segmentation
have allowed applied researchers to automate previously
manual, time-intensive annotation tasks with models that
can be trained and adapted to different problems.
Ramasubramanian et al. (2019) use a convolutional neural
network architecture with 6 bands of GOES-16 imagery as
input and HMS satellite-derived annotations that were sub-
sequently corrected by experts as labels (Ramasubramanian
et al., 2019). Their model uses a single timestamp as input
and relies on subject matter experts to manually correct the
imperfect labels, which resulted in a dataset size of approxi-
mately 120 scenes containing smoke. The authors note that
their model performs smoke pixel classiﬁcation using the
pixel of interest in addition to an input neighborhood around
the pixel of interest. This approach results in predicted
boundaries that extend beyond the visible smoke boundary
and relies on a manually deﬁned input-pixel neighborhood
size. This along with the need for expert corrected labels
makes it difﬁcult to scale the approach to further analysis.
Larsen et al. (2021) utilize a fully convolutional network
(FCN) to identify wildﬁre smoke plumes from satellite ob-
servations obtained by the Himawari-8 geostationary satel-
lite situated over East Asia and Western Paciﬁc regions
(Larsen et al., 2021). They use a deterministic cloud-
masking algorithm to generate smoke versus non-smoke
pixel labels, which are then used to train the FCN. While the
approach is similar, the manually annotated smoke plumes
in our work may better capture variability in the visual rep-
resentation of smoke compared to a deterministic algorithm.
Other recent literature similarly use deep convolutional neu-
ral networks (CNNs) for identifying smoke plumes from
UA V and drone images as well as synthetically generated
smoke images (Frizzi et al., 2021; Yuan et al., 2019). These
works show promising performance but differ from the work
presented here as the aerial or synthetic images used provide
a side-view angle of smoke rather than a top-down view. Li
et al. (2018) and Zhu et al. (2020) both use 3D convo-
lution based CNN approaches to segment smoke plumes
from videos, but these video sequences also present a side-
viewing angle (Li et al., 2018; Zhu et al., 2020). While
the side-view images may provide higher resolution, their
availability can be inconsistent compared to geostationary
satellite observations. Given the temporal frequency of geo-
stationary satellite imagery, future work can explore using
video segmentation networks on sequences of geostationary
images.
In this work, we adapt CNNs to automatically identify wild-
ﬁre smoke plumes from satellite imagery. We use satellite
observations as input and HMS annotated smoke plumes
as the target labels to train our models. Because analysts
often generate these plume annotations using multiple hours
of satellite imagery, we investigate different methods for
improving training with these noisy labels. To validate our
Figure 1. First row: Model input, ground truth annotation label,
and model predicted segmentation after thresholding. Second row:
Additional input channel 07, channel 11, and MERRA-2.
models, we compare the predicted smoke plume segmenta-
tions against the HMS annotated smoke plumes on PM2.5
measurements from EPA monitoring stations. Better under-
standing of the spatial extent of wildﬁre smoke is especially
important in downstream research, such as in the environ-
mental economics literature, where accurate identiﬁcation
of smoke plumes could lead to better estimates of the causal
effect of smoke exposure.
2. Methodology
2.1. Data
The main imagery data used are satellite earth observations
captured by the Geostationary Operational Environmen-
tal Satellite (GOES-16) positioned over the eastern United
States. GOES-16 along with the west coast GOES-17 satel-
lite provide frequent (every 5 minutes for the Continental
US) multi-spectral measurements that are largely used for
weather modeling and storm tracking over the Atlantic and
Paciﬁc oceans respectively. Images are downloaded if there
are associated smoke plumes during 2018 from the HMS
annotations. In order to ensure that the imagery captures
radiance from the earth’s surface, images were limited to be-
tween 12PM and 11PM Coordinated Universal Time (UTC).
Furthermore, due to the large number of daily observations,
we limited training images to California and Nevada from
the 2018 wildﬁre season between May-December of 2018.
However, we perform testing on unseen data between May-
October of 2019 and 2020. For testing on external data
from 2019-2020, we download 3 images per day between
May-October. These multiple images allow us to identify
if multiple plumes are overhead on a given day. Given the
frequency of GOES imagery, in future work we hope to
increase the temporal resolution of the plumes.Wildﬁre Smoke Plume Segmentation
Table 1. Input channels
NAME WAVELENGTH TYPE PRIMARY USES
BLUE 0.47M VISIBLE AEROSOLS
RED 0.64M VISIBLE CLOUDS &ASH
VEGGIE 0.86M NEAR-IR V EGETATION
SHORTWAVE 3.9M IR F IRE HOTSPOTS
CLOUD -TOP 8.4M IR C LOUD -TOP
After collecting the smoke plume data and the associated
GOES-16 imagery from the Amazon Web Services (AWS)
NOAA open data repository, the raw imagery is reprojected
and a pseudo true-color composite is generated from the
red, blue, and ”green” bands using the SatPy package (Ras-
paud et al., 2021). Although the GOES-16 satellite carries
multiple sensors, it lacks a green band, which must be gen-
erated to create a true-color composite (Bah et al., 2018).
Additionally, the 07 and 11 channels are also included in
experiments as these near-infrared channels can be used for
ﬁre hotspot detection and cloud-top identiﬁcation (examples
in Figure 1). Each of the downloaded images was saved
as a 1200x1200 .geotiff image for a total of 615 im-
ages. These were then randomly cropped to generate up to
15 different 300x300 images where 60% of the crops had a
smoke plume to deal with class imbalance. As a result, there
were 6825 images which was split into 70% training, 15%
validation, and 15% testing. We further ensured that the
cropped images generated from the same base image could
only be in one set of data to reduce potential data leakage.
We pair the satellite imagery with smoke plume labels from
the HMS archives. While the labels extend back to 2006,
we use observations from the most recent generation of
geostationary satellite (GOES-16) launched in mid-2017
as this subset of data allows for more spectral bands to be
used in the analysis. Analysts often use multi-hour ani-
mations to draw the extent of the smoke plumes, which
presents challenges as the extent over time might not match
the boundaries of smoke plumes in a single image due to
wind or other meteorological factors (Brey et al., 2018).
Although the current labels are manually annotated from
satellite imagery, one goal of this research is to identify
the extent to which we can learn meaningful segmentations
from these imprecise labels. We attempt to improve train-
ing on noisy labels by providing additional signal using the
Modern-Era Retrospective analysis for Research and Ap-
plications, Version 2 (MERRA-2) aersol optical thickness
(AOT) measurements of particulate matter as an additional
input channel (Gelaro et al., 2017). The MERRA-2 data
combines multiple sources of aerosol optical density in-
formation mainly derived from the Moderate Resolution
Imaging Spectroradiometer (MODIS) instrument aboard
NASA’s Terra and Aqua satellites. We discuss 2 additional
methods to account for the noisy labels in the next section.In the rest of the paper, we will refer to the true-color image
as 1 band and the true-color, channel 07, and channel 11
combined as 3 bands. Lastly, 4 bands refers to using the
true-color, channel 07, channel 11, and the MERRA-2 in
the input.
2.2. Model
Our baseline experiments utilize an adapted U-Net neural
network architecture, originally designed for biomedical im-
age segmentation, to segment smoke plumes from a pseudo
true-color RGB image (Ronneberger et al., 2015). The
adapted network keeps the same number of layers in the
encoding and upsampling blocks but decreases the number
of convolutional ﬁlters. Furthermore, we replace the ReLU
activation function with PReLU activations for improved
stability in training. We also include multiple spectral bands
in subsequent experiments as these bands (shown in Table
1) provide contextual information of ﬁre hotspot location
and cloud-top phase in channel 07 and 11 respectively.
Across the model training, we use the Adam optimization
with a learning rate starting at =5e-5 and stepping down by
=0.1 every 9 epochs (Kingma & Ba, 2017). Each model
was trained for a total of 21 epochs using a batch size of 16.
We compared binary cross entropy (BCE) and mean abso-
lute error (MAE) losses during the training and validation
process. To track accuracy during training and validation,
we kept track of the average Dice coefﬁcient.
Dice Coefﬁcient =2jA\Bj
jAj+jBj(1)
This statistical similarity metric ﬁrst proposed by Lee Ray-
mond Dice in 1945 and shown in Equation 1 calculates 2
times the amount of overlapping pixels between the pre-
dicted (A) and ground truth mask ( B) divided by the total
number of pixels in both masks (Dice, 1945).
Additionally, we consider two methods for explicitly han-
dling noisy labels in the training process. Speciﬁcally, we
experiment with using mean absolute value of error (MAE)
loss, which has been shown to be tolerant to label noise, and
data sampling to specify that only low loss training samples
contribute to the gradient updates (Ghosh et al., 2017; Xue
et al., 2019). The loss sampling strategy allows the model to
run the prediction on a batch of inputs as usual, but before
calculating the average loss across samples, we identify the
training sample in the batch that produced the highest loss.
Then, we set the loss for that example to 0 so that it does not
contribute to making weight updates. As mentioned by Xue
et al., this approach assumes that as the model performance
improves, particularly noisy samples can result in high loss,
which can have large impact on the weight updates. This
training strategy mitigates the effect of these samples.Wildﬁre Smoke Plume Segmentation
Figure 2. The model predicted segmentation on the right more
closely matches the visible smoke in the input imagery compared
to the HMS annotated smoke plumes in the middle, which cover
most of California. The input on the left is a test image from
September 8th, 2019 that was not used for training or validation.
2.3. External validation
While the DICE coefﬁcient is used for validation during
training, we apply the models on unseen images from 2019
and 2020 to estimate the performance of these models com-
pared to the hand annotated HMS smoke plumes from the
same years. This allows us to test the models in a setting
most similar to downstream inference tasks where the mod-
els would be used to identify smoke plumes across a certain
time frame, then used for additional analysis.
Speciﬁcally, we leverage econometric tools for causally
identifying the contribution of wildﬁre smoke to changes
in ground level PM2.5 readings as measured by the EPA.
We use a quasi-experimental approach to exploit variation
in smoke and PM2.5 over time to estimate the effect of
identiﬁed wildﬁre smoke plumes on PM2.5 readings. We
use ﬁxed effect panel regressions (shown in Equation 2) with
station ﬁxed effects to account for time-invariant unobserved
effects such as the fact that different stations may have
unobserved characteristics correlated with smoke exposure.
We set the station PM2.5 reading as the dependent variable
and consider the HMS annotations as well as different model
predicted smoke plumes as the independent variable.
PM2.5 it=1Smoke it+i+it (2)
This approach allows us to compare performance even in
the presence of noisy annotation labels by measuring perfor-
mance against an external ground truth. In the above equa-
tion, theicaptures the EPA station ﬁxed effects, which
would handle time-invariant station level differences. The
Smoke itvariable is determined by the presence or absence
of smoke plumes overlapping an EPA station where the
smoke plumes come from either the HMS annotations or
model predicted segmentations.
To compare the HMS annotated smoke plumes against the
model predicted segmentations, we consider the adjusted R2
(Adj.R2 ) and within-adjusted R2 ( W Adj.R2 ) metrics.
TheAdj.R2 metric measures the total amount of variationTable 2. Model performance on validation set. Bold rows represent
the models that achieve the best validation DICE coefﬁcient for a
speciﬁc loss function. The asterisk denotes that the model weights
were updated after removing the highest loss sample per batch.
BANDS LOSS AVG. LOSS DICE
1 BCE 0.2535 0.0948
3 BCE 0.2236 0.1074
3* BCE 0.2313 0.1008
4 BCE 0.1884 0.1028
1 MAE 0.0986 0.2635
3 MAE 0.0986 0.2649
3* MAE 0.0986 0.2655
4 MAE 0.0986 0.2655
in PM2.5 measured at EPA monitoring stations explained
by the smoke plumes and the W Adj.R2 metric represents
the amount of variation in PM2.5 that is explained ”within”
the PM2.5 station unit by the different sources of smoke
data. This distinction is important and we prefer the ”within”
metric because it is a better indicator of ability to explain
variation in PM2.5 using the different smoke data as it only
considers remaining variation separate from time-invariant
unobserved station level differences.
3. Results
Our preliminary results show that qualitatively the BCE loss
models are able to learn to segment smoke from the input
imagery. The top right panel in Figure 1 shows the perfor-
mance of the model on a validation sample and the rightmost
panel in Figure 2 and Figure 3 show segmentations of the
model trained with BCE loss and 3 input channels on pre-
viously unseen test images. The segmentations appear to
more precisely locate the smoke in the input imagery on the
left compared to the annotations in the middle. Even though
there is cloud cover in Figure 1, the model is able to learn to
differentiate between the cloud cover and the smoke plumes.
Further quantitative results are shown in Table 2, where the
bolded rows represent the best validation DICE coefﬁcient
when using either of the loss functions during training. The
asterisk denotes that the model weights were updated only
after removing training samples that had the highest loss per
batch (Xue et al., 2019).
Although the MAE loss resulted in higher overall accuracy,
the qualitative results indicated that these models were pre-
dicting ”no-smoke” for nearly all pixels and were unable to
deal with the label imbalance in the images. Even with the
addition of the additional step to sample only low loss train-
ing samples, the model performance with MAE loss was
still qualitatively unable to identify smoke pixels compared
to the models trained with BCE loss.
When we evaluate the model performance on previouslyWildﬁre Smoke Plume Segmentation
Table 3. HMS annotated vs. model predicted plume performance
on EPA PM2.5 measurements. Different sources of smoke plumes
are validated against external PM2.5 measurements using a ﬁxed
effect panel regression approach to compare variation explained.
The asterisk denotes the loss sampling model results.
ADJ. R2 W A DJ. R2
ANNOTATIONS 0.2316 0.1946
1BAND 0.2707 0.2367
3BAND 0.2715 0.2374
4BAND 0.3038 0.2703
3BAND * 0.2987 0.2653
unseen data and compare the performance against the an-
notations, we see that the model predictions are able to ex-
plain more of the variation in surface level PM2.5 readings
regardless of model speciﬁcation (results shown in Table
3). The higher values for the model predicted smoke data
suggest that while these results are preliminary, the CNN
segmented smoke plumes may explain more of the changes
in PM2.5 compared to the hand annotated smoke plumes. It
is important to note that the hand annotations are meant to
capture visible smoke, while the particulate matter captured
at EPA stations might not be visible from satellite imagery.
Therefore, the models leveraging the MERRA-2 channel as
additional input might not be a fair comparison against the
hand annotations, which are mainly generated using visi-
ble imagery. However, as seen in Table 3, even the model
trained only using RGB as input appears to capture more of
the ”within” station variation than the hand annotations.
While in Table 2 the model trained by removing the in-
ﬂuence of the highest loss sample per batch appeared to
perform worse than the best 3-band model using BCE loss,
in the external validation (shown in Table 3), this model
was able to explain more of the total and within variation in
PM2.5. Furthermore, this model was nearly able to match
the performance of the 4-band model illustrating that ex-
plicitly ignoring high loss training samples when there are
noisy labels could be beneﬁcial for downstream tasks. This
might not be apparent from the validation accuracy metrics
because the validation dataset also includes noisy labels,
which make it challenging to gauge model performance.
This underscores the importance of clean validation data
especially in the presence of noisy labels.
4. Conclusion
As wildﬁres continue to worsen, it is increasingly important
to quantify the effects of wildﬁre smoke exposure on soci-
ety. In this work, we used an adapted U-Net architecture to
segment smoke plumes from geostationary satellite imagery
with the goal of improving our understanding of the spatial
extent of smoke. We further leveraged quasi-experimental
Figure 3. Additional examples show model predictions on unseen
test images with a lot of smoke in the ﬁrst row and no smoke in
the second row. Model input, ground truth annotation label, and
model predictions are displayed in both rows from left to right.
methods to compare the variation in EPA station PM2.5 mea-
surements that could be explained by either model predicted
segmentations or hand annotated plumes. While smoke
plumes have been manually annotated in the United States
since the 2000s, our results suggest that automated segmen-
tation methods are at least qualitatively comparable to the
annotated smoke plumes and explain more of the within
station PM2.5 variation in external validation. These early
results show the potential of adapting neural networks for
improving downstream inference even with noisy labels.
In future work, we look to focus on additional methods
to improve the model robustness to noisy labels. We also
hope to extend and develop these methods to identify smoke
across the globe and over time to better inform the impacts
of wildﬁres.
Software and Data
The Geostationary Operational Environmental Satel-
lite (GOES) data used in this work is available
for download at https://registry.opendata.
aws/noaa-goes . Hazard Mapping System smoke
data is available at https://www.ospo.noaa.gov/
Products/land . The models were developed using Py-
Torch version 1.7.1 and the ﬁxed effects estimators were
estimated using the Fixest R package version 0.8.4 (Paszke
et al., 2019; Berg ´e, 2018). The models and data will be
made available at the time of publication.
Acknowledgements
We thank reviewers whose comments and suggestions
helped clarify and improve this manuscript. We also thank
the Sustainability and Artiﬁcial Intelligence Lab for discus-
sions.Wildﬁre Smoke Plume Segmentation
References
Ba, R., Chen, C., Yuan, J., Song, W., and Lo, S. Smo-
kenet: Satellite smoke scene detection using convo-
lutional neural network with spatial and channel-wise
attention. Remote Sensing , 11:1702, 07 2019. doi:
10.3390/rs11141702.
Badrinarayanan, V ., Kendall, A., and Cipolla, R. Segnet:
A deep convolutional encoder-decoder architecture for
image segmentation. CoRR , abs/1511.00561, 2015. URL
http://arxiv.org/abs/1511.00561 .
Bah, M., Gunshor, M., and Schmit, T. Generation of goes-
16 true color imagery without a green band. Earth and
Space Science , 5(9):549–558, 2018.
Berg ´e, L. Efﬁcient estimation of maximum likelihood mod-
els with multiple ﬁxed-effects: the R package FENmlm.
CREA Discussion Papers , (13), 2018.
Brey, S. J., Ruminski, M., Atwood, S. A., and Fischer,
E. V . Connecting smoke plumes to sources using haz-
ard mapping system (hms) smoke and ﬁre location
data over north america. Atmospheric Chemistry and
Physics , 18(3):1745–1761, 2018. doi: 10.5194/acp-
18-1745-2018. URL https://www.atmos-chem-
phys.net/18/1745/2018/ .
Chung, Y .-S. and Le, H. Detection of forest-ﬁre smoke
plumes by satellite imagery. Atmospheric Environment
(1967) , 18(10):2143–2151, 1984.
Dice, L. R. Measures of the amount of ecologic association
between species. Ecology , 26(3):297–302, 1945.
Filonenko, A., Kurnianggoro, L., and Jo, K.-H. Comparative
study of modern convolutional neural networks for smoke
detection on image data. In 2017 10th International
Conference on Human System Interactions (HSI) , pp. 64–
68. IEEE, 2017.
Frizzi, S., Bouchouicha, M., Ginoux, J.-M., Moreau, E., and
Sayadi, M. Convolutional neural network for smoke and
ﬁre semantic segmentation. IET Image Processing , 15(3):
634–647, 2021.
Gelaro, R., McCarty, W., Suarez, M. J., Todling, R.,
Molod, A., Takacs, L., Randles, C. A., Darmenov, A.,
Bosilovich, M. G., Reichle, R., Wargan, K., Coy, L.,
Cullather, R., Draper, C., Akella, S., Buchard, V ., Conaty,
A., da Silva, A. M., Gu, W., Kim, G.-K., Koster, R.,
Lucchesi, R., Merkova, D., Nielsen, J. E., Partyka, G.,
Pawson, S., Putman, W., Rienecker, M., Schubert, S. D.,
Sienkiewicz, M., and Zhao, B. The modern-era retro-
spective analysis for research and applications, version
2 (merra-2). Journal of Climate , 30(14):5419 – 5454,
2017. doi: 10.1175/JCLI-D-16-0758.1. URL https://journals.ametsoc.org/view/journals/
clim/30/14/jcli-d-16-0758.1.xml .
Ghosh, A., Kumar, H., and Sastry, P. S. Robust loss func-
tions under label noise for deep neural networks, 2017.
Hong, K. Y ., Pinheiro, P. O., and Weichenthal, S. Predicting
global variations in outdoor pm2.5 concentrations using
satellite images and deep convolutional neural networks,
2019.
Kingma, D. P. and Ba, J. Adam: A method for stochastic
optimization, 2017.
Larsen, A., Hanigan, I., Reich, B. J., Qin, Y ., Cope, M., Mor-
gan, G., and Rappold, A. G. A deep learning approach
to identify smoke plumes in satellite imagery in near-real
time for health risk communication. Journal of exposure
science & environmental epidemiology , 31(1):170–176,
2021.
Li, T., Shen, H., Yuan, Q., Zhang, X., and Zhang,
L. Estimating ground-level pm2.5 by fusing satellite
and station observations: A geo-intelligent deep learn-
ing approach. Geophysical Research Letters , 44(23):
11,985–11,993, Dec 2017. ISSN 0094-8276. doi:
10.1002/2017gl075710. URL http://dx.doi.org/
10.1002/2017GL075710 .
Li, X., Chen, Z., Wu, Q. J., and Liu, C. 3d parallel fully con-
volutional networks for real-time video wildﬁre smoke
detection. IEEE Transactions on Circuits and Systems
for Video Technology , 30(1):89–103, 2018.
Marmanis, D., Wegner, J. D., Galliani, S., Schindler, K.,
Datcu, M., and Stilla, U. Semantic segmentation of aerial
images with an ensemble of cnss. ISPRS Annals of the
Photogrammetry, Remote Sensing and Spatial Informa-
tion Sciences, 2016 , 3:473–480, 2016.
McNamara, D., Stephens, G., Ruminski, M., and Kasheta, T.
The hazard mapping system (hms)–noaa multi-sensor ﬁre
and smoke detection program using environmental satel-
lites. In 13th Conf. Satellite Meteorology and Oceanog-
raphy , 2004.
Mnih, V . Machine Learning for Aerial Image Labeling . PhD
thesis, University of Toronto, 2013.
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury,
J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N.,
Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito,
Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner,
B., Fang, L., Bai, J., and Chintala, S. Pytorch: An
imperative style, high-performance deep learning
library. In Wallach, H., Larochelle, H., Beygelzimer, A.,
d'Alch ´e-Buc, F., Fox, E., and Garnett, R. (eds.), AdvancesWildﬁre Smoke Plume Segmentation
in Neural Information Processing Systems 32 , pp. 8024–
8035. Curran Associates, Inc., 2019. URL http://
papers.neurips.cc/paper/9015-pytorch-
an-imperative-style-high-performance-
deep-learning-library.pdf .
Ramasubramanian, M., Kaulfus, A., Maskey, M., Ra-
machandran, R., Gurung, I., Freitag, B., and Christopher,
S. Pixel level smoke detection model with deep neural
network. In Image and Signal Processing for Remote
Sensing XXV , volume 11155, pp. 1115515. International
Society for Optics and Photonics, 2019.
Raspaud, M., Hoese, D., Lahtinen, P., Finkensieper, S., Holl,
G., Dybbroe, A., Proud, S., Meraner, A., Zhang, X., Joro,
S., joleenf, Roberts, W., Ørum Rasmussen, L., M ´endez, J.
H. B., Zhu, Y ., Daruwala, R., strandgren, BENR0, Jasmin,
T., Barnie, T., Sigurosson, E., R.K.Garcia, Leppelt, T.,
ColinDuff, Egede, U., LTMeyer, Itkin, M., Goodson,
R., jkotro, and peters77. pytroll/satpy: Version 0.27.0
(2021/03/26), March 2021. URL https://doi.org/
10.5281/zenodo.4638572 .
Ronneberger, O., Fischer, P., and Brox, T. U-net: Con-
volutional networks for biomedical image segmentation.
CoRR , abs/1505.04597, 2015. URL http://arxiv.
org/abs/1505.04597 .
Ruminski, M., Kondragunta, S., Draxler, R., and Rolph,
G. Use of environmental satellite imagery for smoke
depiction and transport model initialization. In 16th An-
nual International Emission Inventory Conf.: Emission
Inventories—Integration, Analysis, and Communications ,
2007.
Svejkovsky, J. Santa ana airﬂow observed from wildﬁre
smoke patterns in satellite imagery. Monthly Weather
Review , 113(5):902–906, 1985.
Wan, V ., Braun, W. J., Dean, C., and Henderson, S. B. A
comparison of classiﬁcation algorithms for the identiﬁ-
cation of smoke plumes from satellite images. Statisti-
cal Methods in Medical Research , 20(2):131–156, 2011.
doi: 10.1177/0962280210372454. URL https://
doi.org/10.1177/0962280210372454 . PMID:
20889573.
Wolters, M. A. and Dean, C. Issues in the identiﬁcation of
smoke in hyperspectral satellite imagery — a machine
learning approach. 2015.
Wolters, M. A. and Dean, C. Classiﬁcation of large-scale re-
mote sensing images for automatic identiﬁcation of health
hazards. Statistics in Biosciences , 9(2):622–645, Dec
2017. ISSN 1867-1772. doi: 10.1007/s12561-016-9185-
5. URL https://doi.org/10.1007/s12561-
016-9185-5 .Xue, C., Dou, Q., Shi, X., Chen, H., and Heng, P. A. Robust
learning at noisy labeled medical images: Applied to skin
lesion classiﬁcation, 2019.
Yuan, F., Zhang, L., Xia, X., Wan, B., Huang, Q., and Li,
X. Deep smoke segmentation. Neurocomputing , 357:
248–260, 2019.
Zhu, G., Chen, Z., Liu, C., Rong, X., and He, W. 3d
video semantic segmentation for wildﬁre smoke. Machine
Vision and Applications , 31(6):1–10, 2020.