Predicting Adsorption Energies for Catalyst Screening
with Transfer Learning Using Crystal Hamiltonian
Graph Neural Network
Angelina Chen1, Hui Zheng2, and Paula Harder3
1Lawrence Berkeley National Laboratory
2Lawrence Berkeley National Laboratory
3Mila
Abstract
As the world moves towards a clean energy future to mitigate the risks of climate
change, the discovery of new catalyst materials plays a significant role in enabling
the sustainable production and transformation of energy [ 2]. The development
and verification of fast, accurate, and efficient artificial intelligence and machine
learning techniques is critical to shortening time-intensive calculations, reducing
costs, and improving computational feasibility. We propose applying the Crystal
Hamiltonian Graph Neural Network (CHGNet) on the OC20 dataset in order to
iteratively perform structure-to-energy and forces calculations and identify the
lowest energy across relaxed structures for a given adsorbate-surface combination.
CHGNet’s predictions will be compared and benchmarked to corresponding values
calculated by density functional theory (DFT) [ 7] and other models to determine
its efficacy.
1 Introduction
The discovery of novel catalysts plays a pivotal role in facilitating efficient and carbon-neutral methods
for energy storage and conversion [ 3,10]. Around 90% of global chemical processes use catalysts for
efficient production [ 1], making catalyst development vital for environmental sustainability. However,
as the demand for more efficient and sustainable catalysts grows, the vast number of potential catalyst
candidates renders experimental testing impractical.
Traditional methods of catalyst synthesis and testing to fit specific parameters become inefficient and
costly [ 11]. Computational screening methods have become critical to the design process. However,
modeling the surface reaction network of catalysts is complex and expensive. Common simulation
tools like density functional theory (DFT) [ 7] are examples where computational cost is a limiting
factor in discovering new catalysts [6].
Applying machine learning to molecular simulations provides an efficient way to model complicated
configurations of surface adsorptions. An essential parameter in this screening process is the adsorp-
tion energy [ 12], which denotes the strength of attachment between an adsorbate and the surface of a
catalyst. The rate of a chemical reaction, a parameter of high practical importance, correlates with
absorption energies.
Accurate prediction of the global minimum energy of adsorption holds the potential to estimate the
catalyst’s influence on the overall reaction rate. This is a key criterion for evaluating candidate catalyst
materials and addressing global energy demands. We propose using the Crystal Hamiltonian Graph
Neural Network (CHGNet) to predict the global minimum adsorption energy given the large-scale
catalyst dataset OC20.
Tackling Climate Change with Machine Learning workshop at NeurIPS 2023.2 Background and Previous Work
Deng et al. [ 3] trained a machine learning interatomic potential (MLP) called the Crystal Hamiltonian
Graph Neural Network (CHGNet), which is a universal potential and applicable for a wide range of
compositions consisting of 89 elements from the periodic table.
Since the simulation of large-scale systems with complicated electron interactions remains a signif-
icant hurdle in the realm of atomistic material modeling, they used energies, forces, stresses, and
magnetic moments from the Materials Project [ 4] Trajectory Dataset, a dataset containing over a
decade’s worth of density functional theory static and relaxation trajectories of about 1.5 million
inorganic structures, to pre-train CHGNet. It has been demonstrated to be the best universal MLP to
predict the formation energy for solid-state materials [ 9]. Although they demonstrate the application
of CHGNet to several solid-state materials, there is no research exploring the performance of CHGNet
on the complex surfaces with different adsorbates as of writing.
We will assess the energy, force errors, and adsorption configures of CHGNet when applying the
pre-trained model on the Open Catalyst 2020 (OC20) dataset, which covers a larger structure and
chemistry space and various surfaces and different adsorbates. Furthermore, we will add the OC20
dataset and fine-tune or retrain a new version of CHGNet to extend the capability of CHGNet for
systems that include surfaces and adsorbates.
3 Approach
In this work, we will first be benchmarking the performance of CHGNet on the pre-relaxed dataset.
We will then assess the mean absolute error (MAE) [ 8] in calculating the adsorption energy using the
static calculation of the off-the-shelf CHGNet model. The performance of CHGNet, in calculating
the adsorption energy using relaxations with different initial structures, will be evaluated based on
two cases: unrelaxed structures and pre-relaxed structures from the OC20 data.
After initial relaxations, we will assess the forces error via the comparison of the forces outputs from
CHGNet and the forces from the DFT outputs given the same structure. The predicted structure
configurations from CHGNet relaxation will be compared to the DFT results. After calculating the
computational success rate using the off-the-shelf (pre-trained) CHGNet model, we will check the
convergence and compare the values to the established DFT or highest-performing OC20 model
values. If the convergence metric fails and the MAEs for energy and forces are larger than the best
model, we will fine-tune or retrain the CHGNet model by incorporating the OC20 dataset. We will
repeat this approach iteratively until the MAEs for energies and forces are lower than the current
state-of-the-art models, and the convergence criterion is met.
Based on the structure predictions, we will also ensure that the predicted structures do not violate any
physical constraints, including desorption when the adsorbate fails to bind to the surface, dissociation
of the adsorbate molecule into different molecules or atoms, and surface mismatch between the final
prediction and the corresponding relaxed clean surface. We will use the highest-performing model,
based on fine-tuning, retraining, and casework, to calculate the global energy minimum.
3.1 Dataset
The OC20 dataset consists of over 1.2 million DFT relaxations of molecular adsorptions on sur-
faces. In total, 82 different adsorbates were considered based on renewable energy applications,
including small adsorbates, C1/C2compounds, and N/O -containing intermediates. Pre-relaxations
were performed by the Open Catalyst Project [ 2,5] based on randomly sampled low-Miller-index
facets of stable materials from the Materials Project [ 4]. Additionally, OC20 provides single point
DFT calculations for the randomly perturbed structures, which we will use to assess CHGNet’s
performance.
4 Conclusions and Impact
The main contributions of this work would be (1) a fine-tuned and benchmarked machine learning
(ML) potential to better predict adsorption energy, and (2) a workflow for benchmarking pre-trained
2Figure 1: (a) Visual representation of a structure using CHGNet, (b) Sample graph of relaxation
using CHGNet
Figure 2: Our proposed workflow for benchmarking MLPs on large datasets and evaluating their
validity in force, energy, and structure predictions.
ML potentials on large datasets to determine the global minimum binding energy of an adsorbate and
catalyst surface.
As a computationally efficient method for molecular simulations compared to conventional simulation
tools like DFT, ML can be used to reduce both cost and calculation time across the analysis of the
vast number of potential catalyst materials. A workflow to benchmark existing ML potentials on
large datasets such as OC20, therefore, has high practical utility for research and model development
since it assists in the large-scale exploration of catalyst materials as current state-of-the-art models
become more accurate.
Improving adsorption energy predictions leads to more practical catalyst screening applications,
which is key to enabling new reactions and advancements in renewable energy processes. From
generating electricity through fuel cells to fuel generation through renewable sources, many real-
world examples of climate change and energy scarcity include catalysis. Thus, the discovery of new
catalysts or optimization of existing catalysts drives more energy-efficient and carbon-neutral means
for energy storage and conversion.
3References
[1]J. N. Armor. A history of industrial catalysis. Catalysis Today , 163(1):3–9, 2011. Special issue
on Industrial Catalysis.
[2]L. Chanussot, A. Das, S. Goyal, T. Lavril, M. Shuaibi, M. Riviere, K. Tran, J. Heras-Domingo,
C. Ho, W. Hu, A. Palizhati, A. Sriram, B. Wood, J. Yoon, D. Parikh, C. L. Zitnick, and
Z. Ulissi. Open catalyst 2020 (OC20) dataset and community challenges. ACS Catalysis ,
11(10):6059–6072, may 2021.
[3]B. Deng, P. Zhong, K. Jun, J. Riebesell, K. Han, C. J. Bartel, and G. Ceder. CHGNet as a
pretrained universal neural network potential for charge-informed atomistic modelling. Nat
Mach Intell , 5(9):1031–1041, Sept. 2023.
[4]A. Jain, S. P. Ong, G. Hautier, W. Chen, W. D. Richards, S. Dacek, S. Cholia, D. Gunter,
D. Skinner, G. Ceder, and K. A. Persson. Commentary: The Materials Project: A materials
genome approach to accelerating materials innovation. APL Materials , 1(1):011002, July 2013.
[5]J. Lan*, A. Palizhati*, M. Shuaibi*, B. M. Wood*, B. Wander, A. Das, M. Uyttendaele, C. L.
Zitnick, and Z. W. Ulissi. Adsorbml: Accelerating adsorption energy calculations with machine
learning. arXiv preprint arXiv:2211.16486 , 2022.
[6]A. J. Medford, M. R. Kunz, S. M. Ewing, T. Borders, and R. Fushimi. Extracting knowledge
from data through catalysis informatics. ACS Catalysis , 8(8):7403–7429, 2018.
[7]J. K. Nørskov, F. Studt, F. Abild-Pedersen, and T. Bligaard. Fundamental concepts in heteroge-
neous catalysis . John Wiley & Sons, 2014.
[8]J. Qi, J. Du, S. M. Siniscalchi, X. Ma, and C.-H. Lee. On mean absolute error for deep neural
network based vector-to-vector regression. IEEE Signal Processing Letters , 27:1485–1489,
2020.
[9]J. Riebesell, R. E. A. Goodall, A. Jain, P. Benner, K. A. Persson, and A. A. Lee. Matbench
Discovery – An evaluation framework for machine learning crystal stability prediction, Aug.
2023.
[10] Z. Seh, J. Kibsgaard, C. Dickens, I. Chorkendorff, J. Nørskov, and T. Jaramillo. Combining
theory and experiment in electrocatalysis: Insights into materials design. Science , 355(6321),
2017.
[11] H. W. Turner, A. F. V olpe, and W. Weinberg. High-throughput heterogeneous catalyst research.
Surface Science , 603(10):1763–1769, 2009. Special Issue of Surface Science dedicated to Prof.
Dr. Dr. h.c. mult. Gerhard Ertl, Nobel-Laureate in Chemistry 2007.
[12] Y . Wang, W. Qiu, E. Song, F. Gu, Z. Zheng, X. Zhao, Y . Zhao, J. Liu, and W. Zhang. Adsorption-
energy-based activity descriptors for electrocatalysts in energy storage applications. National
Science Review , 5(3):327–341, 09 2017.
4