DeepWaste: Applying Deep Learning to Waste
ClassiÔ¨Åcation for a Sustainable Planet
Yash Narayan
The Nueva School
yasnara@nuevaschool.org
Abstract
Accurate waste disposal, at the point of disposal, is crucial to Ô¨Åghting climate
change. When materials that could be recycled or composted get diverted into
landÔ¨Ålls, they cause the emission of potent greenhouse gases such as methane.
Current attempts to reduce erroneous waste disposal are expensive, inaccurate, and
confusing. In this work, we propose DeepWaste , an easy-to-use mobile app, that
utilizes highly optimized deep learning techniques to provide users instantaneous
waste classiÔ¨Åcation into trash, recycling, and compost. We experiment with several
convolution neural network architectures to detect and classify waste items. Our
best model, a deep learning residual neural network with 50 layers, achieves an
average precision of 0.881 on the test set. We demonstrate the performance and
efÔ¨Åciency of our app on a set of real-world images.
1 Introduction
Every year, the world generates over 2 billion tons of solid waste [1]. In the U.S., even though 75%
of this waste is capable of being recycled, only 34% is actually recycled [2]. Further, 91% of plastic
isn‚Äôt recycled [3] and only about 5% of food and other organic waste is composted [4]. This waste
generates over 1.5 billion metric tons of CO 2equivalent greenhouse gases [1], contributing nearly as
much to climate change as all the cars on the U.S. roads.
Despite massive investment to educate the public about accurate waste disposal, efforts so far have
been only moderately successful. People are often confused by what they can recycle, or compost.
Signs and boards found ubiquitously near waste bins are difÔ¨Åcult to understand and are often
incomplete. Furthermore, disposal of waste varies based on the local recycling facilities‚Äô capabilities,
and therefore rules for disposal are subject to change on a county-by-county basis.
Errors in waste disposal constitute not only missed opportunities to recycle or compost, but also lead
to the contamination of recycling and compost bins. Often, an entire bin can end up at a landÔ¨Åll due
to a single error leading to contamination. Data from the National Waste and Recycling Association
shows that human confusion in the identiÔ¨Åcation and correct disposal of waste into our waste bins
results in nearly 25% of recyclables getting contaminated [5], diverting materials that could be
recycled into our landÔ¨Åll. When a recyclable or compostable material ends up in the landÔ¨Åll, it
releases methane which is several times more potent than CO 2in contributing to global warming.
Clearly, current ways to inform the public have not been working very well.
In this work, we leverage the recent improvements of convolution neural networks (CNNs) for
image-recognition tasks [6] and the availability of increased computational power on modern-day
cell phones, to provide a novel approach for waste identiÔ¨Åcation that is fast, low-cost, and accurate
for anyone, anywhere. We present DeepWaste, the Ô¨Årst mobile app targeted at the problem of
erroneous waste disposal, at the point of disposal, through deep learning. We construct from scratch
a fully-annotated dataset of more than 1200 waste items that is trained to achieve our best performing
model with an average precision of 0.881 on the test set.
Tackling Climate Change with Machine Learning workshop at NeurIPS 2020.2 Previous Work
The topic of waste classiÔ¨Åcation has begun garnering some interest recently in research, but the
attempts reported across literature to solve this problem have suffered from low accuracy (ranging
from 22% to low 70%) [7], [8], or a network size that is too big for real-time application [9].
Further, most of the previous attempts to mitigate the aforementioned problem of erroneous disposal
envisaged deployment within a ‚Äúsmart bin‚Äù or the use of a commercial and industrial grade binning
system within a recycling plant [10], [11], [12], requiring expensive hardware that costs thousands
of dollars. The high cost of these solutions has so far been a deterrent to their large-scale adoption.
Our approach is novel, as it allows the use of widely available mobile phones, and therefore has the
potential of large-scale adoption at little or no cost.
Finally, none of the previous approaches have targeted compost classiÔ¨Åcation. This is a signiÔ¨Åcant
problem because when compostable material such as food scraps and green waste gets into a landÔ¨Åll,
it is generally compacted down and covered. This removes the oxygen and causes it to break down
in an anaerobic process. Eventually, this releases methane, a greenhouse gas that is 25 times more
potent than carbon dioxide in warming the earth over a 100-year timescale (and more than 80 times
on a 20-year timescale) [13]. Our work is the Ô¨Årst work in literature, to the best of our knowledge,
that considers not only recycling but also compost as a new category for classiÔ¨Åcation.
3 Methods
Classifying waste using machine learning is challenging for three reasons. First, whether a waste
is recyclable or compostable or not depends on the properties of the material which can be hard to
detect simply from the image. Second, the material can come in any shape such as a broken bottle, or
a crumpled can, or deformed plastic; any machine learning technique needs to deal with this variation.
Third, material that is recyclable depends on the capabilities of the local recycling center, so the app
needs to take this geographical variable into account.
Since there was no public dataset available, to accomplish this task, a dataset was constructed from
scratch by contacting various recycling centers and collecting images from the local neighborhood.
Towards this goal, we developed the ability for user generated content so that users can easily take
a picture, annotate it, and upload it to the cloud for further training. In total, we manually collect
1218 images items at various lightings and angles, with 396 images containing compostable item(s),
427 images containing recyclable item(s), and 395 images containing landÔ¨Åll item(s). Utilizing this
data, we experiment with several state-of-the-art convolution neural network methods, including
InceptionV3 [14], Inception ResnetV2 [15], Resnet 50 [16], Mobile Net [17], and PNAS Net [18].
All CNNs used were initialized with weights pre-trained on ImageNet.
During training, each input image was rotated with an angle randomly selected among 0, 90, 180,
and 270and also randomly Ô¨Çipped, cropped, and blurred for data augmentation. Each method
outputs a conÔ¨Ådence for an inputted image. Hyper parameters speciÔ¨Åc to each method are set to the
best values described in the original work.
4 Results
Out of the various CNNs benchmarked on the dataset, Resnet50 showed the best accuracy and
convergence on the test set in terms of average precision and thus was optimized and subsequently
deployed inside of a mobile app using Apple CoreML. Core ML optimizes on-device performance
by leveraging the CPU, GPU, and Neural Engine while minimizing its memory footprint and power
consumption. The DeepWaste model is running strictly on the user‚Äôs mobile device, therefore
removing the need for internet connection and sharing data. The benchmarked models and their
respective average precision scores on the test set can be found in Table 1.
Figure 1 shows the DeepWaste app classifying commonly confused items in real-life. A user can
simply point their phone camera to any piece of waste and get instantaneous feedback, with an
average prediction time of around 100ms. DeepWaste is able to correctly identify items with high
accuracy, even when the shape has been deformed such as a crushed soda can, orange peels, an apple
core, crumpled paper, and a plastic bag. Note that the plastic bag in Figure 1 is classiÔ¨Åed as trash
2Accuracy Inception_V3 Inception_ResnetV2 Resnet_50 MobileNet PNAS_net
Trash 0.771 0.773 0.761 0.751 0.722
Recycle 0.891 0.783 0.924 0.949 0.864
Compost 0.806 0.806 0.882 0.873 0.841
Overall 0.84 0.82 0.881 0.842 0.852
Table 1: CNN performance on test set
Figure 1: DeepWaste app classiÔ¨Åcation output
because plastic bags, Ô¨Ålms, and wraps cannot be recycled in your curbside recycling bin; they must
be dropped-off to a special retail stores that can collect plastic grocery bags for recycling. Throwing
this plastic bag into the recycling bin has the potential of contaminating the entire bin.
5 Conclusion and Future Work
In this work, we propose a mobile application that uses highly-optimized deep learning techniques to
provide users instantaneous waste classiÔ¨Åcation, enabling them to accurately dispose of waste into
recycling, compost, or trash. Currently, the mobile app is available to beta users for testing. In the
near future, we aim to construct a larger data set by releasing the app to the general public so that
more users can add to the growing DeepWaste database. We have started a conversation with local
recycling companies to explore if they would be interested in promoting the adoption of DeepWaste
to their customers. The initial feedback is encouraging and we hope to continue this conversation and
start a trial soon. We hope that our work can reduce the amount of incorrect waste disposal, and over
time raise more awareness around the environmental impacts of waste on our climate. If DeepWaste
can even reduce erroneous waste disposal by 1%, it will be equivalent to removing over 6.5 million
gasoline-burning passenger vehicles from the road, demonstrating the potential for machine learning
techniques to tackle challenging problems related to climate change.
6 Acknowledgements
I would like to thank Dr. Tanja Srebotnjak (The Nueva School), Professor Ram Rajagopal (Stanford
University), Zhecheng Wang (Stanford University), Divyansh Jha (Esri), and Dr. Miranda Gorman
(Project Drawdown) for their valuable feedback, guidance, and support.
3References
[1] S. Kazam, L. Yao, P. Bhada-Tata, F. Van Woerden, ‚ÄúWhat a Waste 2.0: A Global Snapshot of Solid Waste
Management to 2050,‚Äù World Bank, pp. 3-5, 2018.
[2] United States Environmental Protection Agency (EPA), ‚ÄúNational Overview: Facts and Figures on Mate-
rials, Wastes and Recycling,‚Äù 2016. URL https://www.epa.gov/facts-and-Ô¨Ågures-about-materials-waste-and-
recycling/national-overview-facts-and-Ô¨Ågures-materials
[3] L. Parker, ‚ÄúA Whopping 91 Percent of Plastic Isn‚Äôt Recycled,‚Äù National Geographic, 2018. URL
https://www.nationalgeographic.org/article/whopping-91-percent-plastic-isnt-recycled/
[4] United States Environmental Protection Agency (EPA), ‚ÄúFood: Material-SpeciÔ¨Åc Data,‚Äù 2016. URL
https://www.epa.gov/facts-and-Ô¨Ågures-about-materials-waste-and-recycling/food-material-speciÔ¨Åc-data
[5] M. Koerth, ‚ÄúThe Era Of Easy Recycling May Be Coming To An End,‚Äù FiveThirtyEight, 2019. URL
https://Ô¨Åvethirtyeight.com/features/the-era-of-easy-recycling-may-be-coming-to-an-end/
[6] Y . LeCun, Y . Bengio, and G. Hinton, ‚ÄúDeep learning,‚Äù Nature, V ol. 521, pp. 436, 2015.
[7] G. Thung, M. Yang, "ClassiÔ¨Åcation of Trash for Recyclability Status," Stanford CS229 Project Report , 2016.
[8] O. Awe, R. Mengitsu, V . Sreedhar, "Final Report: Smart Trash Net: Waste Localization and ClassiÔ¨Åcation,"
Stanford CS229 Project Report , 2016.
[9] C. Bircano Àòglu, M. Atay, F. Be¬∏ ser, √ñ. Gen√ß and M. A. Kƒ±zrak, "RecycleNet: Intelligent Waste Sorting Using
Deep Neural Networks," Innovations in Intelligent Systems and Applications (INISTA) , Thessaloniki, pp. 1-7,
doi: 10.1109/INISTA.2018.8466276, 2018.
[10] I. Salimi, B. S. Bayu Dewantara, I. K. Wibowo, "Visual-based trash detection and classiÔ¨Åcation system for
smart trash bin robot," International Electronics Symposium on Knowledge Creation and Intelligent Computing
(IES-KCIC) , Bali, Indonesia, pp. 378-383, doi: 10.1109/KCIC.2018.8628499 2018.
[11] D. Vinodha, J. Sangeetha, B. Cynthia Sherin, M. Renukadevi, "Smart Garbage System with Garbage
Separation Using Object Detection," International Journal of Research in Engineering, Science and Management
2020.
[12] D. Ziouzios, M. Dasygenis, "A Smart Recycling Bin for Waste ClassiÔ¨Åcation," Panhellenic Conference on
Electronics Telecommunications (PACET) , pp. 1-4, doi: 10.1109/PACET48583.2019.8956270, 2019.
[13] United States Environmental Protection Agency (EPA), "Overview of Greenhouse Gases," 2018. URL
https://www.epa.gov/ghgemissions/overview-greenhouse-gases
[14] C. Szegedy, V . Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna, "Rethinking the inception architecture for computer
vision," in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2818-2826,
2016.
[15] C. Szegedy, S. Ioffe, V . Vanhoucke, A.Alemi, "Inception-v4, inception-resnet and the impact of residual
connections on learning," arXiv preprint arXiv:1602.07261, 2016.
[16] K. He, X. Zhang, S. Ren, J. Sun, "Deep residual learning for image recognition," Proceedings of the IEEE
conference on computer vision and pattern recognition , pp. 770-778, 2016.
[17] A. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. Andreetto, Adam, H, "Mobilenets:
EfÔ¨Åcient convolutional neural networks for mobile vision applications," arXiv preprint arXiv:1704.04861, 2017.
[18] C. Liu, B. Zoph, J. Shlens, W. Hua, L. Li, L. Fei-Fei, A. Yuille, J. Huang, K. Murphy, "Progressive neural
architecture search," arXiv preprint arXiv:1712.00559, 2017.
4