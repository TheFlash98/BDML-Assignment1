Emulating Numeric Hydroclimate Models with
Physics-Informed cGANs
Ashray Manepalli
terrafuse, inc.
Berkeley, CAAdrian Albert
terrafuse, inc.
Berkeley, CAAlan Rhoades
Berkeley National Lab
Berkeley, CADaniel Feldman
Berkeley National Lab
Berkeley, CA
Introduction and Motivation. Process-based numerical simulations, including those for climate
modeling applications, are compute and resource intensive, Reichstein et al. (2019), requiring
extensive customization and hand-engineering for encoding governing equations and other domain
knowledge, Raleigh et al. (2015). On the other hand, modern deep learning employs a signiﬁcantly
simpler and more efﬁcient computational workﬂow, and has been shown impressive results across a
myriad of applications in the computational sciences. In this work, we investigate the potential of
deep generative learning models, speciﬁcally conditional Generative Adversarial Networks (cGANs),
to simulate the output of a physics-based model of the spatial distribution of the water content of
mountain snowpack - the snow water equivalent (SWE). We show preliminary results indicating that
the cGAN model is able to learn diverse mappings between meteorological forcings and SWE output.
Thus physics based cGANs provide a means for fast and accurate SWE modeling that can have
signiﬁcant impact in a variety of applications (e.g., hydropower forecasting, agriculture, and water
supply management) Rhoades et al. (2018). In climate science, the Snowpack and SWE are seen as
some of the best indicative variables for investigating climate change and its impact. The massive
speedups, diverse sampling, and sensitivity/saliency modelling that cGANs can bring to SWE
estimation will be extremely important to investigating variables linked to climate change as well as
predicting and forecasting the potential effects of climate change to come.
Figure 1: Architecture and diagram of the conditional GAN used, a heavily modiﬁed variant of
Pix2Pix Isola et al. (2016)
Data. For all experiments presented here we have used a reanalysis dataset developed by Livneh,
Livneh et al. (2015), (L15) for the California Sierra Nevada mountain range. The L15 data was
Correspondence to: toni@terrafuse.ai .
33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.originally obtained by combining hydrologic simulation runs of the Variable Inﬁltration Capacity
(VIC) model bounded by spatially interpolated in-situ meteorological station measurements. This
dataset contains meteorological data and simulated SWE, used to train, assess, and constrain cGAN
model. All data channels are at a resolution of 321x321, corresponding to a 4km grid size.
Physics-informed conditional GANs. We formulate our emulation problem as an image-to-image
translation task. The goal is to transform an image from domain X, gridded meteorological variables,
to domainY, SWE grids. The pipeline of training a GAN emulator of SWE is illustrated in Figure 1.
In our setting, training samples from the two domains XandYare assumed paired, f(xi;yi)gN
i=1as
in Isola et al. (2016). Here we denote by xsamples from domain Xand byysamples from domain Y.
Furthermore, the generator takes a noise vector as an additional input, and can generate distributions
of realistic and plausible SWE maps for individual days through sampling.
We have incorporated certain domain knowledge into our model via additional penalty terms into the
optimization loss function, as follows: 1)Areas of higher elevation typically have larger amounts
of snow (and therefore SWE), and we add penalties to large errors in such areas accordingly. 2)As
a signiﬁcant portion of the data we study covers water areas such as the Paciﬁc Ocean, where no
snowpack can exist, we penalize the model harshly for placing SWE values in these areas. 3)We
penalize the difference in total SWE between cGAN solutions and physics model output, to ensure
that total stored water mass is properly estimated.
Figure 2: Three samples (per row) of model inputs (meteorological forcings) on the ﬁrst 6 columns,
physics model output (column 7). cGAN output (column 8) and difference between physics model
and cGAN (column 9). Rotated to match Sierra Nevada range (left).
Figure 3: Histograms of normalized pixel values comparing cGAN (green) and physics-model (black)
across key snowpack seasons.
Evaluation. Having trained the cGAN model as described above on a training set of 9 years of data
(input/output pairs as described above at daily resolution), we have ﬁrst tested its performance on a
holdout sample of two years of data. This is a standard regression setting, for which we compute
typical performance metrics. Even in this much simpliﬁed setting where we don’t explicitly model
time, the model achieves a mean absolute percentage error (MAPE) of 9.54%.
Next, we calculate and plot the power spectral density functions (PSD). This metric in-
corporates information across all spatial frequency scales, and is deﬁned as: PSD =
10 log10jF((SWE;SWE ))j2, whereFdenotes the Fourier transform and the two-point-
correlation function, deﬁned as usual.
2Figure 4: Power Spectral Density of cGAN and Physics Model over different hydrologic seasons:
respectively the end (Summer: July/August), start (Fall/Winter: November/December), and peak
(Spring: April/May) of SWE season.
Figure 5: Distributions of SWE (Blue) formed by sampling from stochastic Generator. Compared
with sample from non-stochastic Generator (Yellow), Livneh training data (Green), and observational
data from nearby Snotel Station (Red). All sampled at different dates, from different locations.
In Figures 3 and 4 we show comparisons between cGAN and physics-based model output over
periods at the peak (spring: April), end (summer: August), and start (winter: December), respectively,
of the SWE season (left, middle, and right panels in the ﬁgures), key periods of interest to snowpack
research. In Figure 3 we observe that the histograms of SWE values closely match, and in Figure 4
we observe that the aforementioned image statistics captured by PSD are also closely aligned.
SWE Distributions and Uncertainty. Another of the main beneﬁts to using cGANs to model SWE
is the ability to model the uncertainty in the underlying data. As stated in Isola et al. (2016), cGANs
learn to ignore noise added to the input alone. Therefore, to properly create a stochastic generator,
the well known trick of injecting a noise vector into several layers of the Generator instead of simply
being adding it to the input was utilized. This strategy worked, and allows for the generation of
diverse but realistic and physically plausible SWE grids. Furthermore, sampling can be performed
at individual points, allowing for the creation of SWE distributions, Figure 5, for the application of
statistical tests and conﬁdence intervals. We observe that the resulting distributions are physically
plausible - SWE in summer months (July) is expected to be near 0, which the model faithfully
recreates regardless of the noise vector injected. The plotted SNOTEL value is the SWE that was
physically measured at a single location. Large deviations from the average SWE value of the pixel
are to be expected, as the numerical model is gridded at a 4km resolution, whereas SNOTEL is
measured with a single small pressure sensor.
Speedup. Lastly, we have validated our hypothesis that inference time on a RTX Titan with a trained
cGAN is extremely fast, the 321x321 model taking 36 seconds to generate 1000 simulated SWE
grids (approximately 0:04seconds per SWE grid). To compare, the runtime of a VIC model used
to generate the SWE grids 100core-hours per 100 years of SWE output - about 10 seconds per
SWE grid. This suggests that the cGAN has a 250x speedup over the numerical model. This is a
very encouraging result - previously intractable studies such as probabilistic risk assessment and
sensitivity analysis are far more doable with the given speedup.
3References
Isola, P., Zhu, J.-Y ., Zhou, T., and Efros, A. A. Image-to-Image Translation with Conditional
Adversarial Networks. ArXiv e-prints , November 2016.
Livneh, B., Bohn, T. J., Pierce, D. W., Munoz-Arriola, F., Nijssen, B., V ose, R., Cayan, D. R., and
Brekke, L. A spatially comprehensive, hydrometeorological data set for mexico, the u.s., and
southern canada 1950–2013. Scientiﬁc Data , 2(150042), 2015. doi: doi:10.1038/sdata.2015.42.
Raleigh, M. S., Lundquist, J. D., and Clark, M. P. Exploring the impact of forcing error characteristics
on physically based snow simulations within a global sensitivity analysis framework, hydrol. Earth
Syst. Sci , 19:3153–3179, 2015. doi: 10.5194/hess-19-3153-2015.
Reichstein, M., Camps-Valls, G., Stevens, B., Jung, M., Denzler, J., Carvalhais, N., and Prabhat.
Deep learning and process understanding for data-driven earth system science. Nature , 566
(7743):195–204, 2019. doi: 10.1038/s41586-019-0912-1. URL https://doi.org/10.1038/
s41586-019-0912-1 .
Rhoades, A. M., Jones, A. D., and Ullrich, P. A. Assessing Mountains as Natural Reservoirs with a
Multi-Metric Framework . Earth’s Future (In Revision), 2018.
4