Automated Identiﬁcation of Oil Field Features using
CNNs
Sonu Dileep
Dept. of ECE
Colorado State University
Fort Collins, CO, 80524
sonudileep@gmail.comDaniel Zimmerle
Energy Institute
Colorado State University
Fort Collins, CO, 80524
dan.zimmerle@colostate.eduJ. Ross Beveridge
Dept. of Computer Science
Colorado State University
Fort Collins, CO, 80524
ross@cs.colostate.edu
Timothy Vaughn
Energy Institute
Colorado State University
Fort Collins, CO, 80524
tim.vaughn@colostate.edu
Abstract
Oil and gas production sites have been identiﬁed as a major source of anthropogenic
methane emissions. Emissions studies utilize counts of equipment to estimate
emissions from production facilities. However these counts are poorly documented,
including both information about well pad locations and major equipment on each
well pad. While these data can be found by manually reviewing satellite imagery,
it is prohibitively difﬁcult and time consuming. This work, part of a larger study
of methane emission studies in Colorado, US, adapted a machine learning (ML)
algorithm to detect well pads and associated equipment. Our initial model showed
an average well pad detection accuracy of 95% on the Denver-Julesburg (DJ) basin
in northeastern Colorado. Our example demonstrates the potential for this type of
automated detection from satellite imagery, leading to more accurate and complete
models of production emissions.
1 Introduction
Methane, the main component of natural gas, is a powerful greenhouse gas with a global warming
potential over 80 times that of CO2 on a 20-year basis[14]. Reducing methane emissions has been
identiﬁed as a key requirement to limit global warming[15,16,17,18,19]. Active natural gas production
sites account for 67% of the total methane emission from oil and gas industry[20]. A study was
conducted by nine cooperating U.S natural gas companies to study the methane emissions from
well pads and production sites. The study showed that methane leaks from equipment and during
transportation are much higher than previously thought[21].
The work described here is part of a top-down, bottom-up, coordinated campaign to be conducted in
the Denver-Julesburg (DJ) basin in northeastern Colorado in 2021. Methods planned for this study
mirror those utilized in the Fayetteville coordinated study [22,23,24,25,26] and the Barnett coordinated
campaign[27]. Methods utilized for these studies involve the development of ‘bottom-up’ (BU)
inventories of emissions. Inventories utilize prior emissions distributions, resolved to the component
level to represent emissions from individual leaks. These emissions data are multiplied, using Monte
Carlo methods, with activity data consisting of counts of major equipment, components per major
equipment unit, and other operational data. These calculations result in an empirical distribution
of emissions expected from all oil and gas facilities in a basin. When additional information is
Tackling Climate Change with Machine Learning workshop at NeurIPS 2020.available to resolve the timing of emissions, BU estimates may be extended by modeling the timing
of emissions events, and, potentially, the downwind dispersion of pollutants.
Since BU studies rely on counts of equipment and components, the accuracy of the counts has a
substantial impact on the modelled emissions. The location of wells is generally well known, as the
location of the bore hole, drilling direction, and production is reported to state authorities. While
traditional ﬁeld development integrated wells directly onto well pads containing initial processing
equipment, such as separators and tanks, in recent development, wellheads are often at a substantial
distance from the well pad containing that equipment. Further, reporting of well pad locations is
typically not required, and few location-speciﬁc data sets exist.
To ﬁll this data gap for the upcoming campaign, the study team developed a machine learning model
to identify well pads in the DJ basin from recent satellite imagery with 70 cm resolution.
2 Dataset
We have created a dataset annotating the location of well pads and storage tanks in Colorado using
GoogleTMsatellite imagery. To assist in annotation we’ve created a plugin in QGIS, an open source
GIS software and used the plugin to annotate over 1650 images of well pads in Colorado and 500
images for storage tanks. There were multiple well pads and well tanks in most of the images and we
annotated over 2826 well pads and 1712 well tanks. Three distinct geographic areas are included in
the dataset roughly corresponding to north-west, south-west and central regions of the state. The well
pads in these three areas have different characteristics. In the north-west the well pads are surrounded
by deserted land, in the south-west well pads are mostly surrounded by forest/vegetation and most of
the well pads in central Colorado are near buildings and roads. The diversity of well pad examples
drawn from the different parts of Colorado provides an excellent basis for generalization for our
machine learning models.
Storage tanks are much more self-similar and consequently it was not necessary to collect as many
training examples. Storage tank examples do vary due to factors such as the size and shape of
shadows, time of year, and minor variations typically associated with surrounding context. Overall,
we concluded that no more than 500 images of storage tanks needed to be hand labeled in order to
train our ML model. One other aspect of applying ML to recognizing storage tanks became apparent
as the dataset was being collected. A variety of other objects near and in gas production ﬁelds look
similar to well tanks, such as grain and agricultural water storage tanks. Therefore, we also collected
over 50 negative samples of storage tank-like structures to better train the ML model to avoid false
positives, i.e. mistaking these other distractors for storage tanks.
3 Methods
Computer Vision is the ﬁeld of artiﬁcial intelligence that deals with analyzing images and video.
The emergence of deep learning has facilitated improvement in the ﬁeld of computer vision tasks
like object detection[8,9] and segmentation[7]. Also the availability of large datasets like ImageNet,
MS COCO, PASCAL VOC has helped researchers push the limits of many computer vision tasks.
Since the introduction of CNNs, many different architectures for object detection tasks have been
developed which include YOLO[1,2,3,5], R-CNN[4], SSD[8] and many more. Because of the fast
inference speed and accuracy of yolo we decided to implement our well pad detection model using
YOLOv4[1].
3.1 Model
Our starting point was an already trained YOLO-v4 network. As is common practice, the initial ML
model weights were derived from training on ImageNet[10]. Our training then was an example of
transfer learning[30] where we used our relatively limited training data to adapt the ML model to the
speciﬁc task of well pad and storage tank detection.
Also, as is common practice with large images such as the satellite images [31], the ML model is
applied to smaller sliding windows which are moved across the satellite imagery. Rather than using a
ﬁxed window size, an adaptive sliding window changes size if necessary. During testing a sliding
window of size 500 x 500 is used for collecting tiles with a stride of 450. If the size of the well pad is
2really large and is close to the boundary of the window, then the window size will be increased by 100
on both sides. This process repeats until the well pad ﬁts the window. This helped us to detect well
pads of different sizes. The adaptive sliding window approach is used only for well pad detection and
not for equipment since they are all of the same size.
A key constraint employed in this work is that storage tanks are most often located within well pads.
Consequently, ﬁrst well pads are detected and then storage tanks are looked for inside well pads. This
technique avoids searching vast areas for unlikely storage tanks.
3.2 Training
Well Pads of different size and features were used for training the model. Each image is either
upsampled or downsampled to 606 x 606 as an input to yolo.The data augmentation techniques used
are scaling, rotation, blur and cut mix[28]. The model was trained over 10,000 iterations with a step
decay learning rate schedule strategy. We initialized the learning rate with 0.001 and after each 5000
iterations it will be multiplied by a factor of 0.1. The loss function used for training is CIoU-loss[32].
We used a momentum of 0.949 and decay of 0.0005.
3.3 Performance
We used a 5-fold cross validation method to evaluate the performance of the well pad detection model.
In 5-fold cross validation the labeled training examples are divided evenly into 5 sets. Then, all
possible splits are created where 4 sets are used to train the ML model and the remaining set is used
to assess performance, i.e. measure recognition performance. We used the same strategy for well
tank detection model but used a 4-fold cross validation instead of 5. The speciﬁc loss function used
for training was CIoU-loss[32] and training was run until the average loss no longer decreased. The
performance of our detection algorithms was measured using standard measures. Intersection over
Union(IoU) thresholded at 0.3 establishes if a detection covers a true example. The true positive
(TP) rate reports the percentage of labeled examples actually found by the ML algorithm. The false
positive (FP) rate reports the percentage of detections which are erroneous. The false negative rate
reports the actual labeled instances not detected as a fraction of all the labeled instances. Finally, the
F1 score is a common measure deﬁned to integrate TP, FP and FN ﬁndings[33].
4 Results
For well pads, the 1650 labeled well pad images were split into 5 sets of 330 images each. There
were multiple well pads in most of these images. Results for the ML well pad detection model trained
and tested using 5-fold cross validation protocol are summarized in Table-1. Since fold-2 gave the
highest F1 score, we choose the weights from fold-2 for our work. We repeated the same strategy for
storage tank detection model, but with a 4-fold cross-validation strategy. So we split the 500 images
into 4 sets of 125 images each. The results are summarized in Table-2. Column 2 in Table-1 and
Table-2 shows the actual number of hand labeled well pads (or storage tanks) in the fold.
Well Pad True Positive False Positive False Negative F1 Score
Fold-1 603 595/603(98.6%) 30/625(4.8%) 8/603(1.3%) 0.9690
Fold-2 665 658/665(98.9%) 19/677(2.8%) 7/665(1.0%) 0.9806
Fold-3 610 607/610(99.5%) 43/650(6.6%) 3/610(0.4%) 0.9607
Fold-4 545 544/545(99.8%) 39/583(6.6%) 1/545(0.1%) 0.9644
Fold-5 403 402/403(99.7%) 21/423(4.9%) 1/403(2.4%) 0.9733
Average 2806/2826(99.2%) 152/2958(5.1%) 20/2826(0.7%) 0.9696
Table 1: 5-fold cross validation result for well pads
The entire model is implemented in an open source GIS software, QGIS, which outputs a shape ﬁle
containing the latitude and longitude of each well pad, and the location of each storage tank detected.
We ran the model over Denver-Julesburg (DJ) basin and checked the results. Due to the unavailability
of a database of exact well pad counts we decided to check the accuracy at 5 different parts of DJ
3Storage Tank True Positive False Positive False Positive F1 Score
Fold-1 291 290/291(99.6%) 0/290(0%) 1/291(0.3%) 0.9982
Fold-2 356 354/356(99.4%) 12/366(3.2%) 2/356(0.5%) 0.9805
Fold-3 389 389/389(100%) 4/393(1.1%) 0/389(0%) 0.9948
Fold-4 676 667/676(98.6%) 17/684(2.4%) 9/676(1.3%) 0.9808
Average 1700/1712(99.2%) 43/1733(2.4%) 12/1712(0.7%) 0.9885
Table 2: 4-fold cross validation result for storage tanks
basin. We used rectangular tiles of 5000 x 5000 at 5 different parts and averaged the results. We got
an average detection accuracy of 95% with the lowest at 93% and highest at 96%.
Figure 1: Well Pad detection across DJ Basin. Left panel indicates the study area (black box) overlaid
with well pad detections in the study box. For reference, the Denver metropolitan area is immediately
south of the box. Right panel shows a portion of the study area indicating well pads detected by the
algorithm.
Figure 2: Individual well pad detections. Red boxes are on-pad storage tank detections
5 Conclusion
We adapted a deep learning approach to detect well pads and their major equipment to support a
study of methane and other air emissions in the DJ basin Colorado. Performance applied to the study
area within the DJ Basin showed promising results. Future work will develop a database of well
pad locations and well pad features in the DJ basin, and possibly throughout Colorado. We will
also upload our dataset for further research in this ﬁeld. The modeling technique utilized here could
also be used for other applications, such as the detection of agricultural facilities (grain storage and
feedlots are of interest), or other emissions sources (e.g. compressor stations, gas stations, or pipeline
infrastructure).
4References
[1] A. Bochkovskiy, C.-Y . Wang, and H.-Y . M. Liao. Yolov4: Optimal speed and accuracy of object detec- tion.
arXiv preprint arXiv:2004.10934, 2020.
[2] Redmon, J., Farhadi, A.: YOLO9000: better, faster, stronger. CoRR abs/1612.08242 (2016)
[3] Van Etten, A.: You only look twice: Rapid multi-scale object detection in satellite imagery. Submitted to
KDD (2018)
[4] Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik. Rich feature hierarchies for accurate object
detection and semantic segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recog- nition (CVPR), pages 580–587, 2014.
[5] Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. You only look once: Uniﬁed, real-time
object de- tection. In Proceedings of the IEEE Conference on Com- puter Vision and Pattern Recognition
(CVPR), pages 779– 788, 2016.
[6] Joseph Redmonand, Ali Farhadi.YOLOv3:An incremental improvement. arXiv preprint arXiv:1804.02767,
2018.
[7] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for semantic segmentation,” in
Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3431–3440, 2015.
[8] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander
C Berg. SSD: Single shot multibox detector. In Proceedings of the European Conference on Computer Vision
(ECCV), pages 21–37, 2016
[9] S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: Towards real-time object detection with region proposal
networks,” in Advances in neural information processing systems, pp. 91–99, 2015.
[10] D.Rolnick,P.L.Donti,L.H.Kaack,K.Kochanski,A.Lacoste,K.Sankaran,A.S.Ross,N.Milojevic- Dupont, N.
Jaques, A. Waldman-Brown, et al., “Tackling climate change with machine learning,” arXiv preprint
arXiv:1906.05433, 2019.
[11] Brantley, H.L.; Thoma, E.D.; Squier, W.C.; Guven, B.B.; Lyon, D. (2014). “Assessment of methane
emissions from oil and gas production pads using mobile measurements.” Environmental Science & Technology
48, pp. 1450814515.
[12] Schneising, O.; Burrows, J.P.; Dickerson, R.R.; Buchwitz, M.; Reuter, M.; Bovensmann, H. (2014).
“Remote sensing of fugitive methane emissions from oil and gas production in North American tight geologic
formations.” Future 2, pp. 548–558.
[13] Caulton, D.R.; Shepson, P.B.; Cambaliza, M.; McCabe, D.; Baum, E.; Stirm, B.H. (2014). “Methane
destruction efﬁciency of natural gas ﬂares associated with shale formation wells.” Environmental Science &
Technology 48, pp. 95489554.
[14] IPCC Core Writing Team, Pachauri R, Meyer L (2014) IPCC, 2014: Climate Change 2014: Synthesis
Report. Contribution of Working Groups I. II and III to the Fifth Assessment Report of the intergovernmental
panel on Climate Change. IPCC, Geneva, Switzerland, 151
[15] D. Allen, “Attributing Atmospheric Methane to Anthropogenic Emission Sources,” Acc. Chem. Res., vol.
49, no. 7, pp. 1344–1350, Jul. 2016, doi: 10.1021/acs.accounts.6b00081.
[16] R. A. Alvarez, S. W. Pacala, J. J. Winebrake, W. L. Chameides, and S. P. Hamburg, “Greater focus needed
on methane leakage from natural gas infrastructure,” PNAS, vol. 109, no. 17, pp. 6435–6440, Apr. 2012, doi:
10.1073/pnas.1202407109.
[17] H. Schaefer et al., “A 21st-century shift from fossil-fuel to biogenic methane emissions indicated by 13CH4,”
Science, vol. 352, no. 6281, pp. 80–84, Apr. 2016, doi: 10.1126/science.aad2705.
[18] S. Schwietzke, W. M. Grifﬁn, H. S. Matthews, and L. M. P. Bruhwiler, “Natural Gas Fugitive Emissions
Rates Constrained by Global Atmospheric Methane and Ethane,” Environ. Sci. Technol., vol. 48, no. 14, pp.
7714–7722, Jul. 2014, doi: 10.1021/es501204c.
[19] A. J. Turner et al., “A large increase in U.S. methane emissions over the past decade inferred from satellite
data and surface observations,” Geophys. Res. Lett., vol. 43, no. 5, p. 2016GL067987, Mar. 2016, doi:
10.1002/2016GL067987.
[20] Inventory of U.S. Greenhouse Gas Emissions and Sinks: 1990-2018, Available online at :
https://www.epa.gov/ghgemissions/inventory-us-greenhouse-gas-emissions-and-sinks
5[21] Allen, D. T.; Torres, V . M.; Thomas, J.; Sullivan, D. W.;Harrison, M.; Hendler, A.; Herndon, S. C.; Kolb,
C. E.; Fraser, M. P.; Hill, A. D.; Lamb, B. K.; Miskimins, J.; Sawyer, R. E.; Seinfeld, J. H. Measurements of
methane emissions at natural gas production sites in the United States. Proc. Natl. Acad. Sci. U. S. A. 2013,
DOI: 10.1073/ pnas.1304880110
[22] D. T. Allen et al., “A Methane Emission Estimation Tool (MEET) for prediction of natural gas emissions
with high temporal and spatial resolution.,” Environ. Sci. Technol., vol. in review, 2020.
[23] A. M. Robertson et al., “Variation in Methane Emission Rates from Well Pads in Four Oil and Gas
Basins with Contrasting Production V olumes and Compositions,” Environ. Sci. Technol., Jun. 2017, doi:
10.1021/acs.est.7b00571.
[24] S. Schwietzke et al., “Improved Mechanistic Understanding of Natural Gas Methane Emissions from
Spatially Resolved Aircraft Measurements,” Environ. Sci. Technol., May 2017, doi: 10.1021/acs.est.7b01810.
[25] T. L. Vaughn et al., “Temporal variability largely explains top-down/bottom-up difference in methane
emission estimates from a natural gas production region,” PNAS, p. 201805687, Oct. 2018, doi:
10.1073/pnas.1805687115.
[26] D. J. Zimmerle et al., “Gathering pipeline methane emissions in Fayetteville shale pipelines and scoping
guidelines for future pipeline measurement campaigns,” Elem Sci Anth, vol. 5, no. 0, Nov. 2017, doi:
10.1525/elementa.258.
[27] D. R. Lyon et al., “Constructing a Spatially Resolved Methane Emission Inventory for the Barnett Shale
Region,” Environ. Sci. Technol., vol. 49, no. 13, pp. 8147–8157, Jul. 2015, doi: 10.1021/es506359c.
[28] S. Yun, D. Han, S. J. Oh, S. Chun, J. Choe, and Y . Yoo. Cutmix: Regularization strategy to train strong
classiﬁers with localizable features. arXiv preprint arXiv:1905.04899, 2019.
[29] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,and Li Fei-Fei. ImageNet: A large-scale hierarchical
image database. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
pages 248–255, 2009.
[30] L. Torrey and J. Shavlik.2009. Transfer learning. In E. Soria, J. Martin,R. Magdalena, M. Martinez, and A.
Serrano, editors,Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods,
and Techniques. IGI Global
[31] A. Albert, J. Kaur, and M. C. Gonzalez. Using convolutional networks and satellite imagery to identify
patterns in urban environments at a large scale. In Proceedings of the 23rd ACM SIGKDD International
Conference on Knowledge Discov-ery and Data Mining, KDD ’17, pages 1357–1366,New York, NY , USA,
2017. ACM.
[32] Zhaohui Zheng, Ping Wang, Wei Liu, Jinze Li, RongguangYe, and Dongwei Ren. Distance-IoU Loss:
Faster and better learning for bounding box regression. In Proceedings of the AAAI Conference on Artiﬁcial
Intelligence (AAAI),2020.
[33] C. Goutte and E. Gaussier. A probabilistic interpretation of precision, recall, and F-score, with implication
for evaluation. In ECIR ’05: Proceedings of the 27th European Conference on Information Retrieval, pages
345–359, 2005.
6