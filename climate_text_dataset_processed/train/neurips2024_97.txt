Stubble (Crop Residue) Burning Detection Through
Satellite Images Using Geospatial Foundation Model:
A Case Study in Punjab, India
Rajiv Ranjan
Center for Sustainable & Precision Agriculture
Plaksha University
Punjab, India
rajiv.ranjan@plaksha.edu.inYing-Jung Chen
College of Computing
Georgia Institute of Technology
Atlanta, GA 30332
yingjungcd@gmail.com
Shashank Tamaskar
Center for Sustainable & Precision Agriculture
Plaksha University
Punjab, India
shashank.tamaskar@plaksha.edu.in
Anupam Sobti
Center for Sustainable & Precision Agriculture
Plaksha University
Punjab, India
anupam.sobti@plaksha.edu.in
Abstract
Stubble burning is a significant environmental challenge globally, with widespread
implications for air quality, greenhouse gases emission, soil degradation and health
issues. This practice is particularly prevalent in agricultural regions across the
world, though its impacts are notably severe in the northern India. This proposed
work focuses on improving the detection of stubble (crop residue) burning in
Punjab (India), using geospatial foundation model. This study leverages series
of satellite images where stubble burning incidents have been documented. By
refining the model to incorporate local environmental factors, this study aims
to improve the accuracy of stubble burning detection, thereby contributing to a
scalable solution for real-time monitoring and intervention in crop residue burning
practices worldwide.
1 Introduction
Stubble (Crop residue) [1], [2] burning is a widespread practice in agricultural regions across the
world [3]–[6] particularly in Punjab, northern India (Figure 1)[7]–[9], where it is predominantly used
to rapidly clear crop residues during the months of October and November. Despite its convenience
for farmers, this practice has severe environmental consequences, including deteriorating air quality,
soil degradation, and adverse health effects across northern India [10]–[13], including New Delhi
[14]–[16]. Total emissions of carbon dioxide (CO 2) sulfur dioxide (SO 2), nitric oxide (NO x), carbon
monoxide (CO), PM 2.5, PM 10etc. from crop residue burning are quantified by [17] using statistical
models combined with satellite observations and sensors. A Detailed study on the impact of stubble
burning on climate change is provided in [18], [19], while satellite-based methods have been used
Tackling Climate Change with Machine Learning: workshop at NeurIPS 2024.to monitor and detect stubble burning [20]–[22]. Similarly, in [23] Sentinel-2 data and Random
Forest classifiers were used to map stubble burning, demonstrating the potential of integrating
spectral indices such as NDVI [24] and NBR [25]. However, these methods often lack regional
adaptability and precision, limiting their overall effectiveness. Recent advancements in remote
sensing and machine learning have led to more accurate detection and monitoring of stubble burning.
[26], [27]) A CNN-based deep learning framework was used to monitor active fire locations with
high-resolution satellite imagery, significantly improving burn scar detection accuracy compared to
traditional methods [28]. Fine-tuning pre-trained Earth observation models for regional applications
enhances performance, achieving state-of-the-art results in land cover classification [29]. Transfer
learning and adaptive strategies, as explored by [30], [31], are crucial for effectively fine-tuning
geospatial models.This study aligns with these goals by fine-tuning the Prithvi-100m geospatial
foundation model [32], [33] for the Punjab region to enhance stubble burning detection, utilizing
a dataset of 1,500 coordinate points to improve regional specificity and detection accuracy. The
Prithvi-100m-burn-scars model [34], further fine-tuned on the extensive HLS Burn Scar Scenes
dataset [35], marks a significant advancement in burn scar detection. By leveraging this model
on high-resolution satellite images [36] and a customized regional dataset (Punjab, India), stubble
burning detection methods can be tailored to local environmental conditions. The proposed approach
aims to offer a scalable solution for real-time monitoring and intervention in stubble burning practices
worldwide. Accurate monitoring of stubble burning can significantly aid in crop residue management
and reduce its environmental consequences, as discussed in [37]–[39].
2 Dataset and Preprocessing
The dataset1consists of 1,500 data points (latitude, longitude, date of observation) from Punjab,
India, representing locations where active fires or stubble burning incidents were reported, as shown
in Figure 2. Manual polygonization can be used to annotate fields on satellite images for the
corresponding stubble burning observation dates. The recommended geospatial foundation model
requires six bands (blue, green, red, narrow NIR, SWIR 1, and SWIR 2) compatible with Sentinel-2
(20m resolution) and a 5- to 6-day revisit time.
Figure 1: Stubble burning in rice field
 Figure 2: 1,500 Ground truth data points
Sentinel-2 (L2A) products [40] offer freely accessible surface reflectance data, making them a
cost-effective alternative to commercial datasets like PlanetScope. While Sentinel-2 has a lower
spatial resolution (10 meters) and a 5-day revisit time compared to PlanetScope’s higher resolution
(around 3 meters) and daily revisit capability, its free and open access is invaluable for large-scale and
long-term monitoring. To correct atmospheric effects in our 2015 data, recorded before Sentinel-2
L2A products became available in 2018, we applied the Sen2Cor processor [41] to the Level-1C data.
This process removes aerosols, water vapor, and other noise. Additionally, Min-Max normalization
[42] is used to scale reflectance values, addressing variations in illumination, sensor angles, and
atmospheric conditions, thereby improving model robustness and generalization across diverse
regions and timeframes.
1Someone gathered it with the assistance of local resources and chose to remain anonymous.
2Figure 3: Fine-tuning of geospatial foundation model
3 Proposed Method
In this study, we aim to fine-tune the Prithvi-100m geospatial foundation model, pre-trained on
diverse remote sensing images, for stubble burning detection.While the baseline remote sensing
index method provides valuable insights, it is prone to false positives, often mistaking dark pixels or
patches on the ground for stubble burning areas when they might actually be regions where bio-char
or ashes have been applied. To address this, we propose a fine-tuned geospatial foundation model
specifically designed to detect actual stubble burning areas, thereby reducing false positives and
enhancing detection accuracy.The model uses a Vision Transformer (ViT) architecture [43] with a
self-supervised encoder [44], employing a Masked Auto-Encoder (MAE) [45] learning strategy and a
Mean Squared Error (MSE) loss function [46]. It leverages spatial attention across multiple patches
and temporal attention within each patch.
To begin the fine-tuning process, we will apply standard data augmentation techniques, such as
rotation, random cropping, flips, spectral perturbations, and patch jigsaw puzzles, to enhance training
diversity and prevent over-fitting. Next, we will adapt the Prithvi-100m model using our stubble
burning dataset, optimizing it for effective burn scar detection. The fine-tuned model will then be
rigorously evaluated against unseen data to validate its performance. The workflow of fine-tuning the
Prithvi-100m geospatial foundation model is shown in Figure 3.
For comparative analysis, we will compare this model with the baseline, the fine-tuned Prithvi-100m-
burn-scars model (Overall accuracy 0.96) [47] on the HLS Burn Scar Scenes dataset [35] and also
with the Skysense FM model [48] as well. The models will be tested on a common validation set to
assess their effectiveness in detecting burn scars or stubble burning. Performance will be evaluated
using standard metrics, including precision, recall, F1-score, and the area under the ROC curve
(AUC-ROC), providing a comprehensive assessment of the model’s ability to detect stubble burning
incidents accurately while minimizing false positives and negatives. This approach highlights that
while the foundational model offers a strong base, task-specific fine-tuning is essential for optimizing
performance in targeted applications like stubble burning detection. Details on the baseline model
and geospatial foundation model are in Appendix.
4 Conclusion & Pathways to Climate Impact
This proposal outlines a method for fine-tuning the Prithvi-100m geospatial foundation model to
detect stubble burning incidents in Punjab, India. By customizing the model to account for regional
environmental conditions and using a localized dataset, this work aims to enhance the accuracy and
effectiveness of stubble burning detection. The improved model is expected to offer greater precision
and reliability in monitoring stubble burning across diverse agricultural landscapes globally , paving
the way for scalable applications to mitigate air pollution. Stubble burning, a common agricultural
practice, significantly impacts air quality by emitting large quantities of greenhouse gases (GHG).
3Effective monitoring of these events allows for more targeted interventions and policy measures to
reduce emissions and promote sustainable farming practices. Ultimately, this study aims to provide
policymakers and civil society with a tool to monitor and regulate stubble burning globally. It supports
climate action (SDG 13) by reducing GHG emissions, addresses land degradation (SDG 15), and
promotes responsible consumption and production in agriculture (SDG 12).
References
[1] S. S. Reddy and V . Chhabra, “Crop residue burning: Is it a boon or a bane?” Communications
in Soil Science and Plant Analysis , vol. 53, no. 18, pp. 2353–2364, 2022.
[2] A. Demirdogen, “Stubble burning: What determines this fire?” Environmental Development ,
vol. 51, p. 101 029, 2024.
[3] I. Chanana, A. Sharma, P. Kumar, et al. , “Combustion and stubble burning: A major concern
for the environment and human health,” Fire, vol. 6, no. 2, p. 79, 2023.
[4] M. Lin and T. Begho, “Crop residue burning in south asia: A review of the scale, effect,
and solutions with a focus on reducing reactive nitrogen losses,” Journal of Environmental
Management , vol. 314, p. 115 104, 2022.
[5] J. L. McCarty, S. Korontzi, C. O. Justice, and T. Loboda, “The spatial and temporal distribution
of crop residue burning in the contiguous united states,” Science of the Total Environment ,
vol. 407, no. 21, pp. 5701–5712, 2009.
[6] J. Chen, Y . Gong, S. Wang, B. Guan, J. Balkovic, and F. Kraxner, “To burn or retain crop
residues on croplands? an integrated analysis of crop residue management in china,” Science
of the Total Environment , vol. 662, pp. 141–150, 2019.
[7] S. Sarkar, R. P. Singh, and A. Chauhan, “Crop residue burning in northern india: Increasing
threat to greater india,” Journal of Geophysical Research: Atmospheres , vol. 123, no. 13,
pp. 6920–6934, 2018.
[8] M. Barman and A. Mukhopadhyay, “Stubble burning in india: Problems and mitigation
strategies,” Agric food e-Newslett , vol. 2, no. 12, pp. 562–564, 2020.
[9] J. Mohite, S. Sawant, A. Pandit, and S. Pappula, “Impact of lockdown and crop stubble burning
on air quality of india: A case study from wheat-growing region,” Environmental Monitoring
and Assessment , vol. 194, no. 2, p. 77, 2022.
[10] P. Chawala and H. Sandhu, “Stubble burn area estimation and its impact on ambient air quality
of patiala & ludhiana district, punjab, india,” Heliyon , vol. 6, no. 1, 2020.
[11] M. I. Abdurrahman, S. Chaki, and G. Saini, “Stubble burning: Effects on health & environment,
regulations and management practices,” Environmental Advances , vol. 2, p. 100 011, 2020.
[12] S. K. Mittal, N. Singh, R. Agarwal, A. Awasthi, and P. K. Gupta, “Ambient air quality during
wheat and rice crop stubble burning episodes in patiala,” Atmospheric Environment , vol. 43,
no. 2, pp. 238–244, 2009.
[13] D. Grover and S. Chaudhry, “Ambient air quality changes after stubble burning in rice–wheat
system in an agricultural state of india,” Environmental Science and Pollution Research , vol. 26,
pp. 20 550–20 559, 2019.
[14] G. Singh, A. Kumar, D. Vaid, and P. Sharma, “Stubble burning and its impact on air quality in
delhi nct: A case study,” J Univ Shanghai Sci Technol , vol. 23, pp. 58–68, 2021.
[15] G. Beig, S. K. Sahu, V . Singh, et al. , “Objective evaluation of stubble emission of north india
and quantifying its impact on air quality of delhi,” Science of The Total Environment , vol. 709,
p. 136 126, 2020.
[16] M. Nair, H. Bherwani, S. Kumar, S. Gulia, S. Goyal, and R. Kumar, “Assessment of contribu-
tion of agricultural residue burning on air quality of delhi using remote sensing and modelling
tools,” Atmospheric Environment , vol. 230, p. 117 504, 2020.
[17] R. Li, X. He, H. Wang, et al. , “Estimating emissions from crop residue open burning in central
china from 2012 to 2020 using statistical models combined with satellite observations,” Remote
Sensing , vol. 14, no. 15, p. 3682, 2022.
[18] S. H. Mondal and A. K. Chattopadhyay, “Impact of stubble burning on air pollution and
climate change in east burdwan district, india,” Indian Economic Review , pp. 1–20, 2024.
[19] G. Singh et al. , “The environmental impact of stubble burning,” International Journal of
Science and Research Archive , vol. 12, no. 2, pp. 114–116, 2024.
4[20] P. Gupta, S. A. Christopher, F. Patadia, and N. Rastogi, “The unusual stubble burning season
of 2020 in northern india: A satellite perspective,” International Journal of Remote Sensing ,
vol. 44, no. 21, pp. 6882–6896, 2023.
[21] A. Garg, F. D. Vescovi, V . Chhipa, et al. , “Stubble burning detection using multi-sensor and
multi-temporal satellite data,” in IGARSS 2023-2023 IEEE International Geoscience and
Remote Sensing Symposium , IEEE, 2023, pp. 1606–1609.
[22] X. Wu, T. Liu, Y . Cheng, et al. , “Dynamic monitoring of straw burned area using multi-source
satellite remote sensing data,” Transactions of the Chinese Society of Agricultural Engineering ,
vol. 33, no. 8, pp. 153–159, 2017.
[23] L. Mohammad, J. Bandyopadhyay, R. Sk, et al. , “Estimation of agricultural burned affected
area using ndvi and dnbr satellite-based empirical models,” Journal of Environmental Manage-
ment , vol. 343, p. 118 226, 2023.
[24] S. Huang, L. Tang, J. P. Hupy, Y . Wang, and G. Shao, “A commentary review on the use of
normalized difference vegetation index (ndvi) in the era of popular remote sensing,” Journal
of Forestry Research , vol. 32, no. 1, pp. 1–6, 2021.
[25] A. E. Cocke, P. Z. Fulé, and J. E. Crouse, “Comparison of burn severity assessments using
differenced normalized burn ratio and ground data,” International Journal of Wildland Fire ,
vol. 14, no. 2, pp. 189–198, 2005.
[26] A. Sharma, H. Kumar, K. Mittal, et al. , “Iot and deep learning-inspired multi-model frame-
work for monitoring active fire locations in agricultural activities,” Computers & Electrical
Engineering , vol. 93, p. 107 216, 2021.
[27] H. Liu, J. Li, J. Du, et al. , “Identification of smoke from straw burning in remote sensing
images with the improved yolov5s algorithm,” Atmosphere , vol. 13, no. 6, p. 925, 2022.
[28] L. O. Chua, “Cnn: A vision of complexity,” International Journal of Bifurcation and Chaos ,
vol. 7, no. 10, pp. 2219–2425, 1997.
[29] A. Vali, S. Comai, and M. Matteucci, “Deep learning for land use and land cover classification
based on hyperspectral and multispectral earth observation data: A review,” Remote Sensing ,
vol. 12, no. 15, p. 2495, 2020.
[30] Y . Ma, S. Chen, S. Ermon, and D. B. Lobell, “Transfer learning in environmental remote
sensing,” Remote Sensing of Environment , vol. 301, p. 113 924, 2024.
[31] Z. Liu, J. Li, M. Ashraf, et al. , “Remote sensing-enhanced transfer learning approach for
agricultural damage and change detection: A deep learning perspective,” Big Data Research ,
vol. 36, p. 100 449, 2024.
[32] J. Jakubik, S. Roy, C. E. Phillips, et al. , “Foundation Models for Generalist Geospatial Artificial
Intelligence,” Preprint Available on arxiv:2310.18660 , Oct. 2023.
[33] J. Jakubik, L. Chu, P. Fraccaro, et al. ,Prithvi-100M , Aug. 2023. DOI:10.57967/hf/0952 .
[34] S. Roy, C. Phillips, J. Jakubik, et al. ,Prithvi 100M burn scar , Aug. 2023. DOI:10.57967/
hf/0953 . [Online]. Available: https://huggingface.co/ibm- nasa- geospatial/
Prithvi-100M-burn-scar .
[35] C. Phillips, S. Roy, K. Ankur, and R. Ramachandran, HLS Foundation Burnscars Dataset , Aug.
2023. DOI:10.57967/hf/0956 . [Online]. Available: https://huggingface.co/ibm-
nasa-geospatial/hls_burn_scars .
[36] C. Yang, “High resolution satellite imaging sensors for precision agriculture,” Front. Agric.
Sci. Eng , vol. 5, no. 4, pp. 393–405, 2018.
[37] S. Bhuvaneshwari, H. Hettiarachchi, and J. N. Meegoda, “Crop residue burning in india: Policy
challenges and potential solutions,” International journal of environmental research and public
health , vol. 16, no. 5, p. 832, 2019.
[38] G. K. Porichha, Y . Hu, K. T. V . Rao, and C. C. Xu, “Crop residue management in india: Stubble
burning vs. other utilizations including bioenergy,” Energies , vol. 14, no. 14, p. 4281, 2021.
[39] M. H. Raza, M. Abid, M. Faisal, T. Yan, S. Akhtar, and K. M. Adnan, “Environmental
and health impacts of crop residue burning: Scope of sustainable crop residue management
practices,” International Journal of Environmental Research and Public Health , vol. 19, no. 8,
p. 4753, 2022.
5[40] M. Main-Knorn, B. Pflug, J. Louis, and V . Debaecker, “Calibration and validation plan
for the l2a processor and products of the sentinel-2 mission,” International Archives of the
Photogrammetry, Remote Sensing and Spatial Information Sciences-ISPRS Archives , vol. 40,
no. W3, pp. 1249–1255, 2015.
[41] M. Main-Knorn, B. Pflug, J. Louis, V . Debaecker, U. Müller-Wilm, and F. Gascon, “Sen2cor
for sentinel-2,” in Image and signal processing for remote sensing XXIII , SPIE, vol. 10427,
2017, pp. 37–48.
[42] F. Cao, Z. Yang, J. Ren, M. Jiang, and W. -K. Ling, “Does normalization methods play a role
for hyperspectral image classification?” arXiv preprint arXiv:1710.02939 , 2017.
[43] K. Han, Y . Wang, H. Chen, et al. , “A survey on vision transformer,” IEEE transactions on
pattern analysis and machine intelligence , vol. 45, no. 1, pp. 87–110, 2022.
[44] X. Chen, M. Ding, X. Wang, et al. , “Context autoencoder for self-supervised representation
learning,” International Journal of Computer Vision , vol. 132, no. 1, pp. 208–223, 2024.
[45] C. Feichtenhofer, Y . Li, K. He, et al. , “Masked autoencoders as spatiotemporal learners,”
Advances in neural information processing systems , vol. 35, pp. 35 946–35 958, 2022.
[46] Z. Wang and A. C. Bovik, “Mean squared error: Love it or leave it? a new look at signal fidelity
measures,” IEEE signal processing magazine , vol. 26, no. 1, pp. 98–117, 2009.
[47] IBM NASA Geospatial, Prithvi-100m-burn-scar (revision a8430c0) , 2023. DOI:10.57967/
hf/0953 . [Online]. Available: https://huggingface.co/ibm- nasa- geospatial/
Prithvi-100M-burn-scar .
[48] X. Guo, J. Lao, B. Dang, et al. ,Skysense: A multi-modal remote sensing foundation model
towards universal interpretation for earth observation imagery , 2024. arXiv: 2312.10115
[cs.CV] . [Online]. Available: https://arxiv.org/abs/2312.10115 .
[49] M. Muszynski, L. Klein, A. F. da Silva, et al. ,Fine-tuning of geospatial foundation models for
aboveground biomass estimation , 2024. arXiv: 2406.19888 [cs.AI] . [Online]. Available:
https://arxiv.org/abs/2406.19888 .
A Appendix
Here we will provide further details on the baseline model and geospatial foundation model used in
this study.
A.1 Baseline Model
Previously, we conducted baseline work on stubble burning detection using traditional remote sensing
methods, leveraging spectral indices such as NDVI (Normalized Difference Vegetation Index) and
NBR (Normalized Burn Ratio) on small ground truth patches we collected. We analyzed this approach
using data from Sentinel, Planet, and various active fire products for the area of interest. This section
provides an overview of the baseline data, the methods employed, and the preliminary results obtained
from our earlier analysis.
A.1.1 Baseline Data
For the baseline work, remote sensing data was collected following a stubble burning incident on May
9, 2023. The dataset includes high-resolution PlanetScope satellite imagery with 8 spectral bands at a
3-meter resolution, captured daily from May 1 to May 20, 2023. Additionally, Sentinel-2 satellite
imagery, providing 13 spectral bands at a 10-meter resolution (2A data product), was acquired on
four distinct dates within the same period (Figure 4). Furthermore, NASA’s active fire products were
utilized to gather data on active fires across the Punjab region during the 2022 Kharif season, offering
a broader spatial resolution of 500 meters.
Planet images available at a daily frequency. Higher spatial resolution leads to better identification of
burn areas. Burn incidents become indistinguishable within 2 days of burning as shown in Figure 5.
However, Sentinel-2 satellite imagery is freely available but on interval of 5-6 days. Infrared spectral
bands (SWIR) are available which are directly correlated with fire.
Daily monitoring of fire incidents is conducted at low spatial resolution using NASA satellite
instruments, specifically MODIS and VIIRS. The MODIS instrument captures data four times each
6day, providing direct detection of fire events at a lower spatial resolution of 1 kilometer. This data is
typically available with a latency of 2 to 3 hours. Similarly, VIIRS collects data once a day, offering
direct detection of fires with an improved spatial resolution of 375 meters. Like MODIS, the data
from VIIRS is also available with a latency of 2 to 3 hours. These tools are critical for consistent and
timely monitoring of fire events over large areas.
Figure 4: Temporal sentinel imagery of burn area (May 2023)
Figure 5: Temporal planet imagery of burn area (May 2023)
A.1.2 Baseline Method
We conducted an analysis by comparing Planet and Sentinel imagery, along with active fire products,
to alert authorities and calculate the last burn index using Sentinel imagery. Figure 6 illustrates the
baseline method for detecting fire-affected areas using remote sensing data. The process begins
with two types of input data: active fire detection from MODIS/VIIRS and other remote sensing
datasets. These inputs are processed to generate visual representations of the affected regions, marked
by red circles. The processed images are then analyzed using various indices, including the Char
Index, Burn Area Index, Bare Soil Index, NBR (Normalized Burn Ratio), and others such as MIRBI
(Mid-Infrared Burn Index) and BSI (Burn Severity Index), to assess the extent and impact of the burn.
The outputs from these indices are subsequently used in a time-series change detection analysis to
monitor changes over time. The final result is visualized, indicating the spatial distribution of detected
changes (marked by red and blue triangles), which aids in identifying patterns and understanding the
impact of burning over time.
A.1.3 Preliminary Results
Combining MODIS, Sentinel, and Planet imagery significantly enhances the accuracy of fire detection,
building on methodologies proposed in prior studies. This integrated approach not only improves
detection precision but also facilitates the timely issuance of alerts to authorities, enabling prompt
action. In Figure 7, the first image, dated October 5, 2022, depicts the area before any burning
activity, showing a relatively uniform landscape. The second image, from October 16, 2022, shows
the aftermath of stubble burning, with darker patches clearly indicating fire-affected areas. The
third image, labeled ’Burn Area Mask’ and also dated October 16, 2022, precisely highlights the
locations impacted by the burning. The pink mask effectively outlines the burn areas, providing an
7Figure 6: Workflow of baseline method using traditional remote sensing indices
accurate assessment of the extent of stubble burning. Similarly, the method successfully detected
stubble-burnt patches in another region, as shown in Figure 8. This visual analysis is crucial for
monitoring agricultural practices and assessing their environmental impact.
Figure 7: Masked burnt area occurred on 16thOct, 2022
Figure 8: Masked burnt area occurred on 9thMay, 2023
A.1.4 Limitation of baseline method and other techniques
Remote sensing (RS) spectral index-based method track the spectral differences between two images-
normal and burned. It is merely a difference of temporal changes in pixel that may be due to any
reason. Some of the RS based indices to detect burning are- MNDFI (Modified normalized difference
fire index), BAI (Burning Area Index), NBR (Normalized Burning Ratio).
Simple Models (CNN, RCNN etc.) can be used but not promising in case of limited training data. It
may also not detect temporal or positional relation. It may not deal with data from different sensors
of different resolution, for different local conditions. Whereas, Foundational models are trained on
diverse data from different sources and sensors.
8A.2 Geospatial Foundation Model
Figure 9: The mask auto-encoder structure for pretraining Prithvi model on large scale multi-temporal
and multi-spectral satellite images [33].
Foundation models, trained on diverse datasets, are adapt at capturing temporal and spatial rela-
tionships, making them highly effective for complex tasks like stubble detection. Fine-tuning these
models with smaller, labeled datasets further enhances their accuracy. However, many farmers burn
stubble at night to avoid detection, making optical imagery alone insufficient. To address this, we need
to fine-tune the foundation model on a diverse range of data collected from multiple sensors. This data
should include optical and radar imagery, providing robust day/night coverage and mitigating issues
like cloud and noise interference. Such multi-modal data fusion cannot be effectively handled by
simple deep learning models. Instead, we require a foundation model trained on diverse datasets with
varying resolutions and sensor types. For this purpose, we selected the PRITHVI-100M geospatial
foundation model, which is specifically trained on three timestamps of Harmonized Landsat Sentinel
(HLS) data.
The PRITHVI-100M model represents a state-of-the-art approach to analyzing high-resolution
satellite imagery using advanced machine learning techniques. Built on the Vision Transformer (ViT)
architecture, it incorporates 3D patch embedding and 3D positional encoding to process multispectral
and temporal satellite data effectively. The model employs a self-supervised learning strategy based
on a masked auto-encoder (MAE). During training, multispectral images captured over various time
intervals and spectral bands are divided into smaller patches, which are flattened and processed by
the model. Its encoder-decoder structure generates a latent representation of the input, which is
used to reconstruct the original image. The training process is guided by a Mean Squared Error
(MSE) loss function to minimize reconstruction errors (Figure 9). The MAE learning strategy, which
involves masking certain patches during training, forces the model to learn underlying data patterns by
reconstructing the missing patches. This improves its ability to generalize and enhances its robustness
across applications like land cover classification, change detection, and environmental monitoring.
In this work, we fine-tune the PRITHVI-100M model on our dataset, using a Swin-B backbone
and a state-of-the-art U-Net regressor [49]. Unlike simpler models that struggle to integrate diverse
data types effectively, foundation models like PRITHVI-100M can leverage cross-modal learning to
capture nuanced relationships between different modalities. This capability significantly enhances
the accuracy and robustness of distinguishing stubble burning from other land disturbances.
PRITHVI-100M is particularly suitable for this task as it is trained on diverse earth observation data
across three timestamps, making it well-suited for change detection tasks. Additionally, it utilizes
six-band Harmonized Landsat Sentinel (HLS) data, including SWIR1 and SWIR2 bands. These
bands are highly effective in capturing the burning ratio, as demonstrated in the baseline method.
Overall, PRITHVI-100M represents a significant advancement in geospatial data analysis by combin-
ing ViT, 3D positional encoding, and MAE learning to deliver robust and scalable performance on
large-scale satellite imagery. After fine-tuning the model, the results will be validated against the
baseline method. However, challenges like detecting minor fires persist, underscoring the need for
further refinements.
9