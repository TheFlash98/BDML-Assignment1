Resolution-Agnostic Transformer-based Climate
Downscaling
Declan J. Curran∗1,1, Hira Saleem†1,1, Sanaa Hobeichi‡1,2, and Flora D. Salim§1,1
1School of Computer Science and Engineering, University of New South Wales, Sydney, New South
Wales, Australia
2ARC Centre of Excellence for the Weather of the 21stCentury and Climate Change Research
Centre, University of New South Wales, Sydney, New South Wales, Australia
Abstract
Understanding future weather changes at regional and local scales is crucial for
planning and decision-making, particularly in the context of extreme weather
events, as well as for broader applications in agriculture, insurance, and infrastruc-
ture development. However, the computational cost of downscaling Global Climate
Models (GCMs) to the fine resolutions needed for such applications presents a
significant barrier. Drawing on advancements in weather forecasting models, this
study introduces a cost-efficient downscaling method using a pretrained Earth Vi-
sion Transformer (Earth ViT) model. Initially trained on ERA5 data to downscale
from 50 km to 25 km resolution, the model is then tested on the higher resolution
BARRA-SY dataset at a 3 km resolution. Remarkably, it performs well without
additional training, demonstrating its ability to generalize across different reso-
lutions. This approach holds promise for generating large ensembles of regional
climate simulations by downscaling GCMs with varying input resolutions without
incurring additional training costs. Ultimately, this method could provide more
comprehensive estimates of potential future changes in key climate variables, aid-
ing in effective planning for extreme weather events and climate change adaptation
strategies.
1 Introduction
Global Climate model simulations are usually produced at coarse resolutions due to the significant
computational requirements involved in running these models World Climate Research Programme
(2014). These models typically operate at resolutions ranging from tens to hundreds of kilometers,
which are inadequate for capturing fine-scale atmospheric processes, such as convection, that drive
extreme weather events Solman et al .(2021). Additionally, finer resolutions are needed for certain
meteorological variables, like soil moisture content and precipitation, to aid in extreme weather events
planning and prediction Sun et al. (2019); Rampal et al. (2024).
Recent advances in machine learning (ML) have demonstrated the ability to model the underly-
ing dynamics of the atmosphere. Models like Pangu, Graphcast, Gencast, and NeuralGCM have
successfully captured fine-scale meteorological patterns and shown promising results in various
climate-related tasks Bi et al .(2022); Lam et al .(2022); Lai et al .(2023); Dueben et al .(2023).
∗d.curran@unsw.edu.au
†h.saleem@unsw.edu.au
‡s.hobeichi@unsw.edu.au
§flora.salim@unsw.edu.au
Preprint. Under review.These models leverage deep learning to enhance the spatial and temporal resolution of climate data,
providing insights that were previously unattainable with traditional ML methods. However, most
of these models are trained and tested on specific datasets and resolutions, limiting their ability to
generalise to new input datasets with finer resolutions.
In assessing the risks associated with climate change, it’s crucial to consider a comprehensive range of
possible changes to key climate variables, such as temperature and precipitation, at regional or local
scales Rampal et al .(2024). This approach helps address uncertainties in climate models, emissions,
and the contributions of natural variability. Traditional methods often rely on using Regional Climate
Models (RCMs) to downscale outputs from GCMs in a process known as dynamical downscaling.
While effective, this approach is highly computationally intensive Rampal et al .(2024). For example,
the New South Wales and Australian Capital Territory Regional Climate Modelling (NARCliM)
NARCLiM2.0 regional simulations required 14 to 18 months to complete projections to 2100, using
the best computational resources available in Australia from the National Computational Infrastructure
(NCI) Nishant et al .(2021). This effort cost $14 million and produced an ensemble of 30 simulations.
Given the limitations of downscaling a large ensemble of GCMs with RCMs, there is a need for
alternative approaches that can generate extensive ensembles of plausible future climate scenarios
with robust uncertainty estimates Bittner et al .(2023),Hobeichi et al .(2023). Machine learning (ML)
offers a promising solution to supplement or enhance existing global or regional climate modeling
efforts Rampal et al. (2024).
Given that GCMs are available at various resolutions, an ML model that is agnostic to input resolution
could enable the downscaling of a large number of GCMs, regardless of their original resolution.
Due to its affordability and significantly lower computational cost at the inference stage compared to
running an RCM, such an ML model could facilitate the generation of large ensembles, providing a
more comprehensive estimate of potential future changes in rainfall and other key climate variables.
To explore this potential, a pretrained ML-based downscaling algorithm, the Earth Vision Transformer
(Earth ViT), was tested on climate/weather data at much higher resolutions than those on which it
was originally trained. Additionally, we introduce an amendment to the loss function to penalise
results that violate the law of conservation of mass, ensuring that the value of a coarse grid accurately
reflects the cumulative property of the enclosed region within its boundary. This step is important for
making the ML model more physically consistent Sun et al. (2024).
2 Earth Vision-Transformer
The architecture of the Earth ViT is very similar to the weather forecasting model, Pangu-Weather.
The number of pressure levels have been reduced from 13 to 3 and the output head was modified
slightly to accommodate a higher resolution necessary for multi-resolution downscaling Bi et al .
(2022).
Loss Function We implemented a custom loss function that ensures the model maintains the con-
servation of mass property, which is crucial in physical simulations. The loss compares the mass
calculated from the low-resolution input images with the mass calculated from the super-resolved
output images. Combined with the Mean Squared Error loss, it ensures that the predicted image is as
close as possible to the ground truth in terms of pixel values and conserves the same total mass as the
input image, enforcing physical consistency.
MSE Loss =1
NPN
i=1(ytrue,i−ypred,i )2
Mass Conservation Loss = |PN
i=1ypred,i−PN
i=1yinput,i|
wherePN
i=1ypred,i is the total mass (sum of pixel values) in the predicted super-resolved image andPN
i=1yinput,i is the total mass in the low-resolution input image.
Total Loss = MSE Loss + Mass Loss
23 Experiments and Results
We trained Earth ViT and a ResNET on daily ERA5 Hersbach et al .(2020) climate variables for
2×downscaling tasks from 0.5◦to 0.25◦(Approx. 55km to 28km). The Earth-ViT was trained on
daily data from 2000/2001 and the ResNET was trained on data from 2000 - 2005. Both models
were tested on data from 2006. The ResNETs were only trained on surface data; results are only
reported across four surface variables (10-meter u/v wind components, 2-meter temperature, total
precipitation) .
These models were then applied to a similar 2 ×downscaling task on BARRA-SY data Su et al .(2022)
in 2006 from 3km to 1.5km. Note that the model was not finetuned or trained on any data at this fine
resolution, but the climate variables remain the same. As a comparison, one version of the Earth-ViT
was also trained directly on BARRA-SY . Details of training hyperparameters is given in Appendix
A.1. The details of datasets are given in Appendix B.
We evaluated the models across all surface variables using three performance metrics: RMSE, PSNR,
and SSIM. RMSE measures prediction accuracy, while PSNR (Peak Signal-to-Noise Ratio) assesses
the quality of the reconstructed image by comparing the maximum possible signal to the noise.
SSIM (Structural Similarity Index) evaluates the structural similarity between predicted and reference
images, focusing on aspects like luminance and contrast. These metrics provide a comprehensive
evaluation of the models’ performance Dawa et al. (2022).
The Earth ViT model was compared against ResNET and Bilinear Interpolation, which are established
benchmarks in super-resolution tasks. This comparison highlights Earth ViT’s effectiveness in
improving downscaling performanceDawa et al .(2022). The performance results for downscaling
2-meter temperature are shown in Table 1 and 2. Figure1 (Figure2) displays the average 2-meter
Figure 1: ERA5 downscaling of 2-meter Temperature using Earth ViT with modified loss function.
From left to right: coarse resolution (50km), ground truth high resolution (25km), predicted high
resolution (25km)
Figure 2: ERA5 downscaling of 2-meter Temperature using Earth ViT with modified loss function.
From left to right: coarse resolution (50km), ground truth high resolution (25km), predicted high
resolution (25km)
temperature for the testing year across both the coarse resolution and the fine resolution of the truth
and prediction when downscaling ERA5 (BARRA-SY coarsened) from 50km to 25km (from 3km to
1.5km). The results demonstrate a strong overall agreement between the truth and the prediction in
terms of both magnitude and spatial consistency.
Results for downscaling precipitation, u_component_of_wind and v_component_of_wind are given
in Appendix C.
3Table 1: ERA5 Results on Temperature from 50km to 25km downscaling
Model RMSE ↓ PSNR ↑ SSIM↑ Carbon
(kgCO 2)
Bilinear Interpolation 0.279 11.084 0.995 0.452
ResNET 8.541 -18.611 0.969 5.481
ResNET - Modified Loss 16.632 -24.413 0.679 5.826
Earth ViT 0.023 32.576 0.983 1.603
Earth ViT - Modified Loss 0.019 34.061 0.987 1.805
Table 2: BARRA-R Results - Trained on ERA5 - tested on BARRA-R
Model RMSE ↓ PSNR ↑ SSIM↑ Carbon
(kgCO 2)
Bilinear Interpolation 0.138 17.269 0.992 0.002
ResNET 1.082 1.647 0.984 0.002
ResNET - Modified Loss 3.199 -9.807 0.755 0.003
Earth ViT 0.031 30.221 0.973 0.040
Earth ViT (TRAINED ON BARRA) 0.031 30.229 0.964 0.194
Earth ViT - Modified Loss 0.031 30.375 0.983 0.043
Earth ViT - Modified Loss
(TRAINED ON BARRA)0.029 30.690 0.969 0.173
We can see that penalising the model for physical discrepancies make it perform better acorss most
of the metrics. In table 2, we can see the performance of EarthViT trained on BARRA is almost
same as the ERA5 pre-trained EarthViT. Therefore, we can deduce that The pretrained Earth Vision
Transformer (Earth ViT) model can generalise well across varying resolutions (50 km and 3 km) and
datasets (ERA5 and BARRA-R); even with less training data.
4 Discussion
A resolution-agnostic model provides significant benefits for downscaling various generations of
climate models, such as CMIP5, CMIP6, and the upcoming CMIP7. Using the same model for each
ensemble without needing to alter resolutions or undergo additional training streamlines the process
and cuts down on computational costs. By generating large ensembles of regional projections, Earth
ViT could enable comprehensive climate risk assessments that are both scalable and cost-effective,
benefiting sectors such as agriculture, disaster management, and infrastructure planning
Unlike traditional Regional Climate Models (RCMs), Earth ViT offers a more accessible alternative
for producing high-resolution climate projections. The introduction of a mass conservation loss
function further improved the model’s performance, ensuring adherence to fundamental physical laws.
This integration is vital for applying the model to regional climate studies and predicting extreme
weather events. Not to mention that each of the models presented here are lightweight with large
carbon savings over equivalent dynamical downscaling models.
Future research will focus on refining Earth ViT to enhance its robustness across different regions
and scenarios. The model’s potential to adapt to new regions or datasets through transfer learning
presents further opportunities for expanding its applicability.
45 Acknowledgement
SH acknowledges the support of the Australian Research Council Centre of Excellence for the
Weather of the 21stCentury (CE230100012). The work was undertaken using resources from the
National Computational Infrastructure (NCI), which is supported by the Australian Government.
References
Kaiming Bi, Xiangyu Chen, Jingyu Tan, Wei Bao, Bo Sun, Yingbin Zhang, Ting Yan, Zhenwei Wang,
Lingxi Xie, Fan Sun, and Jian Sun. 2022. Pangu-Weather: A 3D High-Resolution Model for Fast
and Accurate Global Weather Forecast. arXiv:2211.02556 [cs.CV] https://arxiv.org/abs/
2211.02556
Matthias Bittner, Sanaa Hobeichi, Muhammad Zawish, Samo Diatta, Remigious Ozioko, Sharon Xu,
and Axel Jantsch. 2023. An LSTM-based downscaling framework for Australian precipitation
projections. In NeurIPS 2023 Workshop on Tackling Climate Change with Machine Learning .
Lepcha Dawa, Goyal Bhawna, Dogra Ayush, and Vishal Goyal. 2022. Title of the Article (Replace
with Actual Title). Information Fusion 91 (2022), 154–168. https://doi.org/10.1016/j.
inffus.2022.10.007
Peter Dueben, Peter Bauer, Tim Palmer, Laure Zanna, Yaniv Ben-Haim, Jiwoo Han, and Peter
Korn. 2023. Neural general circulation models for weather and climate. Nature (2023). https:
//doi.org/10.1038/s41586-023-05877-1
Hans Hersbach, Bill Bell, Paul Berrisford, Shoji Hirahara, András Horányi, Joaquín Muñoz-Sabater,
Julien Nicolas, Carole Peubey, Raluca Radu, Dinand Schepers, et al .2020. The ERA5 global
reanalysis. Quarterly Journal of the Royal Meteorological Society 146, 730 (2020), 1999–2049.
https://doi.org/10.1002/qj.3803
Sanaa Hobeichi, Nidhi Nishant, Yawen Shao, Gab Abramowitz, Andy Pitman, Steve Sherwood, Craig
Bishop, and Samuel Green. 2023. Using machine learning to cut the cost of dynamical downscaling.
Earth’s Future 11, 3 (2023), e2022EF003291. https://doi.org/10.1029/2022EF003291
Fan Lai, Xu Cao, Lingxi Xie, Fan Sun, and Jian Sun. 2023. GenCast: Diffusion-based ensemble
forecasting for medium-range weather. arXiv:2312.15796 [cs.CV] https://arxiv.org/abs/
2312.15796
Rupert Lam, Jonathan Weyn, Stephen Tran, Meire Fortunato Ott, Jonathan Heek, and Shakir
Mohamed. 2022. GraphCast: Learning skillful medium-range global weather forecasting.
arXiv:2212.12794 [cs.LG] https://arxiv.org/abs/2212.12794
N. Nishant, J. P. Evans, G. Di Virgilio, P. Hoffmann, and L. V . Alexander. 2021. Introducing
NARCliM1.5: Evaluating the Performance of Regional Climate Projections for Southeast Australia
for 1950–2100. Earth’s Future 9, 12 (2021), e2021EF002545. https://doi.org/10.1029/
2021EF002545
Neelesh Rampal, Sanaa Hobeichi, Peter B Gibson, Jorge Baño-Medina, Gab Abramowitz, Tom
Beucler, Jose González-Abad, William Chapman, Paula Harder, and José Manuel Gutiérrez.
2024. Enhancing Regional Climate Downscaling through Advances in Machine Learning. Ar-
tificial Intelligence for the Earth Systems 3, 2 (2024), 230066. https://doi.org/10.1175/
AIES-D-23-0066.1
S. Solman, D. Jacob, A. Frigon, C. Teichmann, M. Rixen, W. Gutowski, and I. Lake. 2021. The future
scientific challenges for CORDEX. https://cordex.org/wp-content/uploads/2021/05/
The-future-of-CORDEX-MAY-17-2021-1.pdf . Accessed: 2024-08-05.
Chun-Hsu Su, Imtiaz Dharssi, John Le Marshall, Tan Le, Susan Rennie, Andy Smith, Christian
Stassen, Peter Steinle, Joshua Torrance, Carl Wang, et al .2022. BARRA2: Development of
the next-generation Australian regional atmospheric reanalysis. http://www.bom.gov.au/
research/publications/researchreports/BRR-067.pdf
5Hao Sun, Chuangchuang Cai, Hongxing Liu, and Bo Yang. 2019. Microwave and Meteorological
Fusion: A method of Spatial Downscaling of Remotely Sensed Soil Moisture. IEEE Journal of
Selected Topics in Applied Earth Observations and Remote Sensing 12, 4 (2019), 1107–1119.
https://doi.org/10.1109/JSTARS.2019.2901921
Yongjian Sun, Kefeng Deng, Kaijun Ren, Jia Liu, Chongjiu Deng, and Yongjun Jin. 2024. Deep
learning in statistical downscaling for deriving high spatial resolution gridded meteorological data:
A systematic review. ISPRS Journal of Photogrammetry and Remote Sensing 208 (2024), 14–38.
https://doi.org/10.1016/j.isprsjprs.2023.12.011
World Climate Research Programme. 2014. CMIP6 - Coupled Model Intercomparison Project Phase
6.https://pcmdi.llnl.gov/CMIP6/ . Accessed: 2024-04-29.
A Experiments
A.1 Hyperparameters
Table 3: Model Training Hyperparameters
Parameter Value
Learning rate 1e-4
Scaling factor 2
Large kernel size 9
Small kernel size 3
No of channels 64
No of blocks 16
Optimizer Adam
A.2 Hardware Requirements
All models were trained for 50 Epochs, with the ResNETS on NVIDIA V100 GPUs with 32GB RAM
and Earth-ViTs on NVIDIA A100 80 GB RAM GPUs.
B Datasets
B.1 ERA5
We used ERA5 reanalysis data Hersbach et al .(2020), selecting surface variables (10-meter U/V
wind components, 2-meter temperature, total precipitation) and pressure-level variables (geopotential,
specific humidity, temperature, 10-meter U/V wind components) at three pressure levels (hPa) (50,
100, and 150). These variables were regridded to 0.5 degrees for downscaling.
B.2 BARRA-SY
BARRA-SY is an ultra-high-resolution dataset of the Australian BARRA-R reanalysis dataset Su
et al.(2022). At a 1.5 km resolution, it covers the Sydney and coastal New South Wales (NSW)
region (28.0 °S to 37.5 °S latitude and 147.0 °E to 154.0 °E longitude). The variables selected were
consistent with those used in ERA5. Notably, temperature is recorded at 1.5 meters in BARRA-SY ,
whereas it is recorded at 2 meters in ERA5. Despite this difference, our results have shown that the
model’s ability to generalise has not been affected.
6C Results
Table 4: Results for precipitation (pr), u_component_of_wind (u_wind), v_component_of_wind
(v_wind) - Trained on ERA5
Model RMSE ↓ PSNR ↑ SSIM↑
pr u_wind v_wind pr u_wind v_wind pr u_wind v_wind
Bilinear Interpolation 3.66 0.22 0.22 88.71 13.00 13.16 0.99 0.99 0.98
ResNET 0.001 2.05 1.71 75.17 -6.26 -4.65 0.97 0.92 0.92
ResNET - Physics
loss0.00 -9.807 0.755 72.73 n/a n/a 0.77 n/a n/a
Earth ViT 0.12 0.034 0.039 18.22 29.25 28.15 0.99 0.98 0.98
Earth ViT - Physics
Loss0.11 0.029 0.034 18.67 30.46 29.24 0.99 0.98 0.98
Table 5: Results for precipitation (pr), u_component_of_wind (u_wind), v_component_of_wind
(v_wind) - Trained on ERA5 - tested on BARRA-R
Model RMSE ↓ PSNR ↑ SSIM↑
pr u_wind v_wind pr u_wind v_wind pr u_wind v_wind
Bilinear Interpolation 0.07 0.14 0.14 25.72 16.97 16.92 n/a 0.97 0.97
ResNET 0.45 1.43 1.88 12.2 -1.70 -3.46 0.88 0.93 0.92
ResNET - Physics
Loss0.52 2.96 3.55 7.98 -9.10 -10.51 0.61 0.30 0.36
Earth ViT 0.05 0.04 0.04 26.90 26.82 27.38 0.90 0.97 0.97
Earth-ViT
(TRAINED ON
BARRA)0.06 0.03 0.03 25.95 29.61 29.85 0.90 0.97 0.96
Earth-ViT - Physics
Loss0.02 0.04 0.04 25.17 27.21 27.30 0.91 0.98 0.97
Earth ViT - Physics
loss (TRAINED ON
BARRA)0.06 0.03 0.03 27.18 29.85 30.22 0.91 0.97 0.96
7