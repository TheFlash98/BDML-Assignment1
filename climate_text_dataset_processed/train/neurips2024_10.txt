Carbon-Aware Spatio-Temporal Workload
Distribution in Cloud Data Center Clusters Using
Reinforcement Learning
Soumyendu Sarkar†∗,Antonio Guillen†,Vineet Gundecha†,Avisek Naug†,
Ricardo Luna Gutierrez ,Sajad Mousavi ,Paolo Faraboschi ,Cullen Bash
Hewlett Packard Enterprise (Hewlett Packard Labs)
{soumyendu.sarkar, antonio.guillen, vineet.gundecha, avisek.naug,
rluna, sajad.mousavi, paolo.faraboschi, cullen.bash} @hpe.com
Abstract
Reducing the environmental impact of cloud computing requires efficient workload
distribution across geographically dispersed Data Center Clusters (DCCs). In
this paper, we introduce Green-DCC, which proposes Reinforcement Learning-
based hierarchical controller techniques to dynamically optimize temporal and
geographical workload distribution between data centers that belong to the same
DCC. The environment models non-uniform external weather, carbon intensity,
computing resources, cooling capabilities, and dynamic bandwidth costs, which
provide constraints and interdependencies. We adapted and evaluated various
reinforcement learning approaches, comparing their aggregate carbon emissions
across the DCC, demonstrating Green-DCC’s effectiveness for controlling and
testing advanced data center control algorithms for sustainability.
Workload -+ Data Center 
Level (Local) Con 
Weather ... 
Grid Carbon IA !rl. l 
Intensity ~ flm -+ 
dJ;n ~,-4. ~ "'ft 
~ Geographic Shift 
of Workload ) 
Data Center Data Center Cluster 
Level (Global) Control 
Data Center 
Figure 1: Spatio temporal hierarchical workload distribution.
1 Introduction
Major cloud service providers and corporations often have geographically distributed data centers,
enabling enterprise users to schedule large-scale batch workloads across various locations. These
decisions are influenced by factors such as weather, grid carbon intensity, workload characteristics,
compute instance availability, latency requirements, and energy costs. This paper aims to develop
a hierarchical machine learning framework for distributing large-scale batch workloads from mul-
tiple enterprise users across data centers to reduce sustainability metrics like carbon emissions as
∗Corresponding author
†These authors contributed equally
Tackling Climate Change with Machine Learning: workshop at NeurIPS 2024.shown in Figure 1. The dynamic nature of workload requirements, weather patterns, carbon in-
tensity fluctuations, energy pricing, and system states with workload reassignments renders static
solutions ineffective, motivating the use of reinforcement learning (RL) algorithms for our workload
distribution framework. Our main contributions include hierarchical control using RL algorithms to
simultaneously shift load in real-time within and across data centers for sustainability goals and a
customizable data center cluster simulator.
2 Related Work
Geographical workload distribution Ahmad et al. (2020) strategies vary based on factors like work-
load type, energy sources, and data center resources. Prior approaches, such as Stochastic Cost
Minimization Zinober (1994); Guo et al. (2013); Chang et al. (2019) and Mixed Integer Linear
Programming Khalil et al. (2019), often rely on static solutions or relax constraints, limiting their
effectiveness in dynamic environments. Our work addresses these limitations by incorporating a
holistic, reinforcement learning-based approach that considers bandwidth, delay models, carbon
footprint, and heterogeneous data center specifications in an online setting. By prioritizing sustain-
ability alongside performance, our work provides a more comprehensive approach to optimizing data
center operations, focusing on reducing environmental impact. Also, holistic optimization of the data
centers and other reinforcement learning optimizations have been explored in Naug et al. (2024);
Sarkar et al. (2024a,b,c, 2023a,b,c,d); Naug et al. (2023a,b).
3 System Description
Our proposed system optimizes workload distribution across a geographically distributed Data
Centers cluster (DCC), leveraging a hierarchical multi-agent framework. This system is structured
to dynamically adjust to real-time operational conditions, effectively managing workload shifts to
reduce carbon footprint. It can be extended to reduce energy consumption, water usage, energy cost,
etc.
3.1 Hierarchical Framework
The architecture employs a hierarchical framework to optimize workload distribution across geograph-
ically dispersed data centers. It comprises a top-level (global) agent and multiple lower-level (local)
agents. The top-level agent manages global decision-making, strategically distributing workloads
between data centers based on factors like weather, and carbon intensity, which can be extended to
energy cost. Figure 2 illustrates this geographic load shifting strategy, where tasks are dynamically
moved between data centers to optimize resource utilization and reduce environmental impact. Lower-
level agents handle localized operations within each data center, focusing on temporal workload
scheduling. Figure 2 also shows the temporal load shifting strategy, where non-critical tasks are
deferred using a Deferred Task Queue (DTQ) for processing during more favorable conditions. This
combined approach of geographic and temporal load shifting enables our approach to optimize data
center operations’ sustainability and efficiency at both global and local levels.
3.2 Dynamic Bandwidth Cost Model
We use a dynamic model that defines the cost of transmitting data across data centers in a DCC.
Traditional models primarily use geographical distance as a basis for calculating transmission costs.
However, such models often lead to trivial solutions and suboptimal resource utilization, as they
may promote workload migration to data centers with minimal carbon intensity, disregarding other
operational variables and costs, leading to resource underutilization Guo et al. (2013); Wei et al.
(2022). To address these challenges, we introduce a cost model, bij(t), that incorporates both the
geographical distance and the actual transferred workload, measured in megawatts (MW), between
data centers giandgj. The model aims to balance workload distribution by penalizing transfers based
solely on lower carbon intensity. Detailed formulation of the cost is discussed in further detail in the
appendix and will be published in open source.
2Top-Level Agent
DC1
DC1
DC2DC3tUtilization
DC2
tUtilization
DC3
tUtilizationGeographic Load Shifting
DC3
tUtilizationTemporal Load Shifting
t
TasksDeferred Task Queue Original Work.
Geog. Shifted
Original Work.
Temp. ShiftedFigure 2: Illustration of the Green-DCC framework. The left side shows the geographic load shifting strategy
where tasks are dynamically moved between data centers (DC1, DC2, DC3) based on the Top-Level Agent’s
decisions. The center depicts the geographic distribution of data centers and the Top-Level Agent. The right side
depicts the temporal load shifting strategy within a data center (e.g., DC3), where non-critical tasks are deferred
to periods of lower CI, lower external temperatures, or lower utilization to reduce carbon emissions and optimize
energy consumption. Together, these strategies enable intelligent load management both geographically and
temporally to enhance the sustainability and efficiency of data center operations.
Carbon Emissions with Different Controls 
3650 ~ 3600 
t,J) 3550 1/ w 3500 NZ oz 3450 ~ (.) 0 I- 3400 z 3350 1/ 3300 
No Action High Level RL High+Low Level Hierarchical RL 
RL 
CONTROL ALGORITHMS 
Figure 3: Tones of CO2 produced by various RL agents.
3.3 Dynamic Workload Adjustment
Our approach can manage dynamic workload transfers among DDCs, considering the inherent
physical and network limitations that introduce delays in real-time data transfers. Transferred batch
workloads are not processed immediately but are scheduled to start in the subsequent timestep,
accurately reflecting the physical data transfer durations required at the receiver data center. At each
timestep, the receiver data center evaluates its capacity to handle both the expected workload for that
timestep and the incoming transferred batches. If sufficient capacity is available, the batch workload
is processed. Otherwise, any excess workload is reverted and processed at the sender’s center within
the current timestep instead of being dropped.
3.4 MDP formulation
Based on the proposed system model we present our MDP formulation for the hierarchical reinforce-
ment learning problem in table 1:
Table 1: Summary of MDP Components in Hierarchical RL environment
Component Top-Level Lower-Level
S ST SLS
A AT ALS
R R(t) =−(P
g∈DDCDCE g)×10−6
P Based on DC model, bandwidth constraints, operational delays
3ConfigAgent
No Action High Level RL High + Low Level RL PT Hirarchical RL
CO2 3645±3 3515±3 3512±3 3435±5
Table 2: Benchmarking different baseline and RL approaches for spatio-temporal load shifting. No action
implies no temporal or spatial load shifting. High Level RL implies only spatial load shifting. High + Loevel
Level RL Pretrained implies actively learning top level agent with pretrained low level agents. Hierarchical RL
implies the standard set up where all agents train from scratch in a hierarchical manner. ±shows the standard
deviation over the 3seeds.
Config.Hierarchical RL Algorithm
PPO A2C APPO
CO2 3435±53701±33708±3
Table 3: Tones of CO2 produced by different RL
algorithms. ±shows the standard deviation over
the3seeds.αAgent
Random Do Nothing HRL
0.0 3697±3 3645 3435±5
0.2 3741±6 3645 3530±6
Table 4: Tones of CO2 produced by various agents
on the HRL configuration for different cost levels
(α) for workload transfer between DCs. ±shows
the standard deviation over the 3seeds.
Description of symbols: S: State Space, A: Action Space, R: Reward Function, P: Transition
Probabilities, ST: Top-Level State (Aggregated metrics: DC Capacity, Current Workload, Weather,
CI),SLS: Load Scheduling State (Time, workload, DTQ tasks, weather, power, CI), AT: Top-Level
Action (Workload transfer ratios between DCs), ALS: Load Scheduling Action (0: Store, 1: Compute
Immediate, 2: Max Throughput), DCE: Data center Total Carbon Emission, DDC: Distributed Data
Center
4 Benchmark Evaluation
We benchmarked 3hierarchical implementations of three different algorithms (A2C, PPO, APPO)
from RLLib (Liang et al., 2018) for our work. Each algorithm was trained for 1000 episodes using
3different seeds. For all algorithms, agents are trained simultaneously, following the hierarchical
sequence. We evaluated the performance of the three algorithms over an environment episode and
measured the CO2 produced. Table 3 shows the performance, in terms of tones of CO2, of each
algorithm averaged over the three seeds. PPO significantly outperforms all other algorithms by
minimizing carbon footprint the most.
We evaluate the performance of RL on three different configurations and an additional 2 simpler
baselines: High Level RL (Train the top level agent with the DC cluster level geographic distribution
of workload between DCs), High + Low Level RL PT (High Level + Low-Level Pretrained - DC
level controls), and Hierarchical RL (fully Hierarchical Reinforcement Learning). The High Level
RL configuration trains an RL controller for top level agent while all lower-level agents always take
action 1. High + Low Level RL PT trains the top level agent while all low level agents take actions
following a pretrained policy, which has been individually trained in their specific DC. HRL is a truly
hierarchical approach where all agents are trained at the same time. In all cases, we use PPO as the
RL algorithm. We use two basic baselines to compare the performance: Random and No Action. The
Random baseline picks random actions for all training agents at each step. No Action always picks
action 1 for low level agents, while top level agent does not move any loads. The results obtained
from this evaluation are shown in Table 2. As shown in the results, HRL shows most promise and is
the most complex problem to solve.
Additionally, we evaluate the effect that the αhyperparameter for workload transfer might have on
the performance of HRL. For this evaluation, we use PPO as the HRL algorithm. Similar to previous
evaluations we measure the tones of CO2 produced over 3different seeds and average results are
shown in Table 4.
5 Conclusion
Green-DCC represents a significant step forward in comprehensive spatiotemporal workload opti-
mization in data center clusters using hierarchical reinforcement learning. By providing a realistic,
comprehensive benchmark environment that captures the complexities of geographical and temporal
4workload shifting, we enable researchers and practitioners to develop innovative solutions that can
dramatically reduce the carbon footprint of data center clusters. We believe that Green-DCC will
play a crucial role in driving the development of more sustainable cloud computing practices, helping
to align the rapid growth of digital infrastructure with our global environmental goals.
5References
I. Ahmad, M. I. K. Khalil, S. A. A. Shah, Optimization-based workload distribution in geographically
distributed data centers: A survey, Int. J. Commun. Syst. 33 (2020) e4453. doi: 10.1002/dac.
4453 .
A. S. Zinober, Variable structure and Lyapunov control, volume 193, Springer Berlin, 1994.
Y . Guo, Y . Gong, Y . Fang, P. P. Khargonekar, X. Geng, Energy and network aware workload
management for sustainable data centers with thermal storage, IEEE Transactions on Parallel and
Distributed Systems 25 (2013) 2030–2042.
Y .-C. Chang, N. Roohi, S. Gao, Neural lyapunov control, Advances in neural information processing
systems 32 (2019).
M. I. K. Khalil, I. Ahmad, A. A. Almazroi, Energy efficient indivisible workload distribution in
geographically distributed data centers, IEEE Access 7 (2019) 82672–82680.
A. Naug, A. Guillen, R. L. Gutierrez, V . Gundecha, C. Bash, S. Ghorbanpour, S. Mousavi, A. R.
Babu, D. Markovikj, L. D. Kashyap, D. Rengarajan, S. Sarkar, SustainDC: Benchmarking for
sustainable data center control, in: The Thirty-eight Conference on Neural Information Processing
Systems Datasets and Benchmarks Track, 2024. URL: https://openreview.net/forum?id=
UYgE9IfQIV .
S. Sarkar, A. Naug, R. Luna, A. Guillen, V . Gundecha, S. Ghorbanpour, S. Mousavi, D. Markovikj,
A. R. Babu, Carbon footprint reduction for sustainable data centers in real-time, in: Proceedings
of the AAAI Conference on Artificial Intelligence, volume 38, 2024a, pp. 22322–22330.
S. Sarkar, A. Naug, A. Guillen, R. Luna, V . Gundecha, A. Ramesh Babu, S. Mousavi, Sustainability
of data center digital twins with reinforcement learning, Proceedings of the AAAI Conference on
Artificial Intelligence 38 (2024b) 23832–23834. URL: https://ojs.aaai.org/index.php/
AAAI/article/view/30580 . doi: 10.1609/aaai.v38i21.30580 .
S. Sarkar, A. Guillen-Perez, Z. Carmichael, V . Gundecha, A. Naug, R. L. Gutierrez, A. R. Babu,
C. Bash, Cfd surrogates for data center sustainability using 3d u-net convolutional neural network,
in: 2024 23rd IEEE Intersociety Conference on Thermal and Thermomechanical Phenomena in
Electronic Systems (ITherm), 2024c, pp. 1–9. doi: 10.1109/ITherm55375.2024.10709430 .
S. Sarkar, A. Naug, R. Luna Gutierrez, A. Guillen, V . Gundecha, A. Ramesh Babu, C. Bash, Real-time
carbon footprint minimization in sustainable data centers with reinforcement learning, in: NeurIPS
2023 Workshop on Tackling Climate Change with Machine Learning, 2023a.
S. Sarkar, A. Naug, A. Guillen, R. Luna Gutierrez, V . Gundecha, S. Ghorbanpour, S. Mousavi,
A. Ramesh Babu, Sustainable data center modeling: A multi-agent reinforcement learning
benchmark, in: NeurIPS 2023 Workshop on Tackling Climate Change with Machine Learning,
2023b.
S. Sarkar, A. Guillen, Z. Carmichael, V . Gundecha, A. Naug, A. Ramesh Babu, R. Luna Gutierrez,
Enhancing data center sustainability with a 3d cnn-based cfd surrogate model, in: NeurIPS 2023
Workshop on Tackling Climate Change with Machine Learning, 2023c.
S. Sarkar, A. Naug, A. Guillen, R. L. Gutierrez, S. Ghorbanpour, S. Mousavi, A. R. Babu, V . Gundecha,
Concurrent carbon footprint reduction (c2fr) reinforcement learning approach for sustainable data
center digital twin, in: 2023 IEEE 19th International Conference on Automation Science and
Engineering (CASE), 2023d, pp. 1–8. doi: 10.1109/CASE56687.2023.10260633 .
A. Naug, A. Guillen, R. Luna Gutiérrez, V . Gundecha, S. Ghorbanpour, L. Dheeraj Kashyap,
D. Markovikj, L. Krause, S. Mousavi, A. R. Babu, S. Sarkar, Pydcm: Custom data center models
with reinforcement learning for sustainability, in: Proceedings of the 10th ACM International
Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation, BuildSys
’23, Association for Computing Machinery, New York, NY , USA, 2023a, p. 232–235. URL:
https://doi.org/10.1145/3600100.3623732 . doi: 10.1145/3600100.3623732 .
6A. Naug, A. Guillen, R. Luna Gutierrez, V . Gundecha, S. Ghorbanpour, S. Mousavi, A. Ramesh Babu,
S. Sarkar, A configurable pythonic data center model for sustainable cooling and ml integration,
in: NeurIPS 2023 Workshop on Tackling Climate Change with Machine Learning, 2023b.
W. Wei, H. Gu, K. Wang, J. Li, X. Zhang, N. Wang, Multi-dimensional resource allocation in
distributed data centers using deep reinforcement learning, IEEE transactions on network and
service management (2022).
E. Liang, R. Liaw, R. Nishihara, P. Moritz, R. Fox, K. Goldberg, J. E. Gonzalez, M. I. Jordan,
I. Stoica, RLlib: Abstractions for distributed reinforcement learning, in: International Conference
on Machine Learning (ICML), 2018.
7A Dynamic Cost Model
The cost function is defined as:
bij(t) =d(i, j) +α·actual_transfer_mw (1)
Here, d(i, j)denotes the geographical distance between the data centers. The term
actual_transfer_mw is further explained in Subsection B. The hyperparameter αadjusts the im-
pact of the transfer workload on the cost model, allowing tuning based on specific operational
requirements. The total bandwidth cost, or hysteresis cost, for transferring workloads between data
centers in a single timestep, referred to as the workload hysteresis H(t), is computed as:
H(t) =X
r∈A top(t)bij(t) (2)
where each rin the set of transfers provides the sender iand the receiver j. This dynamic bandwidth
cost model ( H(t)), captures the additional power consumption incurred due to workload transfers,
which can lead to increased CO2 emissions.
B Dynamic Workload Adjustment
Green-DCC can manage dynamic workload transfers among DDCs, considering the inherent physical
and network limitations that introduce delays in real-time data transfers. Each transfer is processed
through the following detailed steps:
1.Capacity and Workload Retrieval : Determine the maximum capacities ( scapacity , rcapacity )
and current or expected workloads ( Wt
i, Wt+1
j) for the sender iand receiver jdata centers.
2.Transfer Computation : Calculate the intended transfer workload in MW as:
transfer_amount_mw =Wt
i·rij(t)·scapacity
3.Receiver Capacity Assessment : Evaluate the feasible amount of workload the receiver can
handle, given its next-step capacity:
actual_transfer_mw = min( TAM, rcapacity·(1−Wt+1
j))
where TAM represents transfer _amount _mw.
4.Final Workload Distribution : Adjust the sender and receiver workloads to reflect the
transfer:
Wt
i= (scapacity·Wt
i−actual_transfer_mw )/scapacity
Wt+1
j= (rcapacity·Wt+1
j+actual_transfer_mw )/rcapacity
C Environment Definition
Based on the above Green-DCC environment, the workload scheduling environment is formulated as
a Markov Decision Process (MDP) by the tuple ⟨S,A,R, γ,P⟩where, Sis the state space, Ais the
action space, Ris the reward function, γis the discount factor, and Pis the transition probability
function.
C.1 State Space ( S)
The state describes the operational status from a global perspective (Top-Level agent) and data center
details (Lower-Level agents), incorporating factors like capacity, workload, and weather.
TheTop-Level agent’s state space encompasses aggregated and critical metrics from all data cen-
ters within the cluster, providing a macroscopic view of the entire network’s operational status.
These include: Data Center Capacity (dc_capacity ) indicating the maximum workload capacity in
8megawatts (MW) for each data center. Current Workload (Wt,i) indicates workload levels for each
data center iat time t.Weather Conditions (weather ) captures the local weather conditions for
each data center location, impacting energy use and cooling requirements.
Each type of lower-level agent within the data centers has its own specific state space, tailored
to its operational responsibilities and decision-making requirements: Load Scheduling Agent
State (ls_state ) includes the time of day (sine/cosine encoded), current workload utilization, relative
number of tasks in the DTQ, current and forecast weather over the next two hours. The HV AC Control
Agent State (hvac _state ) includes the time of day (sine/cosine encoded), ambient temperature,
current cooling setpoint, current zone air temperature, power consumption of HV AC and IT equipment,
and current CI.
C.2 Action Space ( A)
The action space within our hierarchical model is divided into two primary layers, reflecting the
decisions made by the Top-Level agent and subsequent adjustments by lower-level agents within
each data center.
Top-Level Agent Atop :
•The agent evaluates the necessity and feasibility of workload transfers between each pair of
data centers ( i, j).
•For each pair, the agent decides the amount of workload to be transferred from data center i
toj, considering the current DCC state. This decision is represented by the ratio of workload
to transfer (rij(t)), a continuous variable where rij(t)∈[−1.0,1.0]specifies the fraction
of the current workload ( Wt,i) to be transferred, with positive values indicating transfers
from itoj, and negative values indicating transfers from jtoi.
•The number of potential transfers evaluated can be as large as |T|, where |T|is the total
number of possible directed transfer paths between data centers in the DCC, calculated as
|T|= N
2
=N(N−1)
2.
The Top-Level action vector, Atop(t), includes the workload transfer decisions between data centers:
Atop(t) =[
i<j, i,j ∈|DDC|{rij(t)}
where rij(t)represents the ratio of workload transferred from data center ito data center jat time t.
Lower-Level Agents Alower After the top-level agent geographically redistributes the workload,
lower-level agents within each data center perform operations to improve sustainability and efficiency.
Each data center has two specialized agents:
Temporal Load Scheduling Agent ( agent _ls): Manages workload execution and temporary schedul-
ing shiftable tasks, with three actions: i) Store Shiftable Workloads (0): Process only non-shiftable
tasks and store shiftable tasks in the DTQ. ii) Compute All Immediate Tasks (1): Process both
non-shiftable and shiftable tasks of the current timestep. iii) Maximize Throughput (2): Process all
current tasks and as many deferred tasks as possible, limited by the data center’s capacity.
HV AC Control Agent ( agent _hvac ): Adjusts HV AC settings to optimize environmental conditions
with three actions: i) Decrease Setpoint (0): Reduce the HV AC setpoint by 1 °C. ii) Maintain Setpoint
(1): Keep the HV AC setpoint unchanged. iii) Increase Setpoint (2): Increase the HV AC setpoint by
1°C.
Thus the lower-level action vector, Alower(t), is a combination of the actions taken by each of the
specialized agents within each data center:
Alower(t) =[
dc∈|DDC|{als(t),ahvac(t)}
The unified action vector A(t)provides a holistic view of the operational decisions across the DDC,
combining both the Top-Level and lower-level actions:
A(t) = (Atop(t),Alower(t))
9These actions ensure that each agent within the data center can respond effectively to both the
immediate operational demands set by the Top-Level agent’s decisions and the long-term goals of
reducing energy consumption and carbon emissions. The coordination between these agents allows
the data center to adaptively manage workload and energy resources in a manner that supports both
operational efficiency and environmental sustainability.
C.3 Reward Function ( R)
The hysteresis effect H(t)along with the IT energy consumption (ITE load) and Data Center cooling
energy consumption (Cooling load), is used to calculate the total energy consumption of the data
center as:
DTE =ITE load +Cooling load +H(t)
1000×timesteps _per_hour(kWh )
where the timesteps_per_hour is 4 for 15-minute timesteps and DTE represents
dc_total _energy _kWh .
The reward function is designed to minimize the energy consumption footprint due to workload
scheduling and is calculated as:
R(t) =−
X
g∈DDCDTEg
×10−6
C.4 Transition Probabilities ( P)
The transition probabilities are influenced by the underlying data center model (Section 3.1), the
bandwidth constraints (Section 3.2), and the operational delays described in the time delay model
(Section B). These components collectively determine the dynamics of workload processing and
transfer success.
Experimental Setup All evaluations were performed over a span of 260 hours on an Intel Xeon Gold
6248 CPU. This included 100 hours for the αevaluation, 100 hours for assessing the algorithms, and
60 hours for evaluating the different configurations.
10