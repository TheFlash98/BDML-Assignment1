Prototype-oriented Unsupervised Change Detection
for Disaster Management
Youngtack Oh, Minseok Seo, Doyi Kim, Junghoon Seo
SI Analytics
70, Yuseong-daero 1689beon-gil, Yuseong-gu, Daejeon, Republic of Korea
{ytoh96,minseok.seo,doyikim,jhseo}@si-analytics.ai
Abstract
Climate change has led to an increased frequency of natural disasters such as
floods and cyclones. This emphasizes the importance of effective disaster moni-
toring. In response, the remote sensing community has explored change detection
methods. These methods are primarily categorized into supervised techniques,
which yield precise results but come with high labeling costs, and unsupervised
techniques, which eliminate the need for labeling but involve intricate hyperpa-
rameter tuning. To address these challenges, we propose a novel unsupervised
change detection method named Prototype-oriented Unsupervised Change Detec-
tion for Disaster Management (PUCD). PUCD captures changes by comparing
features from pre-event, post-event, and prototype-oriented change synthesis im-
ages via a foundational model, and refines results using the Segment Anything
Model (SAM). Although PUCD is an unsupervised change detection, it does not
require complex hyperparameter tuning. We evaluate PUCD framework on the
LEVIR-Extension dataset and the disaster dataset and it achieves state-of-the-art
performance compared to other methods on the LEVIR-Extension dataset.
1 Introduction
Climate change is leading to more extreme weather events [ 23]. With the acceleration of global
warming, damage from climate-related disasters such as floods and tropical cyclones is escalating [ 2,
19]. As a result, there is heightened emphasis on the critical role of disaster management in both
prevention and response [ 28]. Employing remote sensing data for disaster management proves
efficient as it enables the monitoring of large areas [ 11,34]. However, even though remote sensing
is efficient, the large area affected by natural disasters makes it difficult for humans to analyze [ 18].
Addressing these challenges, unsupervised change detection (UCD) methods have been introduced,
utilizing change vector analysis (CV A) of pre- and post-disaster images [ 20,5,22,25,32,6]. While
UCD allows for rapid responses, it necessitates the adjustment of numerous hyperparameters. This is
because UCD uses pixel statistical differences such as brightness, color, and clarity of the image, so
it is difficult to generalize differences across various disaster types and regions. On the other hand,
supervised change detection [ 12,1,35,26] can be used without the need to adjust hyperparameters.
However, it is difficult to build large-scale datasets because disaster situations are rare [ 13]. Specifying
and labeling targets of interest also requires a significant cost [ 33]. In addition, these models cannot
respond to disasters that are not trained.
In this paper, we introduce a Prototype-oriented Unsupervised Change Detection for Disaster
Management (PUCD), illustrated as Figure 1. This approach designates a target-of-interest as a
prototype and detects changes relative to it. PUCD uses the DINOv2 foundational model to extract
features representing the context and structure of pre-, post-event imageries and prototypes. Following
this, CV A is applied to the features of the pre-, post-event images and the prototype to identify changed
Tackling Climate Change with Machine Learning: workshop at NeurIPS 2023.Figure 1: Overview of our PUCD framework. The framework receives a bi-temporal pair of images:
the pre-disaster image x1and the post-disaster image x2.(a)A prototype is then synthesized as ˆx1
andˆx2.(b)Subsequent steps involve feature extraction and subtraction them output Sx2x1,Sˆx1x1and
Sˆx2x2.(c)change vector creation through CV A. (d)A change map emerges from change clustering.
The final output is a fusion of this map and the results from the SAM.
regions. The preliminary coarse output is then enhanced using the segment anything technique [16].
To evaluate the PUCD framework, we conducted qualitative assessments on events like the Libyan
flood, the United States hurricane, and the Japan tsunami. Subsequent quantitative evaluations
were executed using the LEVIR-Extension dataset. Our experimental results showed that PUCD is
qualitatively and quantitatively efficient.
2 Method
In this section, we provide a detailed explanation of the PUCD framework. Initially, we summarize
the components constituting PUCD, specifically the DINOv2 and the segment anything model.
Subsequently, we delve into the contents corresponding to Figure 1-(a), (b), (c), and (d) in sequence.
2.1 Preliminaries
DINOv2 DINOv2 [ 24] is a foundational model rooted in representation learning, widely used in
various computer vision tasks. It utilizes the Vision Transformer (ViT) architecture [ 10,14] and is
trained on a comprehensive compilation of diverse datasets [ 24]. DINOv2 is trained using contrastive
learning, assessing the similarity between objects in two images based on their context and shape
[4,24]. Consequently, DINOv2 is not only capable of capturing changes in context and shape but
also exhibits robustness to stylistic change. This capability underpins our rationale for employing
DINOv2, particularly for UCD tasks that necessitate detecting changes in context and shape.
Segment Anything The Segment Anything Model (SAM) [ 16], built upon the MaskFormer ar-
chitecture [ 8], is a universal segmentation solution. It is recognized as a foundational model in the
segmentation field, having been trained on a massive instance segmentation dataset comprised of 1
billion masks and 11 million images. SAM consistently produces fine-grained segmentation results
across diverse applications, ranging from satellite imagery and medical imaging to autonomous
driving [ 21,27,9,31]. Given its capabilities, SAM holds significant promise for enhancing the
precision of change detection in the remote sensing domain.
2.2 PUCD framework
Prototype-oriented Change Synthesis Satellite imagery exhibits significant variation in resolution,
and even within the same resolution category, the visual representation of target objects can substan-
tially differ [ 29]. Given that disasters can occur globally, satellite images with varying resolutions play
2Figure 2: Results of qualitative analysis of PUCD. Note that all qualitative experiments were
performed by selecting a random object from images x1andx2using the SAM model, rather than
manually selecting a specific prototype p.
a crucial role in disaster management. However, the context and structural attributes of objects differ
depending on the region. Addressing this complexity necessitates a dynamic change threshold, which
considers both satellite resolution and specific object attributes. To meet this need, we introduce a
prototype -oriented change detection.
Aprototype (p) refers to a predefined single-sample image representing a target of interest, such as a
house or sports field. By storing these images in advance, the system can define changes with respect
to the prototype, offering a structured method to handle different imaging contexts. The PUCD
framework, while allowing for the specification of a prototype, remains adaptable enough to operate
without manually defined one. Notably, if pis not provided from user’s choices, an object from either
x1orx2is randomly selected as pfrom results of SAM, streamlining change detection across various
regions or targets and obviating exhaustive hyperparameter tuning. Note that the prototype aids in the
assignment of change clusters, discussed in the subsequent section.
Change Feature Extraction Given the bi-temporal images (x1, x2)and the images generated
through prototype-oriented change synthesis (ˆx1,ˆx2), PUCD extracts the corresponding features.
Specifically, PUCD divides these images into multiple patches, each of size 14×14. Each patch
is then processed by DINOv2 to extract its features. Essentially, PUCD derives features of context
and structure from a confined 14×14area for image comparison. This approach is especially
advantageous in situations where the same area of interest is captured in bi-temporal images from
satellites, but spatial discrepancies, referred to as co-registration errors, exist between these images
[17, 30].
Change Vector Analysis & Change Cluster proposal The CV A of PUCD identifies change
features using the ˆx1andˆx2, in conjunction with the x1andx2. Specifically, Sx2x1,Sˆx1x1, andSˆx2x2
represent the feature differences between x2andx1, theˆx1andx1, and the ˆx2andx2, respectively.
After concatenating the features Sx2x1,Sˆx1x1, and Sˆx2x2, they undergo dimensionality reduction
using Principal Component Analysis (PCA) [ 15]. Beyond its primary role in reducing dimensions, it
accentuates pertinent features while diminishing data noise, ensuring the feature space concentrates
on the most crucial variances. Once significant features have been extracted via PCA, K-means
clustering categorizes these features, distinguishing changes from unchanges. Within this scheme,
the cluster that contains the prototype is identified as the change cluster.
Refinement with SAM Model A single pixel within the feature map from DINOv2 corresponds
to a14×14area in the original image. Consequently, detected changes often manifest over an
excessively larger region than a size of 14×14. To address this issue, we utilize the SAM model.
Upon obtaining a coarse change map Smap, PUCD refines the x1image. Specifically, only those
objects with an overlap exceeding 70% with the semantic SAM segmentation map are retained.
3Table 1: Performance comparison of unsupervised change detection methods (CV A, IRMAD, PCAK-
means, SFA, DCV A) that require co-registered bi-temporal images on the LEVIR-Extension dataset.
Please note that the best scores are indicated in bold , and the second-best scores are underlined .
Method Param(M)LEVIR-Extension
Pre. (0/1) Rec. (0/1) F1 (0/1) IoU (0/1) ACC
CV A [3] - 45.4/ 60.9 92.7/9.3 60.9/16.2 43.8/8.8 46.7
IRMAD [22] - 73.6/46.3 93.7/13.9 82.5/21.4 70.1/12.0 71.3
PCAKmeans [5] - 63.7/43.6 92.5/9.9 75.4/16.2 60.6/8.8 62.0
SFA [32] - 76.9/48.0 94.1/16.1 84.7/24.1 73.4/13.7 74.5
DCV A [25] 16.15 94.1/14.3 92.3/18.2 93.2 /16.0 87.2 /8.7 87.41
SAM-CD 632 92.7/10.9 66.9/43.7 77.7/17.4 63.6/9.5 65.0
PUCD w/o SAM 932 97.4/23.1 75.8/ 78.6 85.2/35.6 74.3/21.7 76.0
PUCD w/ SAM 932 95.0/47.7 95.3/46.2 95.1/46.8 90.8 /30.7 91.1
3 Experiment Results
In our experiments, we employed the DINOv2 ViT-L/14 distilled model [ 24] for DINOv2 and utilized
the SAM-H [ 16] model for SAM. Within the PUCD framework, the number of PCA components was
set to 1, and for k-means clustering, the value of kwas set to 2(change and unchange).
To assess the efficacy of the PUCD framework, we conducted a quantitative evaluation using the
LEVIR-Extension dataset. Additionally, qualitative evaluations were carried out on events such as
the Libyan flood, the hurricane in the United States, and the tsunami in Japan. The LEVIR-CD
dataset [ 7] comprises 637 bi-temporal pairs of high spatial resolution (HSR) optical images with
labels indicating building changes. Each image has a spatial size of 1,024 ×1,024 pixels and a
ground sample distance (GSD) of 0.5 m. To capture all major changes in the LEVIR-CD dataset,
we added labels for roads, parking lots, lakes, and other features. This augmented dataset, named
LEVIR-Extension , will be available online shortly. The pre/post-disaster dataset for qualitative results
was sourced from MAXAR’s WorldView-2 and GeoEye-1 imagery, with GSDs of 0.46mand0.25m,
respectively.
Qualitative Results Figure 2 showcases the change detection results for various disasters, including
floods, hurricanes, and typhoons. The figure clearly demonstrates PUCD’s ability to detect signs of
damage, such as destroyed buildings, flooded areas, and damaged trees. Remarkably, these results
were achieved without any training procedure on the target dataset, highlighting its capability as an
UCD model and its adaptability across different regions and disaster types.
Quantitative Results Table 1 presents the performance comparison of PUCD with other UCD
methodologies using the LEVIR-Extension dataset. The table results reveal that PUCD consistently
outperforms existing methods, achieving state-of-the-art results with a significant margin. These
findings underscore the PUCD framework’s potential in the domain of UCD.
4 Conclusion
In this paper, we introduced the Prototype-oriented Unsupervised Change Detection (PUCD), which
delivers robust performance regardless of satellite image resolution or the specific subject of interest.
By leveraging features from both pre-event and post-event imagery and incorporating prototypes,
followed by refining results through the Segment Anything technique, PUCD achieves superior
accuracy over the other unsupervised change detectors. Qualitative assessments across various
disaster types further attest to its robust performance across different regions. We foresee PUCD
becoming a cornerstone tool in future disaster management efforts.
4References
[1]Wele Gedara Chaminda Bandara and Vishal M Patel. A transformer-based siamese network for change
detection. In IGARSS 2022-2022 IEEE International Geoscience and Remote Sensing Symposium , pages
207–210. IEEE, 2022.
[2]Kieran T Bhatia, Gabriel A Vecchi, Thomas R Knutson, Hiroyuki Murakami, James Kossin, Keith W Dixon,
and Carolyn E Whitlock. Recent increases in tropical cyclone intensification rates. Nature communications ,
10(1):635, 2019.
[3]Francesca Bovolo and Lorenzo Bruzzone. A theoretical framework for unsupervised change detection
based on change vector analysis in the polar domain. IEEE Transactions on Geoscience and Remote
Sensing , 45(1):218–236, 2006.
[4]Mathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal, Piotr Bojanowski, and Armand
Joulin. Emerging properties in self-supervised vision transformers. In Proceedings of the IEEE/CVF
international conference on computer vision , pages 9650–9660, 2021.
[5]Turgay Celik. Unsupervised change detection in satellite images using principal component analysis and
k-means clustering. IEEE geoscience and remote sensing letters , 6(4):772–776, 2009.
[6]Turgay Celik. Unsupervised change detection in satellite images using principal component analysis and
k-means clustering. IEEE Geoscience and Remote Sensing Letters , 6(4):772–776, 2009.
[7]Hao Chen and Zhenwei Shi. A spatial-temporal attention-based method and a new dataset for remote
sensing image change detection. Remote Sensing , 12(10), 2020.
[8]Bowen Cheng, Alex Schwing, and Alexander Kirillov. Per-pixel classification is not all you need for
semantic segmentation. Advances in Neural Information Processing Systems , 34:17864–17875, 2021.
[9]Yangming Cheng, Liulei Li, Yuanyou Xu, Xiaodi Li, Zongxin Yang, Wenguan Wang, and Yi Yang.
Segment and track anything. arXiv preprint arXiv:2305.06558 , 2023.
[10] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas
Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit,
and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In
International Conference on Learning Representations , 2021.
[11] Chao Fan, Cheng Zhang, Alex Yahja, and Ali Mostafavi. Disaster city digital twin: A vision for inte-
grating artificial and human intelligence for disaster management. International journal of information
management , 56:102049, 2021.
[12] Sheng Fang, Kaiyu Li, Jinyuan Shao, and Zhe Li. Snunet-cd: A densely connected siamese network for
change detection of vhr images. IEEE Geoscience and Remote Sensing Letters , 19:1–5, 2022.
[13] Ryuhei Hamaguchi, Ken Sakurada, and Ryosuke Nakamura. Rare event detection using disentangled
representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR) , June 2019.
[14] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised
visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition , pages 9729–9738, 2020.
[15] Ian T Jollife and Jorge Cadima. Principal component analysis: A review and recent developments. Philos.
Trans. R. Soc. A Math. Phys. Eng. Sci , 374(2065):20150202, 2016.
[16] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete
Xiao, Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al. Segment anything. arXiv preprint
arXiv:2304.02643 , 2023.
[17] Viktoria Kristollari and Vassilia Karathanassi. Change detection in vhr imagery with severe co-registration
errors using deep learning: A comparative study. IEEE Access , 10:33723–33741, 2022.
[18] Xuelong Li, Zhenghang Yuan, and Qi Wang. Unsupervised deep noise modeling for hyperspectral image
change detection. Remote Sensing , 11(3):258, 2019.
[19] Teng-Chiu Lin, J Aaron Hogan, and Chung-Te Chang. Tropical cyclone ecology: A scale-link perspective.
Trends in ecology & evolution , 35(7):594–604, 2020.
5[20] Sicong Liu, Daniele Marinelli, Lorenzo Bruzzone, and Francesca Bovolo. A review of change detection in
multitemporal hyperspectral images: Current techniques, applications, and challenges. IEEE Geoscience
and Remote Sensing Magazine , 7(2):140–158, 2019.
[21] Maciej A Mazurowski, Haoyu Dong, Hanxue Gu, Jichen Yang, Nicholas Konz, and Yixin Zhang. Segment
anything model for medical image analysis: an experimental study. Medical Image Analysis , 89:102918,
2023.
[22] Allan Aasbjerg Nielsen. The regularized iteratively reweighted mad method for change detection in
multi-and hyperspectral data. IEEE Transactions on Image processing , 16(2):463–478, 2007.
[23] Intergovernmental Panel on Climate Change. Ar6 synthesis report: Climate change 2023. https:
//www.ipcc.ch/report/ar6/syr/downloads/report/IPCC_AR6_SYR_FullVolume.pdf , 2023.
[24] Maxime Oquab, Timothée Darcet, Théo Moutakanni, Huy V o, Marc Szafraniec, Vasil Khalidov, Pierre
Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. Dinov2: Learning robust visual
features without supervision. arXiv preprint arXiv:2304.07193 , 2023.
[25] Sudipan Saha, Francesca Bovolo, and Lorenzo Bruzzone. Unsupervised deep change vector analysis
for multiple-change detection in vhr images. IEEE Transactions on Geoscience and Remote Sensing ,
57(6):3677–3693, 2019.
[26] Minseok Seo, Hakjin Lee, Yongjin Jeon, and Junghoon Seo. Self-pair: Synthesizing changes from single
source for object change detection in remote sensing imagery. In Proceedings of the IEEE/CVF Winter
Conference on Applications of Computer Vision , pages 6374–6383, 2023.
[27] Peilun Shi, Jianing Qiu, Sai Mu Dalike Abaxi, Hao Wei, Frank P-W Lo, and Wu Yuan. Generalist vision
foundation models for medical imaging: A case study of segment anything model on zero-shot medical
segmentation. Diagnostics , 13(11):1947, 2023.
[28] Wenjuan Sun, Paolo Bocchini, and Brian D Davison. Applications of artificial intelligence for disaster
management. Natural Hazards , 103(3):2631–2689, 2020.
[29] Lau Bee Theng. Automatic building extraction from satellite imagery. Engineering Letters , 13(4), 2006.
[30] Devis Tuia, Claudio Persello, and Lorenzo Bruzzone. Domain adaptation for the classification of remote
sensing data: An overview of recent advances. IEEE geoscience and remote sensing magazine , 4(2):41–57,
2016.
[31] Di Wang, Jing Zhang, Bo Du, Dacheng Tao, and Liangpei Zhang. Scaling-up remote sensing segmentation
dataset with segment anything model. arXiv preprint arXiv:2305.02034 , 2023.
[32] Chen Wu, Bo Du, and Liangpei Zhang. Slow feature analysis for change detection in multispectral imagery.
IEEE Transactions on Geoscience and Remote Sensing , 52(5):2858–2874, 2013.
[33] Xiwen Yao, Junwei Han, Gong Cheng, Xueming Qian, and Lei Guo. Semantic annotation of high-
resolution satellite images via weakly supervised learning. IEEE Transactions on Geoscience and Remote
Sensing , 54(6):3660–3671, 2016.
[34] Manzhu Yu, Chaowei Yang, and Yun Li. Big data in natural disaster management: a review. Geosciences ,
8(5):165, 2018.
[35] Xiaofeng Zhang, Shuli Cheng, Liejun Wang, and Haojin Li. Asymmetric cross-attention hierarchical
network based on cnn and transformer for bitemporal remote sensing images change detection. IEEE
Transactions on Geoscience and Remote Sensing , 61:1–15, 2023.
6