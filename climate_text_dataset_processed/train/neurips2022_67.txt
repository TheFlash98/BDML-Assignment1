EnhancedSD: Downscaling Solar Irradiance
from Climate Model Projections
Nidhin Harilal∗
University of Colorado Boulder
Boulder, CO, USABri-Mathias Hodge
University of Colorado Boulder
National Renewable Energy Laboratory (NREL)
Boulder, CO, USA
Claire Monteleoni
University of Colorado Boulder
Boulder, CO, USAAneesh Subramanian
University of Colorado Boulder
Boulder, CO, USA
Abstract
Renewable energy-based electricity systems are seen as a keystone of future decar-
bonization efforts. However, power system planning does not currently consider
the impacts of climate change on renewable energy resources such as solar energy,
chiefly due to a paucity of climate-impacted high-resolution solar power data.
Existing statistical downscaling (SD) methods that learn to map coarse-resolution
versions of historical reanalysis data to generate finer resolution outputs are of
limited use when applied to future climate model projections due to the domain gap
between climate models and reanalysis data. In contrast, we present EnhancedSD,
a deep learning-based framework for downscaling coarse-scale climate model
outputs to high-resolution observational (reanalysis) data. Our proposed ML based
downscaling allows for future reanalysis projections, which can be pivotal for
mitigating climate change’s impacts on power systems planning.
1 Introduction
Renewable energy-based electricity systems can potentially reduce not only the 25% of global
greenhouse gas emissions that currently stem from electricity generation but also large amounts
of emissions from the transportation, industrial, and agricultural sectors. While net-zero emission
electricity systems are perhaps the most critical mitigation option for combating climate change, they
themselves require adaptation to climate change’s impacts. Power system planning has traditionally
relied on historical demand and solar resource data to plan future generation and transmission build-
outs, implicitly assuming a stationary climate. We have already seen the dire impacts, in terms of loss
of life and economic ramifications, of failing to account for correlated generation failures induced by
climate change in the February 2021 Texas Power outage [3].
The largest impediment to mitigating impacts of climate change-induced events in applications such
as power generation planning is the lack of high-quality datasets translating expected future climate
change impacts on variables like solar irradiance. Owing to high-computational requirements, climate
models are run at very coarse resolutions, on the order of 111 kms ( 1◦), yet climate variables are
needed at a much higher resolution, typically 27 kms ( 0.25◦) or higher for assessing the regional
impacts. SD techniques are used to mitigate the low spatial resolution of climate model outputs by
learning a functional form to map coarse-scale to fine-scale observational data. Recently, a variety of
statistical [ 4,10] and machine learning (ML) based models [ 22,6,7,13] have been applied for SD
∗Corresponding author: Nidhin Harilal, nidhin.harilal@colorado.edu
Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022.of different climate variables. Despite the availability of many techniques, the existing approaches
consider coarse-resolution versions of the same observational data (reanalysis) to generate finer-
resolution outputs. This way of mapping limits the generality of SD approaches when applied to
future climate model outputs due to the significant domain gap between climate model outputs and
observational (reanalysis) data.
In this study, we propose EnhancedSD - an end-to-end model design to massively downscale present
and future climate projections from current generation climate model outputs to high-resolution
observational (reanalysis) data. Complex and non-linear inter-dependencies among climate variables
and reanalysis at different resolutions motivated us to combine various neural network-based super-
resolution techniques to design this model. Super-resolution [ 5] refers to ML methods, often inspired
by problems in computer vision, that address the downscaling task, i.e., learning a model that will
map a coarse resolution spatial grid to one of a finer spatial resolution. We apply our approach to
downscale climate model forecasts for solar irradiation over the Continental United States (CONUS),
where the rich, high-resolution data required for power system studies is available, with which to
validate our predictions.
Contributions: We propose EnhancedSD, designed to downscale coarse-scale climate model outputs
while correcting its bias to fine-scale reanalysis. We showcase the generality of EnhancedSD on
solar irradiance data allowing fine-scale predictions of future reanalysis-resolution projections (called
reanalysis projections hereafter), and plan to make it publicly available for use by the power systems
community to design net-zero future power systems.
Pathways to Climate Impact: EnhancedSD is designed to model the gap between coarse-resolution
climate model outputs and fine-resolution reanalysis. Predicting high-resolution reanalysis for future
climate scenarios is critically important to fully understand the impacts of climate change and inform
adaptation strategies. Future reanalysis predictions will have a broad potential user base: from
academics creating innovative new technologies for renewable energy integration to power utilities
currently planning the future power grid based on historical climate data.
2 Proposed Method
EnhancedSD consists of an end-to-end model design combining several ideas based on re-
cent advances in super-resolution for computer vision [ 5,24]. Specifically, we employ
Residual-in-Residual Dense Blocks (RRDBs) [ 23] for learning in the coarse-resolution space.
Figure 1: Structure of one RRDB blockAs shown in Figure 1, RRDB combines multi-level resid-
ual networks and dense blocks. Residual connections [ 8]
provide another path for data to reach the latter parts of
the neural network by skipping some layers. While the
dense blocks [ 12] inside each RRDB extract relevant local
features from the climate projection, the multi-level resid-
ual connections [ 8] between them allows for local feature
fusion. Stacking several such RRDB blocks provides a
deeper and more complex structure which improves the
overall representation ability required to model the biases
between coarse climate forecasts and fine reanalysis pro-
jections. Additionally, we found that incorporating resid-
ual scaling [ 15] - a technique to scale down the residuals
by weighting them with a constant between 0 and 1 before adding them to the main path, increases
the performance and reduces instability between batches. After 24 such RRDB blocks, the model
exploits sub-pixel convolutions [ 15,19] followed by a set of standard convolutions for learning in the
high-resolution space and constructs the final reanalysis prediction. Figure 2 gives an overview of
each of the components of EnhancedSD architecture.
Multi-resolution pathways: Overall, we considered two pathways: 1) learning in coarse-resolution
space ( 1◦) and 2) learning in fine-resolution space ( 0.25◦). We restrict our initial learning to the coarse
resolution space, which significantly reduces the computation complexity and allows the training
of a very deep multi-level residual network (24 stacked RRDBs). Since the task of downscaling
demands generating high-resolution predictions, we need to map learned coarse-scale representations
to fine-scale features, which could be used to reconstruct the final prediction. Deconvolutions [ 26]
2are used as a standard for increasing the resolution of features. However, they are prone to generating
known artifacts [ 16], which can cause spurious climate predictions. We instead exploit sub-pixel
convolutions [ 15,19] for mapping the coarse-resolution convolutional features to fine-resolution
outputs, which is followed by a set of convolutions altering the generated fine-scale predictions
close to reanalysis. More information regarding the architecture implementation is available in the
Appendix.
Figure 2: Overview of EnhancedSD architecture incorporating 1) RRDB blocks where all the
computation is done in coarse-resolution space, and 2) Sub-pixel convolution which maps coarse-
resolution convolutional features to fine-resolution followed by convolutions to reconstruct the
reanalysis output.
Optimization: We employ root-mean-squared error (RMSE), mathematically expressed as
RMSE =p
(1/n)Pn
i=1(yi−ˆyi)2which is also one of the most commonly used criteria to
optimize image reconstruction. Our initial experiments showed that only using RMSE as the criterion
for optimizing the model does not perform well, as it generates over-smoothed projections while
downscaling. The reason could be associated with RMSE only capturing the mean statistics. We
realized that the model should also be incentivized to make the overall structure between the gener-
ated downscaled projections and the reanalysis as close as possible. Therefore, we incorporate the
Structural Similarity Index Measure (SSIM) to capture this notion of structural similarity that can
be essential for reliable reanalysis prediction. Our current loss function (criterion for optimization)
involves a weighted combination of RMSE and SSIM (Here, α∈(0,1)).
Joint loss =RMSE +α×(1−SSIM )
2.1 Dataset
Table 1: Dataset Statistics
IPSL ERA-5
Years-range 1950-2014 1978-2022
Shape 24×59 96 ×236
Spatial res. 1◦0.25◦
Temporal res. 3-hourly 1-hourlyTo maximize the impacts of the proposed work, we
refine our techniques on the continental United States
(CONUS), where historical data for supervised train-
ing and validation purposes is relatively rich, with the
long-term goal of applying it in data-poor environ-
ment. We use the climate model outputs of the solar
radiation field from Institut Pierre-Simon Laplace
(IPSL) Phase 6 of the Coupled Model Intercompar-
ison Project (CM6A) [ 2] as the foundation for the
downscaling. The IPSL-CM6A outputs are at a spa-
tial resolution of 1◦and are considered to have high fidelity in reproducing 20th-century observed
climate over the US [ 2]. For the reanalysis, we use downward solar irradiance fields from ERA5 [ 9],
which is the fifth generation reanalysis from ECMWF and provides several improvements over
previous versions, such as ERA-I [ 9]. The reanalysis is produced hourly and has a spatial resolution
of0.25◦. To summarize, we have coarse-scale 3-hourly solar irradiance (IPSL) as input, and the
ground truth labels are the corresponding fine-scale reanalysis data (ERA5). We focus on spatial
downscaling from 1◦to0.25◦horizontal resolution.
33 Experiments
Baselines: Existing SD approaches are designed to downscale a synthetically generated coarse
version of fine-scale observational data. In contrast, we learn a transfer function between coarse
climate model outputs and fine-scale observational data, so there is no directly comparable baseline
from previous work. We instead try to inspect the design choices of EnhancedSD and how it affects
predictability. Additionally, we compare EnhancedSD and its ablations with bicubic interpolation -
a standard baseline used in the super-resolution literature [ 24,13]. This will represent existing SD
approaches that only consider increasing the resolution with no knowledge of the domain-gap.
3.1 Results
Table 2: Results on downscaling solar-irradiance
MethodRMSE
Capacity↓SSIM↑
Bicubic intep. 0.1584 0.508EnhancedSDw/o RRDB 0.1329 0.618
w/o sub-pixel 0.1121 0.632
w/o res-scaling 0.1107 0.641
w/o SSIM 0.1083 0.647
Proposed 0.1071 0.691Error calculations related to solar irradiance are
complicated as nighttime, and low solar condi-
tions can lead to very low absolute error [ 11]
statistics. We instead use a relative error such as
RMSE/Capacity, where capacity equals peak
nominal irradiance , to evaluate average pre-
dictability as it is more desirable in our con-
text [ 25,11]. The visual structural quality of
the predictions is evaluated using SSIM. Table 2
compares the metric values from bicubic inter-
polation, the proposed EnhancedSD, and its ab-
lated versions. Since bicubic interpolation only
focuses on increasing the resolution and does
not correct biases with reanalysis, all the EnhancedSD versions outperform it. Comparing the
ablations, just using RMSE ( w/o SSIM ) slightly worsens both the relative RMSE and the SSIM,
which was surprising as it suggests incorporating structural similarity ends up improving the average
predictability too. Furthermore, not applying residual scaling ( w/o res-scaling ), that is - adding the
residuals directly without weighing them down (discussed in Section 2), performs worse as well.
However, the largest drop in performance both in terms of relative RMSE and SSIM, is observed
when RRDB blocks are replaced with standard convolutional layers ( w/o RRDB ), which suggests that
residual connections in conjunction with dense networks are critical in introducing bias-correcting
capabilities in the model to bridge the domain-gap between climate models and reanalysis. Additional
qualitative results are available in the Appendix.
Figure 3: RMSE computed at each location using
EnhancedSD with deconvolutions over test-period,
showing the checkerboard error pattern [16].Checkerboard Artifacts: EhancedSD
with sub-pixel convolutions is observed
to have better metric values compared to
when deconvolutions are used instead ( w/o
sub-pixel in Table 2). This result is consis-
tent with representation power trade-offs
of deconvolutions [ 20]. Our main reason
for not using deconvolutions was to avoid
checkerboard artifacts [ 16]. Figure 3 shows
deconvolutions exhibiting this exact behavior
suggesting its less reliability in climate predic-
tions.
4 Conclusion
In this study, we have presented EnhancedSD, which downscales coarse-scale climate outputs to the
scale of fine-resolution reanalysis data. It addresses a major limitation with existing SD approaches,
which only consider the coarse-resolution version of the same observational data (reanalysis) to gen-
erate finer-resolution outputs and do not account for the inherent domain-gap between climate model
outputs and reanalysis data. On downscaling solar irradiance, our approach significantly outperforms
a simple baseline representing existing SD approaches. Our ablation study on EnhancedSD shows
the significance of several design choices in solar power predictability.
4In addition to solar power datasets, EnhancedSD could potentially be applied to generate high-
resolution reanalysis predictions from other coarse-resolution climate model outputs (such as pre-
cipitation, surface temperature, etc.). We believe that additional investigation into the methods for
generating future reanalysis have a huge potential to inform climate change adaptation strategies.
References
[1]Andrew Aitken, Christian Ledig, Lucas Theis, Jose Caballero, Zehan Wang, and Wenzhe Shi.
Checkerboard artifact free sub-pixel convolution: A note on sub-pixel convolution, resize
convolution and convolution resize. arXiv preprint arXiv:1707.02937 , 2017.
[2]Olivier Boucher, Jérôme Servonnat, Anna Lea Albright, Olivier Aumont, Yves Balkanski,
Vladislav Bastrikov, Slimane Bekki, Rémy Bonnet, Sandrine Bony, Laurent Bopp, et al. Presen-
tation and evaluation of the ipsl-cm6a-lr climate model. Journal of Advances in Modeling Earth
Systems , 12(7):e2019MS002010, 2020.
[3]Joshua W Busby, Kyri Baker, Morgan D Bazilian, Alex Q Gilbert, Emily Grubert, Varun Rai,
Joshua D Rhodes, Sarang Shidore, Caitlin A Smith, and Michael E Webber. Cascading risks:
Understanding the 2021 winter blackout in texas. Energy Research & Social Science , 77:102106,
2021.
[4]Alex J Cannon. Quantile regression neural networks: Implementation in r and application to
precipitation downscaling. Computers & geosciences , 37(9):1277–1284, 2011.
[5]Honggang Chen, Xiaohai He, Linbo Qing, Yuanyuan Wu, Chao Ren, Ray E Sheriff, and Ce Zhu.
Real-world single image super-resolution: A brief review. Information Fusion , 79:124–145,
2022.
[6]Brian Groenke, Luke Madaus, and Claire Monteleoni. Climalign: Unsupervised statistical
downscaling of climate variables via normalizing flows. In Proceedings of the 10th International
Conference on Climate Informatics , pages 60–66, 2020.
[7]Nidhin Harilal, Mayank Singh, and Udit Bhatia. Augmented convolutional lstms for generation
of high-resolution climate change projections. IEEE Access , 9:25208–25218, 2021.
[8]Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition ,
pages 770–778, 2016.
[9]Hans Hersbach, Bill Bell, Paul Berrisford, Shoji Hirahara, András Horányi, Joaquín Muñoz-
Sabater, Julien Nicolas, Carole Peubey, Raluca Radu, Dinand Schepers, et al. The era5 global
reanalysis. Quarterly Journal of the Royal Meteorological Society , 146(730):1999–2049, 2020.
[10] Masoud Hessami, Philippe Gachon, Taha BMJ Ouarda, and André St-Hilaire. Automated
regression-based statistical downscaling tool. Environmental modelling & software , 23(6):813–
834, 2008.
[11] Thomas E Hoff, Richard Perez, Jan Kleissl, David Renne, and Joshua Stein. Reporting
of irradiance modeling relative prediction errors. Progress in Photovoltaics: Research and
Applications , 21(7):1514–1519, 2013.
[12] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected
convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern
recognition , pages 4700–4708, 2017.
[13] Rupa Kurinchi-Vendhan, Björn Lütjens, Ritwik Gupta, Lucien Werner, and Dava Newman.
Wisosuper: Benchmarking super-resolution methods on wind and solar data. arXiv preprint
arXiv:2109.08770 , 2021.
[14] Nina Siu-Ngan Lam. Spatial interpolation methods: a review. The American Cartographer ,
10(2):129–150, 1983.
5[15] Bee Lim, Sanghyun Son, Heewon Kim, Seungjun Nah, and Kyoung Mu Lee. Enhanced deep
residual networks for single image super-resolution. In Proceedings of the IEEE conference on
computer vision and pattern recognition workshops , pages 136–144, 2017.
[16] Augustus Odena, Vincent Dumoulin, and Chris Olah. Deconvolution and checkerboard artifacts.
Distill , 2016.
[17] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas
Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,
Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-
performance deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d 'Alché-
Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32 ,
pages 8024–8035. Curran Associates, Inc., 2019.
[18] Tim Salimans and Durk P Kingma. Weight normalization: A simple reparameterization to
accelerate training of deep neural networks. Advances in neural information processing systems ,
29, 2016.
[19] Wenzhe Shi, Jose Caballero, Ferenc Huszár, Johannes Totz, Andrew P Aitken, Rob Bishop,
Daniel Rueckert, and Zehan Wang. Real-time single image and video super-resolution using an
efficient sub-pixel convolutional neural network. In Proceedings of the IEEE conference on
computer vision and pattern recognition , pages 1874–1883, 2016.
[20] Wenzhe Shi, Jose Caballero, Lucas Theis, Ferenc Huszar, Andrew Aitken, Christian Ledig, and
Zehan Wang. Is the deconvolution layer the same as a convolutional layer? arXiv preprint
arXiv:1609.07009 , 2016.
[21] Yusuke Sugawara, Sayaka Shiota, and Hitoshi Kiya. Super-resolution using convolutional neural
networks without any checkerboard artifacts. In 2018 25th IEEE International Conference on
Image Processing (ICIP) , pages 66–70. IEEE, 2018.
[22] Thomas Vandal, Evan Kodra, Sangram Ganguly, Andrew Michaelis, Ramakrishna Nemani, and
Auroop R Ganguly. Deepsd: Generating high resolution climate change projections through
single image super-resolution. In Proceedings of the 23rd acm sigkdd international conference
on knowledge discovery and data mining , pages 1663–1672, 2017.
[23] Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Yu Qiao, and Chen
Change Loy. Esrgan: Enhanced super-resolution generative adversarial networks. In Proceed-
ings of the European conference on computer vision (ECCV) workshops , pages 0–0, 2018.
[24] Zhihao Wang, Jian Chen, and Steven CH Hoi. Deep learning for image super-resolution: A
survey. IEEE transactions on pattern analysis and machine intelligence , 43(10):3365–3387,
2020.
[25] Cort J Willmott, Steven G Ackleson, Robert E Davis, Johannes J Feddema, Katherine M Klink,
David R Legates, James O’donnell, and Clinton M Rowe. Statistics for the evaluation and
comparison of models. Journal of Geophysical Research: Oceans , 90(C5):8995–9005, 1985.
[26] Li Xu, Jimmy S Ren, Ce Liu, and Jiaya Jia. Deep convolutional neural network for image
deconvolution. Advances in neural information processing systems , 27, 2014.
6Supplementary material
This document presents the materials that were excluded or summarized due to space limitation in
the main text. It is organized as follows:
Appendix A provides additional information related to dataset preprocessing.
Appendix B provides further information regarding our experimental setup and training details.
Appendix C includes some additional results.
A Dataset processing
As input, we have coarse-scale 3-hourly solar irradiance (IPSL), and the ground truth labels are
the corresponding fine-scale reanalysis data (ERA5). We focus on spatial downscaling from 1◦to
0.25◦horizontal resolution. Due to differences in the resolution and non-overlapping spatial grid
between the original coarse-scale climate model outputs and fine-scale reanalysis outputs, we use
a bicubic interpolation method [ 14] on coarse projections to re-grid it while still maintaining its
original resolutions of 1◦. This results in an interpolated version of coarse-resolution data which
overlaps the grid space with the corresponding high-resolution reanalysis version. In addition, we use
a mean-threshold value of 10W/m2to exclude nighttime values. To facilitate training, coarse and
fine resolution projections are normalized between 0 and 10 to limit the neural network’s learning to
a compact space, leading to faster training and stable representations. Further, we split the data into
train, validation and test periods. The training period comprises years between 1978-2000, whereas
validation and test consist of years 2000-2007, 2008-2014 respectively.
B Architecture
Built entirely on PyTorch [ 17], EnhancedSD consists of approximately 40.3M parameters. We use
a consistent set of convolutional layers, each having a kernel size of 3 and stride of size 1. We
use a combination of ReLU and LeakyReLU between Dense blocks and the residual-in-residual
connections as implemented in Wang et al. [ 23]. We find that a total of 24 RRDB blocks stacked with
a residual scaling factor of 0.2 in each of them works best for our setting and use it throughout the
experiments.
B.1 Sub-pixel Convolution Implementation
We implement the sub-pixel convolution layers [ 1] for upsampling convolutional features with an
ICNR [ 1] initialization scheme and weight normalization [ 18]. he sub-pixel convolution layers allow
upsampling of features while conserving feature-related information and avoiding checkerboard
artifacts [ 1]. Each sub-pixel convolution layer is followed by a blur layer [ 21] consisting of an average
pooling layer with a 2 ×2 filter which further improves on the previous initialization for dealing with
checkerboard artifacts in the generated outputs.
B.2 Training Details
We perform all our training on NVIDIA RTX-3090 with 24GB memory paired with an Intel i9-
12900K processor. Some of the key libraries we have used are as follows : Python 3.7: Numpy 1.21.5,
PyTorch 1.11.0, Torchvision 0.12.0, Xarray 0.20.2, nctoolkit 1.9.8 Scipy 1.5.3, Matplotlib 3.5.2.
We train EnhancedSD for 150 epochs with a batch-size of 14. We initialize the learning rate with
2e-4 and decay it by a factor of 2 for every 200,000 mini-batch updates or when the performance
stagnates. We use Adam optimizer with coefficients - (0.9, 0.999) to optimize the loss. For all the
ablation designs, most configurations other than the ablation are kept the same, except for the cases
of modifying residual-scaling and not using RRDB blocks, in which a strong weight decay factor
of 1e-4 was used to stabilize the training. For each scenario, best-performed configuration in the
entire training period (1978-2000) over validation (2000-2007) is chosen for evaluation on the test set
(2008-2014).
7C Additional Qualitative Results
Figure 4: Sample comparison of IPSL low-resolution input, generated high-resolution predictions
from bicubic-interpolation and EnhancedSD, with Reanalysis ground truth for solar-irradiance field.
8