Enhancing Laboratory-scale Flow Imaging of Fractured Geological Media with
Deep Learning Super Resolution
Manju Pharkavi Murugesu1Timothy I Anderson2Niccol ´o Dal Santo3Vignesh Krishnan4
Anthony R Kovscek1
Abstract
Injection into deep geological formations is a
promising approach for the utilization, seques-
tration, and removal from the atmosphere of CO 2
emissions. Laboratory experiments are essential
to characterize how CO 2ﬂows and reacts in var-
ious types of geological media. We reproduce
such dynamic injection processes while imaging
using Computed Tomography (CT) at sufﬁcient
temporal resolution to visualize changes in the
ﬂow ﬁeld. The resolution of CT, however, is on
the order of 100’s of m and insufﬁcient to char-
acterize ﬁne-scale reaction-induced alterations to
micro-fractures. Super resolution deep learning
is, therefore, an essential tool to improve spatial
resolution of dynamic CT images. We acquired
and processed pairs of multi-scale low- and high-
resolution CT rock images. We also show the
performance of our baseline model on fractured
rock images using peak signal to noise ratio and
structural similarity index. Coupling dynamic CT
imaging with deep learning results in visualiza-
tion with enhanced spatial resolution of about a
factor of 4 thereby enabling improved interpreta-
tion.
1. Introduction
Low-carbon energy resources and large-scale greenhouse
emissions reductions are important to meet the global de-
mand for energy while combating climate change. Subsur-
face geology provides large scale solutions to our climate
goals through technologies such as CO 2utilization and se-
questration, subsurface hydrogen and compressed air stor-
1Department of Energy Resources Engineering, Stanford
University, California, USA2Department of Electrical En-
gineering, Stanford University, California, USA3The Math-
Works Ltd, Cambridge, UK4The MathWorks Ltd, Natick,
Massachusetts, USA. Correspondence to: Anthony R Kovscek
<kovscek@stanford.edu >.
Proceedings of the 38thInternational Conference on Machine
Learning , PMLR 139, 2021. Copyright 2021 by the author(s).age, and enhanced geothermal systems. For example, CO 2
can replace water in hydraulic fracturing processes while
simultaneously sequestering, creating a reduced-carbon or
carbon negative energy process (Middleton et al., 2015;
Pruess, 2006).
Injected CO 2tends to ﬂow preferentially through naturally
existing or induced fractures. CO 2and brine mixtures are
quite acidic. The low pH brine chemically interacts with
surface minerals along fractures, altering rock-ﬂuid interac-
tions through dissolution and precipitation of certain rock
minerals. Such reactions can signiﬁcantly impact the poros-
ity and permeability along the fractures and near-fracture
matrix, affecting both CO 2ﬂow and storage processes. Visu-
alization techniques, such as Computed Tomography (CT)
imaging, capture alterations of fractures during reactive
transport experiments at the laboratory scale.
CT is an important technique to image rocks during dynamic
transport experiments. The resolution of CT images, how-
ever, is insufﬁcient to characterize accurately the changes
in fractures and rock matrix porosity on the order of m or
less. Micro-CT ( CT) scanners have the necessary superior
resolution to characterize reactive transport processes at the
microscale. The scan time of CT is longer than that of a
CT by at least an order of magnitude and therefore limits
the temporal resolution signiﬁcantly.
To overcome these challenges, we propose to image dy-
namic reactive transport using CT scanners and later upsam-
ple the CT image to have comparable resolution to CT.
Dong et al. (2015) shows that deep convolutional neural net-
works (CNN) are state of the art superior methods for image
super resolution tasks. Past literature reports supervised su-
per resolution deep learning models based on micro-CT and
synthetically downsampled micro-CT image pairs for geo-
logical samples (Wang et al., 2019; Da Wang et al., 2019;
Chen et al., 2020). Low-resolution CT images are more
applicable inputs to super resolution deep learning models
due to the widespread use of CT in geoscience. The avail-
ability of CT and micro-CT imaging capability motivates us
to train CNN models with low resolution CT as input im-
ages and high-resolution micro-CT as ground truth images.
Hence, this work extends super resolution deep learning forEnhancing Laboratory-scale Flow Imaging with Deep Learning Super Resolution
multi-scale data obtained from separate imaging platforms.
2. Proposed Workﬂow
We propose the workﬂow shown in Figure 1 to conduct
neural network super resolution of multi-scale CT rock im-
ages. The workﬂow outlines the steps to prepare images,
train models and later effectively deploy the models for our
application.
Image acquisition: We imaged cylindrical rock samples
in both CT and micro-CT under ambient conditions. The
resolutions of rock images obtained from CT and micro-CT
are 195 m x 195 m x 625 m, and 27 m x 27 m x 27 m
respectively. Despite the resolution difference, we prefer to
use CT images for our dynamic transport experiments due
to the shorter scan time of CT in the range of minutes. The
3D rock images in Figure 1 show two fractures extending
from either side of the core. The CT image overestimates
the actual fracture aperture.
Image pre-processing: Image pre-processing is crucial for
curating a dataset for deep learning single image super reso-
lution. We align the images using the pipeline outlined in
Figure 2. The distribution of pixels in the CT and micro-CT
images are approximately similar at the end of the pre-
processing step.
Model training: We use feed-forward deep SR-ResNet
generator adapted from Ledig et al. (2017). Due to ho-
mogeneity of rock images, it is important that the model is
sensitive to ﬁne details and produces realistic looking matrix
structure. Super resolution generative adversarial network
(SR-GAN) addresses this problem by incorporating an ad-
ditional discriminator network that pushes the synthesized
images towards the manifold of natural images (Ledig et al.,
2017). Although the images for this study are all obtained
from CT-based instruments, image contrast is possibly offset
due to default settings of the separate CT and CT machines.
Therefore, the project adapts the multimodal image enhance-
ment implementation suggested by Anderson et al. (2020)
based on the Pix2pix conditional GAN model (Isola et al.,
2017; Zhu et al., 2017). For initial 2D super resolution,
we randomly sampled 64 x 64 patches in CT images and
their 256 x 256 micro-CT pairs. Preliminary training based
on hyperparameters recommended by Isola et al. (2017)
is conducted with different loss functions such as L1 loss,
Wasserstein GAN loss and vanilla GAN loss. The common
hyperparameters between the different models are shown in
Table 1.
Initial results for a validation set are shown in Figure 3. For
the purpose of initial study, the images are evaluated ofﬂine
after the acquisition. Peak signal to noise ratio (PSNR)
measures the proportion between maximum signal power
and the mean squared error, and structural similarity indexTable 1. Model Parameters
Model Parameter Choice
Training data size 10,000
Validation data size 100
Test data size 100
Initial learning rate 0.0002
Optimization Adam
Normalization Instance
Batch size 1
Number of epochs 20
measure (SSIM) quantiﬁes the structural difference between
two images.
The feedforward SR-CNN model shows the greatest PSNR
and SSIM. However, the matrix structure of the rocks are
washed out because the L1 loss function tends to better dis-
tinguish the main features and renders other details sparsely.
The conditional GAN predictions look more realistic be-
cause the discriminator drives the model to predict percep-
tually realistic looking images. Therefore, We propose to
formulate an ensemble model combining the SR-CNN and
conditional GAN for future analysis. Note the artifact in
the GAN-predicted image. Checkerboard artifacts are also
reported for GAN-predicted fake images during upsampling
in previous studies (Zhang et al., 2019; Zhu et al., 2019).
3. Ongoing Work
Once the model is trained, we propose to deploy directly
the model during each time step of the dynamic reactive
transport process. The combination of rapid CT imaging
and super resolution deep learning models allows us to visu-
alize dynamic transport experiments with high spatial and
temporal resolution. The enhanced visualization accurately
characterizes fractures and porosity of the geological forma-
tion rocks that are in consideration for CO 2and H 2storage
processes as well as enhanced geothermal systems. We plan
to analyze in detail the uncertainty of the pixel resolution
outcome of the model with images obtained during dynamic
transport experiments.
4. Path to Climate Impact
Figure 4 shows the path of this proposal to meaningful
climate impact. The 3D image shows the CT-segmented
fractures of a geologic rock at laboratory scale. Enhanced
visualization of transport processes in fractured rock with
greater spatial and temporal resolutions allows for more ac-
curate segmentation of the fractures and porosity of the core.
Such information is foundational to modeling of transport
and reaction. Additionally, accurate characterization of theEnhancing Laboratory-scale Flow Imaging with Deep Learning Super Resolution
Figure 1. Proposed workﬂow for application of machine learning to characterize better fractured geologic porous media using enhanced
visualization during dynamic injection processes.
Figure 2. Image pre-processing pipeline for CT and micro-CT im-
ages of the same volume.
formation rock guides selection of geological formations for
CO2injection and appropriate technology for monitoring of
ﬂuid storage. This study signiﬁcantly reduces the uncertain-
ties encountered during subsurface injection and monitoring
and will enable new insights into carbon emission reduction
strategies and safe implementation of these technologies.
References
Anderson, T. I., Vega, B., and Kovscek, A. R. Multimodal
imaging and machine learning to enhance microscopeimages of shale. Computers & Geosciences , 145:104593,
2020.
Chen, H., He, X., Teng, Q., Sheriff, R. E., Feng, J., and
Xiong, S. Super-resolution of real-world rock microcom-
puted tomography images using cycle-consistent gener-
ative adversarial networks. Physical Review E , 101(2):
023305, 2020.
Da Wang, Y ., Armstrong, R. T., and Mostaghimi, P. Enhanc-
ing resolution of digital rock images with super resolution
convolutional neural networks. Journal of Petroleum Sci-
ence and Engineering , 182:106261, 2019.
Dong, C., Loy, C. C., He, K., and Tang, X. Image super-
resolution using deep convolutional networks. IEEE
transactions on pattern analysis and machine intelligence ,
38(2):295–307, 2015.
Isola, P., Zhu, J.-Y ., Zhou, T., and Efros, A. A. Image-to-
image translation with conditional adversarial networks.
InProceedings of the IEEE conference on computer vi-
sion and pattern recognition , pp. 1125–1134, 2017.
Ledig, C., Theis, L., Husz ´ar, F., Caballero, J., Cunningham,
A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang,
Z., et al. Photo-realistic single image super-resolution
using a generative adversarial network. In ProceedingsEnhancing Laboratory-scale Flow Imaging with Deep Learning Super Resolution
Figure 3. Preliminary results for 2D super resolution based on different loss functions.
Figure 4. Path to climate impact: Enhanced visualization of dy-
namic injection processes of fractured rock allows for better char-
acterization and monitoring of CO 2and H 2injection and seques-
tration.
of the IEEE conference on computer vision and pattern
recognition , pp. 4681–4690, 2017.
Middleton, R. S., Carey, J. W., Currier, R. P., Hyman, J. D.,
Kang, Q., Karra, S., Jim ´enez-Mart ´ınez, J., Porter, M. L.,
and Viswanathan, H. S. Shale gas and non-aqueous frac-
turing ﬂuids: Opportunities and challenges for supercriti-
cal co2. Applied Energy , 147:500–509, 2015.Pruess, K. Enhanced geothermal systems (egs) using co2 as
working ﬂuid—a novel approach for generating renew-
able energy with simultaneous sequestration of carbon.
Geothermics , 35(4):351–367, 2006.
Wang, Y ., Teng, Q., He, X., Feng, J., and Zhang, T. Ct-image
of rock samples super resolution using 3d convolutional
neural network. Computers & Geosciences , 133:104314,
2019.
Zhang, X., Karaman, S., and Chang, S.-F. Detecting and
simulating artifacts in gan fake images. In 2019 IEEE
International Workshop on Information Forensics and
Security (WIFS) , pp. 1–6. IEEE, 2019.
Zhu, J., Yang, G., and Lio, P. How can we make gan
perform better in single medical image super-resolution?
a lesion focused multi-scale approach. In 2019 IEEE 16th
International Symposium on Biomedical Imaging (ISBI
2019) , pp. 1669–1673. IEEE, 2019.
Zhu, J.-Y ., Park, T., Isola, P., and Efros, A. A. Unpaired
image-to-image translation using cycle-consistent adver-
sarial networks. In Proceedings of the IEEE international
conference on computer vision , pp. 2223–2232, 2017.