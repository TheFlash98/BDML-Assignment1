Synthesis of Realistic Load Data: Adversarial
Networks for Learning and Generating Residential
Load Patterns
Xinyu Liang
Department of Data Science and AI
Faculty of IT
Monash University
adamliang42@gmail.comHao Wang∗
Department of Data Science and AI
and Monash Energy Institute
Monash University
hao.wang2@monash.edu
Abstract
Responsible energy consumption plays a key role in reducing carbon footprint and
CO2 emissions to tackle climate change. A better understanding of the residential
consumption behavior using smart meter data is at the heart of the mission, which
can inform residential demand flexibility, appliance scheduling, and home energy
management. However, access to high-quality residential load data is still limited
due to the cost-intensive data collection process and privacy concerns of data shar-
ing. In this paper, we develop a Generative Adversarial Network (GAN)-based
method to model the complex and diverse residential load patterns and generate
synthetic yet realistic load data. We adopt a generation-focused weight selection
method to select model weights to address the mode collapse problem and generate
diverse load patterns. We evaluate our method using real-world data and demon-
strate that it outperforms three representative state-of-the-art benchmark models in
better preserving the sequence level temporal dependencies and aggregated level
distributions of load patterns.
1 Introduction
Residential energy use accounts for roughly 20% of greenhouse gas (GHG) emissions [11] in
the United States. Responsible energy consumption promotes energy saving, energy efficiency
upgrades, and consuming more renewable energy when available, thus reducing carbon footprint
and CO2 emissions to tackle climate change. Load profiling, load forecasting and demand response
can be performed by analysing residential load data [1, 3, 23, 30] so that the industry can better
understanding the residential consumption behavior to greatly inform responsible energy consumption
[14]. However, due to the cost-intensive data collection process and privacy concerns of data sharing,
the lack of access to diverse and high-quality residential load data becomes a barrier to enabling
responsible energy consumption [12, 15, 22].
A lot of effort has been made to study the modeling and generation of residential load to overcome
the aforementioned challenges due to the lack of access to residential load data. One category of
studies [7, 8, 16, 20, 25] followed a bottom-up approach where individual appliances’ electricity
consumption is modeled first and then aggregated to model and generate load data at a household
level. Household-level load data can be further aggregated to a group level. Bottom-up approaches
are able to generate diverse synthetic data. However, intrusive sensors are often required during the
∗Corresponding author: Hao Wang <hao.wang2@monash.edu>. Hao Wang’s research has been supported in
part by the FIT Startup Funding of Monash University and the Australian Research Council (ARC) Discovery
Early Career Researcher Award (DECRA) under Grant DE230100046.
Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022.data collection process, which is costly and time-consuming, making bottom-up approaches hard
to scale up and be widely applied. The other category of studies [17, 26, 31] followed a top-down
approach where the residential load is modeled and generated at the household level directly, for
example, using Gaussian Mixture Model or Markov Chain Model. Recently, Generative Adversarial
Network (GAN) has attracted much attention for generating synthetic energy data. Gu et al. [13]
proposed a conditional GAN-based generative model using the Auxiliary Classifier GAN [21] for
residential load data generation, which is promising for the low cost and high scalability. However,
residential load data can be very diverse because of various housing properties and lifestyles of energy
users. Most results generated using the top-down approaches suffer from low diversity problems.
To overcome the challenges of GAN-based methods, we develop a novel Residential Load Pattern
Generation method (called RLPGen). Our method can better capture the time dependencies within
the daily load patterns and generate diverse load data reflecting different lifestyles. We evaluate our
method’s performance against three representative benchmarks using real-world data. Our method
outperforms all the benchmarks by achieving higher similarity to the real data and better diversity
within the generated load patterns.
2 Data Description
We use real-world data from the Pecan Street database [24] to train and evaluate our RLPGen method.
This database contains smart meter data of hourly load recordings (in kWh). After data cleaning,
we obtain the hourly load data of 417 households from Jan. 1, 2017 to Dec. 31, 2017. In our work,
we focus on load patterns using normalized hourly smart meter data and develop a novel method
(presented in Section 3) to generate diverse daily load patterns reflecting all kinds of real-world
consumption behaviors. For our future works, a more comprehensive comparison including non-GAN
and non-ML based method can be conducted and further extension can be done on our approach to
perform residential load demand data generation.
3 Methodology
As existing top-down methods can hardly capture diverse load patterns across various households,
whiles existing bottom-up methods are not suitable to overcome the load data shortage and privacy
concerns of load data collection, we develop an LSTM-based GAN model along with the weight
selection method to learn and generate residential load patterns. Inspired by TimeGAN [28], we 1)
introduce autoencoders in the model allowing adversarial training at the hidden space level, and 2)
perform weakly-supervised training for finer control over temporal dynamics. We use LSTM units
across the model to improve the ability of learning time-series load data. We present the detailed
model design and implementation as follows.
3.1 Model Design With Weakly Supervised Adversarial Training
Suggested in TimeGAN framework [28] and several other studies [10, 18, 19] adopting autoencoders
with GAN to perform adversarial training with the trained representation can improve learning simi-
larity measure, inference efficiency, and generative capability during adversarial training. As shown
in Figure 1, we integrate an over-complete autoencoder into the standard GAN, where the encoder
(Ewith weight parameters θE) encodes the original load pattern into a sparse representation ( h) in
the hidden space, and the decoder ( Rwith weight parameters θR) recovers the hidden representation
back to the load pattern format. This approach allows the data generation to be performed in a more
feature-rich hidden space so that the diverse household level load pattern can be more efficiently
captured. The encoder and decoder will be trained in the first step of model training by updating θE
andθRusing the recovery loss ( Lr), e.g., the mean square error of the estimated load patterns.
Relying solely on the feedback from the discriminator is not sufficient enough to help the generator
capture the stepwise conditional distributions in the data. Hence, a supervisor unit ( Swith weight
parameters θS) is employed following the generator ( Gwith weight parameters θG) as an additional
step to finely adjust the temporal dynamics of the output sequence of the generator to form a two-step
data generation process. The supervisor will be pre-trained in a supervised manner in the second
step of the model training, where part of the hidden representation will be taken as the input for the
2R/F
Real/Fake
Household Load PatternRandom Noise
Recovered Load Pattern
Generator(G) Supervisor(S)Encoder(E)Decoder(R)
Discriminator(D)Sparse
Representation  
Load Pattern Data
Generation PartFigure 1: Model structure of RLPGen. The dashed arrow represent inference in training process only
and solid arrow represent inference in both training and generation process.
supervisor to predict the one-step ahead value. The supervisor loss ( Ls) is calculated using MSE of
the predicted one-step ahead value to update θS.
The discriminator ( Dwith weight parameters θD) and the generation process (i.e., generator with
supervisor) are trained against each other to perform the adversarial training in the feature-rich hidden
space. The sparse representation can ensure that the complex and diverse structure of the load pattern
can be better reflected, which is more suitable for the top-down approach to residential load pattern
generation. During the third step of the training process, the standard adversarial loss ( La) will be
calculated to update θG,θSandθD, where a standard adversarial training of GAN is performed.
3.2 Model Weight Selection
The GAN training process can be unstable and suffer from mode collapse problems (i.e., consistently
generating data with low diversity regardless of the generator input) if overtrained [2]. However, the
quality of generated load pattern can hardly be fully reflected by the generator loss only. Hence, we
incorporate a model weight selection method by choosing the model weight with the lowest measured
distribution distance between the real and generated data. We assume the load pattern data follow a
multivariate Gaussian by only considering the mean and covariance. We adopt the method in [9] to
calculate the Fréchet distance using
D2
Fr´echet =||µXreal−µXfake||2+tr
ΣXreal+ ΣXfake−2 
ΣXrealΣXfake1
2
, (1)
where Xrealdenotes load pattern samples from real dataset, Xfake denotes load pattern samples
from generated dataset, D2
Fr´echet denotes the Fréchet distance between two multivariate Gaussian
distributions with means µXrealandµXfakeand covariance matrices ΣXrealandΣXfake.
3.3 Evaluation Methods
We validate our RLPGen method using the real-world data presented in Section 2. To evaluate the
generated results, we develop a set of comprehensive evaluation methods to measure the generated data
with two criteria: diversity and similarity. Our evaluation methods can address the two criteria at both
sequence level (i.e. evaluate individual load data sequence) and aggregated level (i.e. aggregate all
load data sequences in the dataset and evaluate the mean profile). We visually compare the difference
between load patterns along with their auto-correlation by selecting real and fake sample sets with the
minimum Euclidean distance, and dimension-reduced data points (i.e., perform dimension reduction
using PCA [4], and T-SNE [27]) across the original and generated datasets to evaluate the framework
performance at the sequence level. We further calculate distances, such as root mean square error
(RMSE) and Jenson-Shannon distance (J-S) between the mean profile of generated and original load
pattern samples to evaluate the model performance at the aggregated level.
34 Results and Discussions
To compare with our method, we select three state-of-the-art benchmark models, including ACGAN,
WGAN, and C-RNN-GAN. These methods have been adopted to solve similar problems, such as
time-series data generation. All selected benchmark models are considered to be good representations
of different types of GAN models (with details discussed in the Supplementary section).
1.5
 1.0
 0.5
 0.0 0.5 1.0 1.5
x-PCA1.5
1.0
0.5
0.00.51.01.5y-PCARLPGen
Original
Synthetic
1.5
 1.0
 0.5
 0.0 0.5 1.0 1.5
x-PCA1.5
1.0
0.5
0.00.51.01.5y-PCAWGAN
Original
Synthetic
1.5
 1.0
 0.5
 0.0 0.5 1.0 1.5
x-PCA1.5
1.0
0.5
0.00.51.01.5y-PCAACGAN
Original
Synthetic
1.5
 1.0
 0.5
 0.0 0.5 1.0 1.5
x-PCA1.5
1.0
0.5
0.00.51.01.5y-PCAC-RNN-GAN
Original
SyntheticPCA Visualization
10
 5
 0 5 10
x-T-SNE10
5
0510y-T-SNERLPGen
Original
Synthetic
10
 5
 0 5 10
x-T-SNE10
5
0510y-T-SNEWGAN
Original
Synthetic
10
 5
 0 5 10
x-T-SNE10
5
0510y-T-SNEACGAN
Original
Synthetic
10
 5
 0 5 10
x-T-SNE10
5
0510y-T-SNEC-RNN-GAN
Original
SyntheticT-SNE Visualization
Figure 2: Similarity and Diversity comparisons using dimension reduction data visualization tech-
nique. The top four plots use PCA and the bottom four plots use T-SNE.
As shown in Figure 2, all the tested models are able to capture certain levels of temporal correlation
and data distributions from original data. However, our RLPGen method is more capable of generating
residential load patterns with well-retained temporal feature correlation against original data while
still being able to capture the diverse patterns from real-life load patterns. Data points generated by our
RLPGen method are significantly more diverse than the two CNN-based GAN models (i.e., WGAN
and ACGAN) and achieve better coverage than the other RNN-based model (i.e., C-RNN-GAN).
Our method achieves a considerable amount of performance gain against the other three benchmark
models, by achieving the lowest distance from the original samples, as shown in Table 1.
Table 1: Result of Distance Measurements.
Distance Measurement RLPGen ACGAN WGAN C-RNN-GAN
J-S Distance 0.00770 0.18363 0.05576 0.04277
RMSE 0.03522 0.56700 0.26113 0.19247
5 Conclusion
In this paper, we developed a comprehensive method called RLPGen to generate residential load
patterns. Compare to existing methods, RLPGen has demonstrated significant improvement in
generated load pattern data quality and can be further adapted as a promising method to produce
representative household load patterns for different regions globally. The generated load pattern can
help the field of research to better understand residential consumption and greatly inform utilization
of renewable energy and responsible energy consumption. RLPGen method includes a GAN-based
model with weakly-supervised training and a weight selection method that can effectively select
generator weight with the highest quality of data generation while overcoming mode collapse issues.
We validated the performance of RLPGen against three state-of-the-art models, including ACGAN,
WGAN, and C-RNN-GAN, showing that RLPGen outperformed all the benchmarks.
4References
[1]I. Antonopoulos, V . Robu, B. Couraud, D. Kirli, S. Norbu, A. Kiprakis, D. Flynn, S. Elizondo-
Gonzalez, and S. Wattam, “Artificial intelligence and machine learning approaches to energy
demand-side response: A systematic review,” Renewable and Sustainable Energy Reviews , vol.
130, p. 109899, 2020.
[2]M. Arjovsky, S. Chintala, and L. Bottou, “Wasserstein generative adversarial networks,” in
International conference on machine learning . PMLR, 2017, pp. 214–223.
[3]M. Arpogaus, M. V oss, B. Sick, M. Nigge-Uricher, and O. Dürr, “Short-term density fore-
casting of low-voltage load using bernstein-polynomial normalizing flows,” arXiv preprint
arXiv:2204.13939 , 2022.
[4]F. B. Bryant and P. R. Yarnold, “Principal-components analysis and exploratory and confirmatory
factor analysis.” 1995.
[5]Y . Chen, Y . Wang, D. Kirschen, and B. Zhang, “Model-free renewable scenario generation
using generative adversarial networks,” IEEE Transactions on Power Systems , vol. 33, no. 3, pp.
3265–3275, 2018.
[6]D. L. Davies and D. W. Bouldin, “A cluster separation measure,” IEEE transactions on pattern
analysis and machine intelligence , no. 2, pp. 224–227, 1979.
[7]J. Dickert and P. Schegner, “A time series probabilistic synthetic load curve model for residential
customers,” in 2011 IEEE Trondheim PowerTech . IEEE, 2011, pp. 1–6.
[8]T. Ding, H. Liang, and W. Xu, “An analytical method for probabilistic modeling of the steady-
state behavior of secondary residential system,” IEEE Transactions on Smart Grid , vol. 8, no. 6,
pp. 2575–2584, 2016.
[9]D. Dowson and B. Landau, “The fréchet distance between multivariate normal distributions,”
Journal of multivariate analysis , vol. 12, no. 3, pp. 450–455, 1982.
[10] V . Dumoulin, I. Belghazi, B. Poole, O. Mastropietro, A. Lamb, M. Arjovsky, and A. Courville,
“Adversarially learned inference,” arXiv preprint arXiv:1606.00704 , 2016.
[11] B. Goldstein, D. Gounaridis, and J. P. Newell, “The carbon footprint of household energy use
in the united states,” Proceedings of the National Academy of Sciences , vol. 117, no. 32, pp.
19 122–19 130, 2020.
[12] A. Grandjean, J. Adnot, and G. Binet, “A review and an analysis of the residential electric load
curve models,” Renewable and Sustainable energy reviews , vol. 16, no. 9, pp. 6539–6565, 2012.
[13] Y . Gu, Q. Chen, K. Liu, L. Xie, and C. Kang, “Gan-based model for residential load generation
considering typical consumption patterns,” in 2019 IEEE Power & Energy Society Innovative
Smart Grid Technologies Conference (ISGT) . IEEE, 2019, pp. 1–5.
[14] Y . Himeur, A. Alsalemi, F. Bensaali, and A. Amira, “Building power consumption datasets:
Survey, taxonomy and future directions,” Energy and Buildings , vol. 227, p. 110404, 2020.
[15] J. Hu and A. V . Vasilakos, “Energy big data analytics and security: challenges and opportunities,”
IEEE Transactions on Smart Grid , vol. 7, no. 5, pp. 2423–2436, 2016.
[16] C. Klemenjak, C. Kovatsch, M. Herold, and W. Elmenreich, “A synthetic energy dataset for
non-intrusive load monitoring in households,” Scientific data , vol. 7, no. 1, pp. 1–17, 2020.
[17] W. Labeeuw and G. Deconinck, “Residential electrical load model based on mixture model
clustering and markov models,” IEEE Transactions on Industrial Informatics , vol. 9, no. 3, pp.
1561–1569, 2013.
[18] A. B. L. Larsen, S. K. Sønderby, H. Larochelle, and O. Winther, “Autoencoding beyond pixels
using a learned similarity metric,” in International conference on machine learning . PMLR,
2016, pp. 1558–1566.
[19] A. Makhzani, J. Shlens, N. Jaitly, I. Goodfellow, and B. Frey, “Adversarial autoencoders,” arXiv
preprint arXiv:1511.05644 , 2015.
[20] A. Marszal-Pomianowska, P. Heiselberg, and O. K. Larsen, “Household electricity demand
profiles–a high-resolution load model to facilitate modelling of energy flexible buildings,”
Energy , vol. 103, pp. 487–501, 2016.
5[21] A. Odena, C. Olah, and J. Shlens, “Conditional image synthesis with auxiliary classifier gans,”
inInternational conference on machine learning . PMLR, 2017, pp. 2642–2651.
[22] E. Proedrou, “A comprehensive review of residential electricity load profile models,” IEEE
Access , vol. 9, pp. 12 114–12 133, 2021.
[23] B. Stephen, A. J. Mutanen, S. Galloway, G. Burt, and P. Järventausta, “Enhanced load profiling
for residential network customers,” IEEE Transactions on Power Delivery , vol. 29, no. 1, pp.
88–96, 2013.
[24] Street Pecan, “Pecan street online database,” [Accessed July 2019]. [Online]. Available:
https://www.pecanstreet.org/work/energy/
[25] R. Subbiah, K. Lum, A. Marathe, and M. Marathe, “Activity based energy demand modeling
for residential buildings,” in 2013 IEEE PES Innovative Smart Grid Technologies Conference
(ISGT) . IEEE, 2013, pp. 1–6.
[26] G. Valverde, A. Saric, and V . Terzija, “Probabilistic load flow with non-gaussian correlated
random variables using gaussian mixture models,” IET generation, transmission & distribution ,
vol. 6, no. 7, pp. 701–709, 2012.
[27] L. Van der Maaten and G. Hinton, “Visualizing data using t-sne.” Journal of machine learning
research , vol. 9, no. 11, 2008.
[28] J. Yoon, D. Jarrett, and M. Van der Schaar, “Time-series generative adversarial networks,”
Advances in neural information processing systems , vol. 32, 2019.
[29] C. Zhang, S. R. Kuppannagari, R. Kannan, and V . K. Prasanna, “Generative adversarial network
for synthetic time series data generation in smart grids,” in 2018 IEEE International Conference
on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm) .
IEEE, 2018, pp. 1–6.
[30] L. Zhang and B. Zhang, “Scenario forecasting of residential load profiles,” IEEE Journal on
Selected Areas in Communications , vol. 38, no. 1, pp. 84–95, 2019.
[31] T. Zufferey, D. Toffanin, D. Toprak, A. Ulbig, and G. Hug, “Generating stochastic residential
load profiles from smart meter data for an optimal power matching at an aggregate level,” in
2018 Power Systems Computation Conference (PSCC) . IEEE, 2018, pp. 1–7.
6 Supplementary
6.1 Details of Benchmark Models
The details of selected benchmark models are discussed as follows:
1.Auxiliary Classifier Generative Adversarial Network (ACGAN) is a specialized CNN-
based GAN, which can perform data generation based on given class labels. Proposed by
Gu [13] to pre-label all load data using K-Means Clustering and then perform training and
generation using ACGAN, can further ensure the diversity of the model. Hence, we choose
ACGAN as the baseline to compare with our framework, to assess both the capability of the
CNN-based approach and the pre-clustering method.
2.Wasserstein Generative Adversarial Network (WGAN) uses Wasserstein distance to
replace the original loss function in standard CNN based GAN to solve the mode collapse
problem. Since existing energy related studies [5,29] have also suggested to use CNN based
GAN method to perform time series data generation, we choose WGAN as a representation
used in our benchmarks to compare with the RNN-based models and pre-clustering method.
3.Continuous RNN-GAN (C-RNN-GAN) is an RNN-based GAN method. For the compari-
son purposes, we use LSTM units in the C-RNN-GAN model to compare the performance
of LSTM-based GAN against CNN-based GAN and evaluate the performance differences by
further incorporating overcomplete autoencoders and weakly-supervised training method.
The benchmark evaluation has been done under the following model training and data generation
conditions:
61.To ensure all selected models are being evaluated under the same condition, we perform
the model weight selection process for all selected models to generate the best possible
benchmark result.
2.During the preprocessing before ACGAN model training, we carefully select the Kvalue
for K-Means clustering with the lowest Davies-Bouldin Index (DBI) [6] which evaluates the
goodness of split of the clustering algorithm. In our study, DBI starts to stabilize when the
Kvalue reaches 10. Therefore, we choose K= 10 to perform K-Means clustering.
3.To ensure the distribution of original data can be accurately reflected, we generate the same
number of data points as the sampled evaluation dataset from original load pattern data. For
the ACGAN model, we further ensure the number of data points from each cluster stays the
same as the sampled evaluation dataset.
6.2 Similarity comparison of selected original and generated sample sets
In this section, we provide the pattern plots along with the auto-correlation plots for similarity
comparison. We randomly selected three typical load patterns from original data that can represent
different household electricity consumption. The peak hours generally suggest the residents start
to use appliances while during lower consumption periods the residents are more likely to rest or
not at home. Figure 3(a) demonstrates 2 load peaks from 7:00 to 9:00 and 17:00 to 24:00, where
the first peak period can reflect the time when the residents wake up and prepare for breakfast, and
the second peak period at night matches with the time when residents go back home after work or
school. In Figure 3(b), the electricity consumption peak starts from 12:00 until 20:00 which can
potentially due to the residents are working in night shift so that the activities are concentrated during
the afternoon and in the early evening. The third representative load pattern shown in Figure 3(c)
demonstrates three peak periods in the morning, noon, and night which matches the preparation time
of three meals.
In each figure, the matched generated load pattern samples are selected within the synthetic datasets
generated using different models with the lowest Euclidean Distance. From the plot, we can see
that patterns generated by our model are able to more accurately capture peaks within the daily load
pattern shown in the pattern comparison graph and better retain temporal dynamics shown in the
auto-correlation graph.
0 5 10 15 20
Time (1hr)0.00.20.40.60.81.0Electricity LoadPattern
Original
RLP-GAN
WGAN
ACGAN
C-RNN-GAN
0 2 4 6 8 10 12
Time-lag0.2
0.00.20.40.60.81.0CoefficientAutocorrelation
Original
RLP-GAN
WGAN
ACGAN
C-RNN-GAN
Figure 3(a): Representative load pattern 1.
70 5 10 15 20
Time (1hr)0.00.20.40.60.81.0Electricity LoadPattern
Original
RLP-GAN
WGAN
ACGAN
C-RNN-GAN
0 2 4 6 8 10 12
Time-lag0.4
0.2
0.00.20.40.60.81.0CoefficientAutocorrelation
Original
RLP-GAN
WGAN
ACGAN
C-RNN-GANFigure 3(b): Representative load pattern 2.
0 5 10 15 20
Time (1hr)0.00.20.40.60.81.0Electricity LoadPattern
Original
RLP-GAN
WGAN
ACGAN
C-RNN-GAN
0 2 4 6 8 10 12
Time-lag0.2
0.00.20.40.60.81.0CoefficientAutocorrelation
Original
RLP-GAN
WGAN
ACGAN
C-RNN-GAN
Figure 3(c): Representative load pattern 3.
8