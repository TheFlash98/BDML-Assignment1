Submitted to Tackling Climate Change with Machine Learning: workshop at NeurIPS 202 2. Estimating Chicago’s tree cover and cano py height  
using multi -spectral satellite imagery  
 
John Francis                                             Stephen Law  
        The Alan Turing Institute  &                   University College London  & 
                           University College London                         The Alan Turing Institute  
 
Abstract  
Information on  urban tree canop ies is fundamental t o mitigating climate change 
[1] as well as improving quality of life  [2]. Urban  tree planting initiatives  face a 
lack of up -to-date data about the  horizontal and vertical dimension s of the tree 
canopy  in cities . We pr esent  a pipeline  that utilizes  LiDAR  data as ground -truth  
and then trains a multi -task machine  learning  model  to generate  reliable  estimates  
of tree cover  and canopy  height  in urban  areas  using  multi -source  multi -spectral  
satellite  imagery  for the case study  of Chicago .  
1 Introduction  1 
Major American cities such as New York, Los Angeles, Boston, and Chicago have set fo rth tree 2 
planting initiatives as part of larger efforts to mitigate climate change, improve quality of life, and 3 
promote environmental equity. One of the primary issue s policymakers face when deciding how to 4 
allocate tree planting resources is a lack of hi gh quality, up -to-date datasets about the urban canopy. 5 
This paper  proposes a novel pipeline for generating estimates of two urban canopy measures, tree 6 
cover and canopy height,  in Chicago  for timepoints when high -quality data is unavailable. Previous 7 
research has utilized machine learning ( ML) approaches  to predict tree canopy  [3] but  have yet  to 8 
leverage th ese technique s to create detailed estimates of urban tree cover and canopy height a s 9 
demonstrated in this project.  10 
2 Data on the Urban Canopy  11 
Three main techniques have been  previously developed to generate estimates of urban canopies . 12 
Surveying techniques  have been used, for example, by Morton Arboretum in Chicago to produce a 13 
tree census. This tree census counted the number of trees in 268 selected plots, and then extrapolated 14 
those numbers to the entire city, estimating that Chicago contains about 3,997,000 trees  [4]. As it 15 
would be impossible for humans to physically  count the num ber of trees in an area as large as 16 
Chicago, the exact number of trees remains  unknown and can only be estimated.  17 
An alternative to surveying techniques is airborne Light Detection and Ranging (LiDAR). LiDAR 18 
utilizes light beams to create a cloud of millio ns of points  that can be  accurate within a few 19 
centimeters [5].  Numerous algorithms exist for detecting and measuring trees from LiDAR point 20 
clouds  that can be used to generate three -dimensional  representations  of the urban canopy . Despite 21 
this, LiDAR can only capture  a point in time, and the collection of LiDAR data, especially over 22 
large areas, is quite expensive, so researchers are often relegated to using outdated data.  23 
To get around a lack of consistent data collection, ML techniques can be used to ge nerate accurate, 24 
up-to-date estimates of urban canopies.  Weinstein et al.  [6] used a convolutional neural network to 25 
identify individual trees through image segmentation in a California forest using RGB (red, green, 26 
and blue) images . In addition to RGB ima ges, multi -spectral (MS) imagery  has been shown to aid 27 
in predictive models. Wang Li et al.  [3] successfully  used a ML model to predict forest canopy height 28 
from MS imagery in a mountainous region of China. Furthermore, p revious research has tried  to 29 
predict relative building and vegetation height and semantic segmentation masks simultaneously  30 
[7,8]. Despite these efforts,  studies have yet to estimate tree cover and canopy height in an urban 31 
setting using MS satellite images.  32  
 
 2 This paper focuses on  multiple measures of the urban canopy, tree cover and canopy height, because 33 
alone, neither horizontal nor vertical measures of the urban canopy capture the whole effect trees 34 
have on the environment. In general, larger trees tend to have a greater enviro nmental effect than 35 
smaller trees, with numerous smaller trees often unable to match the effects of a single large tree [9, 36 
10]. By accounting for both a horizontal and vertical measure, a more accurate assessment of the 37 
urban canopy’s impact on climate in dicators  can eventually  be quantified.  38 
3 Estimating Tree Cover and Canopy Height  39 
Chicago LiDAR point cloud data from 2017 was retrieved from the Illinois Geospatial Data 40 
Clearinghouse [11]. Additional MS satellite imagery was used from the National Agriculture 41 
Imagery Program (NAIP) and the Sentinel -2 satellite program. Four -band NAIP RBG and NIR data  42 
at 1-m resolution was collected from the US Geological Survey’s earth explorer for 2017 and 2019. 43 
Sentinel -2 data from 2017 and 2019 was collected from the Sentinel Hub’s Earth observation 44 
browser, with four bands at 10 -m resolution, and s ix bands at 20 -m resolution. A methodology 45 
similar to Roussel et al.  [12] was used to extract ground truth tree cover and canopy height measures 46 
from the LiDAR data . Details on how the input data was prepared can be found in the appendix . 47 
3.2 Training the UNet Multi -Task Model  48 
This paper followed a multi -task (MT)  learning approach, utilizing the UNet architecture  which has 49 
achieve d good performance on various  pixel -level tasks [13,14,15,16]. Three tasks,  predicting  if a 50 
pixel is part of a tree (tree mask) , estimating how tall a pixel represents (pixel height) , and  a third 51 
auxiliary task predicting whether a pixel represents impervious space (NDVI<0) were  included 52 
together  to enable better generalizations on individual tasks . The U Net architecture consists of an 53 
encoding path and a decoding path that share representations to increase the output’s resolution [ 17]. 54 
 
Figure 1. UNet model architecture . 55 
The primary MT model used in this paper can be seen in Figure 1. The output of the decoding path 56 
is fed into three separate convolutional layers, one with a linear activation (pixel height) and two 57 
with sigmoid activation (tree mask, auxiliary mask). To retrieve canopy h eight, the predicted tree 58 
mask was applied to the pixel height layer to only retain the height of pixels determined by the 59 
model to be trees. An Adam optimizer algorithm was used to train models with mean squared error 60 
loss used for pixel height and with J accard distance loss used for the two binary masks to account 61 
for class  imbalance  in the data  [18]. In total, 9,535 240x240 images from 2017 were used to train 62 
the model, with 25% of these images held out as a testing set. The input images for the model 63 
consisted of the 14 MS bands from the NAIP and Sentinel 2 satellite images.  In addition to the 64 
primary model shown in Figure 1, separate models for comparison were run with just the RGB 65 
bands of the NAIP image s, single -task versions of the model for each out put, and versions where 66 
only the encoding features of the model were shared by the three task s, with separate decoding layers 67 
for each output . The model was trained  and evaluated  solely using data from 2017 . It was then used 68 
to predict tree cover and canop y height for 2019 where ground truth data does not exist. To evaluate 69 
model performance, Intersection over Union (IoU) is used for the tree mask and the impervious 70 
 
 
 3 surface mask, while Mean Absolute Error (MAE) is used for pixel height.  71 
4 Results  72 
Ten UNet models were run to determine which method was best able to locate trees and determine 73 
their height. Table 1 shows the results of these models. The model that was best able to locate trees 74 
(IoU=.647) was the MT model with fully shared layers. This was  unexpected as the MT model with 75 
partially shared layers (encoding only) contain ed nearly twice as many parameter s and allowed for 76 
more features specific to the individual tasks. Because the tasks are all closely related, the features 77 
most relevant to each individual task may simply be  the shared features . Pixel height was best 78 
predicted by the UNet model looking at pixel height alone within about five percent of the observed 79 
value.  It is possible that pixel height predictions suffered  in the MT models because the weighting 80 
scheme was more focused on generating an accurate prediction of tree location. Notably,  while  the 81 
MT models using  MS image bands achieved better results for all t hree tasks,  nearly comparable 82 
results were found when using only the RGB bands of the NAIP data .  83 
Table 1: UNet model results  84 
 85 
Model  Bands Used  Tree Mask IoU  Height MAE  Auxiliary IoU 
Tree Mask Alone  RGB Only  .475 - - 
Tree Mask Alone  14 MS Bands  .476 - - 
Pixel Height Alone  RGB Only  - .063 - 
Pixel Height Alone  14 MS Bands  - .050 - 
Auxiliary Mask  RGB Only  - - .131 
Auxiliary Mask  14 MS Bands  - - .747 
MT Fully Shared  RGB Only  .614 .099 .878 
MT Fully Shared  14 MS Bands  .647 .085 .940 
MT Partially Shared  RGB Only  .621 .070 .884 
MT Partially Shared  14 MS Bands  .642 .072 .934 
While the IoU of .647 and the MAE of .050 indicated relatively good predictions of tree cover  and 86 
canopy height, it was important to visually inspect the results to ensure  that the metrics provided an 87 
accurate assessment of model performance. Figure 2 show s the ground truth raster layers generated 88 
by the analysis of the LiDAR data, the RGB bands of the NAIP satellite image that fed into the 89 
model, and the predicted  output raster layers generated by the models for tree cover and canopy 90 
height among the 2017 test data. Tree cover seems to mimic the ground truth data  well, although 91 
there may be a slight  overinflation of tree size in some spots. Additionally, it appears that some 92 
smaller trees may have been missed, while some small shrubbery may have been miside ntified as 93 
trees. This is to be expected as even a human looking through the satellite images would have a 94 
difficult time capturing all the pixels that contain trees. For pixel height, the model clearly struggled 95 
with some of the taller buildings ; however, it is important to remember that only the height of pixels 96 
determined to be trees are interpreted  in final canopy height estimates . Among locations that are 97 
clearly trees from the satellite data, the model seemed to appropriately predict height values .  98 
 
Figure 2: 2017 tree cover and pixel height  predictions . 99 
 
 
 4 4.1 Predicting 2019 Tree Cover and Canopy Height  100 
Utilizing  the model trained in 2017, we inferred the 2019 tree cover and canopy height metrics for 101 
Chicago  and estimated a total city -wide cover of 5.9%. This is a slight increase from the ground 102 
truth 2017 LiDAR data which calculated the city -wide cover  to be about 4.8%. Notably, these 103 
estimates are much lower than results from Chicago’s 2020 tree census which estimated the canopy 104 
cover to be nearly 16% when including shrubs  [4]. This paper’s  estimates may be more reliable than 105 
the larger tree cover estimates proposed via survey techniques  as they are based on the highly 106 
accurate 2017 LiDAR data. The ten sample images shown in Figure 2 all provide examples of areas 107 
with less than 10% of pixels  identified as trees. Figure 3 shows the 2019 UNet predictions  at 46,149 108 
census blocks . The maps here indicate that the areas of highest tree cover are concentrated primarily 109 
in the northern part of the city, as well as within the many parks that line Chic ago’s eastern coast.  110 
 
Figure 3: Estimated tree cover and canopy height . 111 
5 Conclusions and Future Work  112 
This paper provides a novel pipeline  for estimating tree cover and canopy height. Utilizing ML, 113 
specifically the UNet architecture with MS imagery, researchers and policy makers are presented a 114 
method  with which to generate up -to-date and accurate measures of the urban canopy. With better 115 
data, better decisions can be made about where to plant new trees in cities to maximize climate 116 
benefits while improving equity and quality of life for as many people  as possible. The results from 117 
this study provide confidence that ML methodologies can generate usable estimates of the urban 118 
canopy moving forward. Additionally, many studies utilizing satellite imagery across different 119 
domains for various ML tasks only u se RGB image bands, often because RGB bands are the only 120 
bands available at high resolutions. This study provides initial evidence that including MS bands in 121 
ML models, even when these bands are at lower resolutions, can lead to slight increases in predict ive 122 
capacity. Urban tree canopies are constantly evolving, so to keep up with these ever -changing 123 
environments, policy makers  need to arm themselves with the highest quality data. When  and where 124 
LiDAR data collection is unavailable, ML methods provide a pro mising alternative for researchers 125 
and governments  to generate estimates of the urban canopy . 126 
Moving forward,  newer  ML models could be easily integrated into this pipeline,  while more 127 
resources could allow for the usage of higher resolution MS imagery to f urther improve predictions. 128 
Additionally , there is a need to test model generalizability geographically leveraging global LiDAR 129 
datasets (e.g. GEDI) as well as including additional auxiliary tasks (e.g. species type, above ground 130 
carbon estimates) which ca n provide useful information for urban tree planting policies and 131 
initiatives. By leveraging ML techniques to generate high quality data, public  officials will be given 132 
more confidence that their decisions will have strong and lasting positive impact s on communities.  133 
 
 
 5 Acknowledgements  and Funding  134 
This work was supported by Towards Turing 2.0 under the EPSRC Grant EP/W037211/1 and The 135 
Alan Turing Institute.  This work was completed as part of the Social and Geographic Data Science 136 
MSc program within  the University College London ’s Department of Geography . Special thanks 137 
to Mat Disney  for his advice on  tree metrics and the use of LiDAR data.   138 
References  139 
[1] Zimmerman, R., & Faris, C. (2011). Climate change mitigation and adaptation in North American 140 
cities. Current Opinion in Environmental Sustainability, 3(3), 181 -187. 141 
[2] Hipp, J. A., Gulwadi, G. B., Alves, S. & Sequeira, S. (2015). The Relationship Between  Perceived 142 
Greenness and Perceived Restorativeness of University Campuses and Student -Reported Quality of 143 
Life. Environment and Behavior, 48(10), 1292 -130. 144 
[3] Li, W., Niu, Z., Shang, R., Qin, Y., Wang, L., & Chen, H. (2020). High -resolution mapping of for est 145 
canopy height using machine learning by coupling ICESat -2 LiDAR with Sentinel -1, Sentinel -2 and 146 
Landsat -8 data. International Journal of Applied Earth Observation and Geoinformation, 92, 102163.  147 
[4] The Morton Arboretum. (2021). 2020 Chicago Region Tr ee Census Report. The Morton Arboretum.  148 
[5] Kim M., Park S., Irwin J., McCormick C., Danielson J., Stensaas  G., Sampath A., Bauer M., Burgess 149 
M. (2020). Positional Accuracy Assessment of Lidar Point Cloud from NAIP/3DEP Pilot Project. 150 
Remote Sensing. 12(12):1974.  151 
[6] Weinstein, B.G., Marconi, S., Bohlman, S., Zare, A., & White, E. (2019). Individual tree -crown 152 
detection in RGB imagery using semi -supervised deep learning neural networks. Remote Sensing, 153 
11(11), 1309.  154 
[7] Lu, M.; Liu, J.; Wang, F.; Xiang, Y. Multi -Task Learning of Relative Height Estimation and Semantic 155 
Segmentation from Single Airborne RGB Images . Remote Sens. 2022, 14, 3450.  156 
[8] Karatsiolis, S.; Kamilaris, A.; Cole, I. IMG2nDSM: Height Estimation from Single Airborne RGB 157 
Images with Deep Learning. Remote Sens. 2021, 13, 2417.  158 
[9] Le Roux, D. S., Ikin, K., Lindenmayer, D. B., Manning, A. D., & Gi bbons, P. (2015). Single large 159 
or several small? Applying biogeographic principles to tree -level conservation and biodiversity offsets. 160 
Biological conservation, 191, 558 -566. 161 
[10] Stephenson, N. L., Das, A. J., Condit, R., Russo, S. E., Baker, P. J., Beckm an, N. G., & Zavala, M. 162 
A. (2014). Rate of tree carbon accumulation increases continuously with tree size. Nature, 507(7490), 163 
90-93. 164 
[11] Illinois Height Modernization Program, Illinois State Geological Survey, & Illinois Department of 165 
Transportation. (201 7). Illinois LiDAR county database: Illinois State Geological Survey. Available at: 166 
https://clearinghouse.isgs.illinois.edu/data/elevation/illinois -height -modernization -ilhmp  167 
[12] Roussel J., Auty D., Coops N.C., Tompalski P., Goodbody T.R., Meador A.S., B ourdon J., de 168 
Boissieu F., & Achim A. (2020). lidR: An R package for analysis of Airborne Laser Scanning (ALS) 169 
data. Remote Sensing of Environment, 251, 112061. ISSN 0034 -4257.  170 
[13] Singh, N. J., & Nongmeikapam, K. (2022). Semantic Segmentation of Satellite Images Using Deep - 171 
Unet. Arabian Journal for Science and Engineering, 1 -13. 172 
[14] McGlinchy, J., Johnson, B., Muller, B., Joseph, M., & Diaz, J. (2019). Application of UNet fully 173 
convolutional neural network to impervious surface segmentation in ur ban environment from high 174 
resolution satellite imagery. In IGARSS 2019 -2019 IEEE International Geoscience and Remote Sensing 175 
Symposium (pp. 3915 -3918). IEEE.  176 
[15] Andersson, T.R., Hosking, J.S., Pérez -Ortiz, M. et al . (2021 ). Seasonal Arctic Sea ice foreca sting 177 
with probabilistic deep learning. Nat Commun 12, 5124.  178 
[16] Alsabhan, W., & Alotaiby, T. (2022). Automatic Building Extraction on Satellite Images Using Unet 179 
and ResNet50. Computational Intelligence and Neuroscience, Vol. 2022.  180 
[17] Ronneberger, O., Fischer, P., & Brox, T. (2015). U -net: Convolutional networks for biomedical 181 
image segmentation. In International Conference on Medical image computing and computer -assisted 182 
intervention (pp. 234 -241). Springer, Cham.  183 
[18] Yuan, Y., Chao, M., & Lo, Y.C. ( 2017). Automatic skin lesion segmentation using deep fully 184  
 
 6 convolutional networks with jaccard distance. IEEE transactions on medical imaging, 36(9), 1876 -1886.  185 
[19] Zhao, Z., Wang, H., Wang, C., Wang, S., & Li, Y. (2019). Fusing LiDAR data and aerial imag ery 186 
for building detection using a vegetation -mask -based connected filter. IEEE Geoscience and Remote 187 
Sensing Letters, 16(8), 1299 -1303.  188 
[20] Dalponte, M. & Coomes , D.A. (2016). Tree -centric mapping of forest carbon density from airborne 189 
laser scanning and hyperspectral data. Methods Ecol Evol 7:1236 –1245.  190 
Appendix  191 
Preparing the UNet input  data  192 
The LiDAR  point cloud data consisted of 1,131 2500x2500 foot tiles with a derived nominal pulse 193 
spacing of one point every 0.35 meters. First, a vegetation mask was created using the NIR and Red 194 
bands of the NAIP images, creating a normalized difference vegetation index (NDVI) raster layer 195 
as calculated in Zhao et al. [19]. The point cloud was then masked, keeping only points that were 196 
vertically aligned with NDVI values above .05. Masking the point cloud not only speeds up 197 
calculations, but also prevents buildings and non -biological objects from being classified as trees. 198 
Points below six feet and above 80 feet were filtered out to ignore small shrubbery and any incidental 199 
non-vegetation points (e.g., birds). A canopy height model was then generated using a pitfree 200 
algorithm which allows for individual tree detection using a local maximum filter. Next, tree s were  201 
segment ed based on the Dalponte and Coomes algorithm [20]. From this process, two raster layers 202 
were generated, one with binary values if a pixel was identi fied as being part of a tree, while the 203 
other raster layer contained the average max height of each pixel. These raster layers were then 204 
mosaiced together and stacked on top of the Sentinel -2 and NAIP data which were all projected to 205 
the extent and resolut ion of the NAIP 1 -m data. These raster stacks were then cut into 240x240 pixel 206 
patches to be used as the input for a convolutional neural network . 207 