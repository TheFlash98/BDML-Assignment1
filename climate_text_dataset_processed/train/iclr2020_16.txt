Published as a conference paper at ICLR 2020
WAVELET -POWERED NEURAL NETWORKS
FOR TURBULENCE
Arvind T. Mohan
Center for Nonlinear Studies
Computer, Computational and Statistical Sciences Division
Los Alamos National Laboratory
Los Alamos, NM, United States
arvindm@lanl.gov
Daniel Livescu
Computer, Computational and Statistical Sciences Division
Los Alamos National Laboratory
Los Alamos, NM, United States
flivescug@lanl.gov
Michael Chertkov
Dept. of Mathematics
University of Arizona
Tucson, AZ, United States
chertkov@math.arizona.edu
ABSTRACT
One of the fundamental driving phenomena for climate effects is Ô¨Çuid turbulence
in geophysical Ô¨Çows. Modeling these Ô¨Çows and explaining its associated spatio-
temporal phenomena are notoriously difÔ¨Åcult tasks. Navier-Stokes (NS) equations
describe all the details of the Ô¨Çuid motions, but require accounting for unfeasibly
many degrees of freedom in the regime of developed turbulence. Model reduc-
tion and surrogate modeling of turbulence is a general methodology aiming to
circumvent this curse of dimensionality. Originally driven by phenomenological
considerations, multiple attempts to model-reduce NS equations got a new boost
recently with Deep Learning (DL), trained on the ground truth data, e.g. extracted
from high-Ô¨Ådelity Direct Numerical Simulations (DNS). However, early attempts
of building NNs to model turbulence has also revealed its lack of interpretability
as the most signiÔ¨Åcant shortcoming. In this paper we address the key challenge
of devising reduced but, at least partially, interpretable model. We take advantage
of the balance between strong mathematical foundations and the physical inter-
pretability of wavelet theory to build a spatio-temporally reduced dynamical map
which fuses wavelet based spatial decomposition with spatio-temporal modeling
based on Convolutional Long Short Term Memory (C-LSTM) architecture. It is
shown that the wavelet-based NN makes progress in scaling to large Ô¨Çows, by
reducing computational costs and GPU memory requirements.
1 C HALLENGE OF LEARNING SPATIO -TEMPORAL PHYSICS
Multitude of research problems in earth and climate sciences are exceptionally complex to study
and model with existing analysis tools because of their high-dimensionality, with thousands-to-
millions degrees of freedom exhibiting spatio-temporal dynamics, non-linearity and chaos. One of
the most pertinent problems combining all these factors is Ô¨Çuid turbulence which occurs in geo-
physical Ô¨Çows and inÔ¨Çuences much of near and long term climate effects. In an era where vast
Use footnote for providing further information about author (webpage, alternative address)‚Äî notfor ac-
knowledging funding agencies. Funding acknowledgements go at the end of the paper.
1Published as a conference paper at ICLR 2020
Figure 1: Wavelet-3D-C-LSTM: A schematic
quantities of turbulence data are generated for studying these applications, building practically us-
able, physics-driven reduced order surrogate models becomes extremely challenging and important.
Recent surge in devising NN-based reduced models of turbulence Hennigh (2017); Wu et al. (2019);
King et al. (2018) including signiÔ¨Åcant efforts from the computer graphics community Wiewel et al.
(2019); Werhahn et al. (2019); Xie et al. (2018); Um et al. (2018) for Ô¨Çow visualization by applying
powerful, but application-agnostic Deep Learning (DL) techniques, such as Generative Adversarial
Networks Goodfellow et al. (2014) and Convolutional LSTM (C-LSTM) Networks Xingjian et al.
(2015) has provided valuable tools boosting research in this important Ô¨Åeld of physics. However,
majority of approaches used in this emerging Ô¨Åeld are limited to analysis based on two dimensional
spatial projections of the originally 3+1 dimension (three-dimensional space and another dimension
in time) spatio-temporal data-sets. Some of the state-of-the art spatio-temporal NN modeling archi-
tectures, like C-LSTM, have signiÔ¨Åcant memory costs thus resulting in a limited utility to practical,
e.g. climate and geophysical, datasets. Our main focus in this paper is on making C-LSTM tractable
for large scientiÔ¨Åc spatio-temporal datasets.
2 E XISTING STRATEGY : AUTOENCODER 3D C ONVOLUTIONAL LSTM
An approach to building reduced modeling of massive 3D spatio-temporal turbulence datasets is
described in Mohan et al. (2019). The main spatio-temporal modeling block, 3D-C-LSTM, was
implemented in Mohan et al. (2019) through 3D extension of the 2D C-LSTM, originally proposed
in Xingjian et al. (2015). To reduce dimensionality, spatial compression and decompression steps
were implemented via autoencoders, sandwiched by 3D-C-LSTM layers. A sequence of 50 tempo-
ral snapshots, each of size 1283with3velocity components, was used. This imposed a signiÔ¨Åcant
training cost, and the solution relied on convolutional auto-encoders to compress/decompress data
before/after the 3D-C-LSTM block. The approach has helped to compress by factor of 125, down to
15315numbers. Knowledge of physics was utilized in Mohan et al. (2019) postfactum ‚Äì only to
evaluate prediction quality. However, this generally successful autoencoder-based approach had two
important shortcomings. First, we do not have explicit control on the features to retain in the latent
space and therefore some important features may be lost. Second, autoencoders are computationally
expensive for even moderate in size datasets. This manuscript suggests to resolve these compli-
cations by replacing the autoencoder NNs with explicit and physics-based model reduction guided
by wavelets. Wavelets provide additional beneÔ¨Åts of strong mathematical foundations through the
wavelet selection (e.g. resulting in numerical stability) and signiÔ¨Åcant reduction of the underlying
computational cost.
3 P ROPOSED SOLUTION : W AVELET -3D-C-LSTM
In this manuscript we propose a new NN scheme, coined Wavelet-CLSTM , to simultaneously ad-
dress the twin challenges of reducing the computational cost and injecting physics-based features
into the procedure. The key idea of our Wavelet-CLSTM scheme consists in decomposing the 3+1
2Published as a conference paper at ICLR 2020
dimensional training data set with the wavelet transform, which results in a compact representation
though the wavelet coefÔ¨Åcients. The approach is superior to the previously used (auto-encoder based
compression/decompression) methodology because it represents turbulence data in a compact, math-
ematically accurate, robust and Ô¨Çexible way. Moreover, we capitalize on the fact, well documented
in the literature Farge (1992); Meneveau (1991); Everson et al. (1990); Farge et al. (2001); Schneider
et al. (1997); Pulido et al. (2016); Li et al. (2018), that the wavelet coefÔ¨Åcients capture multi-scale
physics embedded in the turbulence dataset in one of the most efÔ¨Åcient compressed formats. For
example, a 3 level wavelet decomposition of a volumetric dataset of size 1283produces 512coef-
Ô¨Åcients of size 163. This reduction in dimensionality is critical for saving memory and improving
practical applicability of powerful, but expensive, architectures like C-LSTM. Additionally, a full
wavelet decomposition can be used to perfectly reconstruct the original dataset i.e it is non-lossy
if all coefÔ¨Åcients are considered. However, for reduced order modeling of practical datasets, we
choose fewer coefÔ¨Åcients to achieve maximal compression. This is an important choice to be made
prior to training called wavelet thresholding , where the coefÔ¨Åcients with the highest L2 norm are
chosen for training - this cutoff number is determined by % of ‚Äúenergy‚Äù captured by the coefÔ¨Åcients.
A3%thresholding would indicate 3=10051215coefÔ¨Åcients with the highest L2 norm. When
compared with autoencoders, wavelets are advantageous because:
Wavelet coefÔ¨Åcients have a dimensionality orders of magnitude lower than the original
training data , and low dimensional coefÔ¨Åcients of a desired size can be computed for
extremely large datasets Pulido et al. (2016); Rodler (1999); Ihm & Park (1999). This
decouples training for each wavelet coefÔ¨Åcient from other coefÔ¨Åcients, thereby avoiding
communication overheads and memory limitations which otherwise would plague large,
distributed, parallel training tasks.
Wavelet transform (decomposition) and inverse wavelet transform (reconstruction) can be
computed analytically , making it orders of magnitude cheaper and faster.
An additional beneÔ¨Åt of the analytical formulation translates into ability to extend thresh-
olding, i.e. the scales to be modeled can be explicitly selected a priori to training. (This
is to be contrasted to the convolutional autoencoder handicap which lacked direct control,
apart from selection of kernel size Mohan et al. (2019) during training.)
Oura priori analysis of the 3%thresholding shows that it captures all the large scales, and a ma-
jority of the intermediate scales in turbulence, however excluding sufÔ¨Åciently small scales. This
is an acceptable trade-off, since large and intermediate scales are typical quantities of interest in
majority of practical applications Meneveau & Katz (2000); She & Leveque (1994); Port ¬¥e-Agel
et al. (2000). We would like to emphasize, however, that including smaller scales by increasing the
thresholding percentage, is a degree of freedom to decide based on the application requirements. In-
creasing thresholding percentage increases the total training duration; but the adaptive, local nature
of the coefÔ¨Åcients ensures that the memory cost of training per coefÔ¨Åcient stays constant , such that
various coefÔ¨Åcients can be trained separately , on available computer resources. This remarkable
feature of the wavelet decomposition makes large scale parallelism a choice - rather than a neces-
sity - thereby opening up this technique to extremely large datasets even with moderate computer
resources available. To further increase compression efÔ¨Åciency we plan to investigate in the future
scale based thresholding (i.e. different thresholds at different scales) as well as integer quantization
(or re-quantization) to reduce the number of bits needed to represent the coefÔ¨Åcients. A Schematic
outlining this methodology is illustrated in Fig. 1.
4 R ESULTS
The wavelet coefÔ¨Åcients are computed with a biorthogonal 1.3 Lee et al. (2019) mother wavelet and
3%thresholding which we only have 15coefÔ¨Åcients to train, out of a total of 512. We compare
accuracy of the NN predictions based on the turbulence diagnostics developed and tested in King
et al. (2018); Mohan et al. (2019). We predict a sequence of Ô¨Çow-Ô¨Åelds from the trained model, and
analyze the Ô¨Çow at = 1:5;3and4:5, which correspond to non-dimensional eddy turnover times.
Analyzing the statistical properties of the predicted Ô¨Çow at varied time instants allows us to assess
the long-term stability of our temporal predictions.
First, we analyze relative signiÔ¨Åcance of different HIT scales conducting the energy spectra test.
Higher wave-numbers in Fig 2a correspond to smaller scales. It is clear from the results that the large
3Published as a conference paper at ICLR 2020
105
103
101
101E(k)=1.5
105
103
101
101E(k)=3
105
103
101
101E(k)=4.5
100101102
Wavenumber K105
103
101
101E(k)Averaged
Neural Network
DNS
k^(-5/3)
(a) Energy Spectra.
105
103
101
p(Z)=1.5
105
103
101
p(Z)=3
105
103
101
p(Z)=4.5
5
 0 5
Z105
103
101
p(Z)Averaged
Neural Network
DNS(b) PDF of velocity gra-
dients.
10
5
0510Q/(Qw) r = 1,=1.5
Q/(Qw) r = 8,=1.5
Q/(Qw) r = 32,=1.5
10
5
0510Q/(Qw) r = 1,=3
Q/(Qw) r = 8,=3
Q/(Qw) r = 32,=3
10
5
0510Q/(Qw) r = 1,=4.5
Q/(Qw) r = 8,=4.5
Q/(Qw) r = 32,=4.5
10
 0 10
R/(Qw)^(3/2)10
5
0510Q/(Qw)Ave r = 1
10
 0 10
R/(Qw)^(3/2)Q/(Qw)Ave r = 8
10
 0 10
R/(Qw)^(3/2)Q/(Qw)Ave r = 32
Neural Network
DNS(c) Q-R plane: isolines of the velocity gradient
invariants coarse-grained at small, r= 1, iner-
tial, r= 8, and large, r= 32 scales.
Figure 2: Wavelet-CLSTM Neural Network Turbulence vs Physical Simulation (DNS)
scale spectra are matched almost exactly, with good reproduction in the intermediate scale range.
Comparatively, small scale spectra are not reproduced well, which is intentional because a signiÔ¨Åcant
portion of small scales were removed (set to zero) during the thresholding. Effects of the small
scale absence is also seen in the Probability Distribution Function (PDF) of the velocity gradient
(Fig 2b), which tests solely the smallest scales of HIT. This is expected, since we are building a
reduced order model for applications where large and inertial scales are of primary interest. The
third test is the Q-R plane diagnostic in Fig 2c, which offers an arguably more stringent test of three-
dimensional structure in turbulence Chertkov et al. (1999); Chong et al. (1990); Elsinga & Marusic
(2010); Suman & Girimaji (2010), as described in the previous section. We observe in Fig. 2c
that the Wavelet-CLSTM reproduces the large scale behavior almost perfectly, while reproduction of
turbulence geometry start to deteriorate as we move down-scales, to intermediate ( r= 8) and small
(r= 1) scales. The small scale behavior is not reproduced due to the 3%thresholding favoring
large scales. The symmetric structure seen in the small scale prediction is likely linked to the noise
added by the model. The bottom graphic ‚ÄúAve‚Äù in Fig. 2c shows the averaged diagnostics for the 3
time instants. Overall, the test results present ample evidence to the fact that due to the physically-
interpretable selection of the wavelet basis, the Wavelet-CLSTM is capable of modeling the large
and inertial scale spatio-temporal dynamics of HIT well. We point out that it is straightforward to
include small scale behavior by including relevant wavelet coefÔ¨Åcients, obviously on the expense of
increase in the computational cost.
5 I MPACT ON CLIMATE RESEARCH AND CONCLUSION
Climate data is extremely high dimensional and necessitates model reduction for timely, efÔ¨Åcient
analysis and insights (Overpeck et al., 2011). Another major application is surrogate modeling
of high-Ô¨Ådelity of geophysical Ô¨Çows (San & Maulik, 2018). We present here the Ô¨Årst results for
the novel Wavelet-CLSTM , which is an efÔ¨Åcient, scalable, high dimensional deep NN framework
for reduced modeling of turbulence, and similar or related multi-scale physical phenomena. The
key strength of the framework is in the combination of a well-developed and mathematically justi-
4Published as a conference paper at ICLR 2020
Ô¨Åed wavelet decomposition with its highly desirable physical model reduction and interpretation
power. Further investigation is desired into intelligent thresholding methods for non-stationary
spatio-temporal climate phenomena. Another major application for Wavelet-CLSTM is for learning
low dimensional dynamics of large climate and observational datasets where the governing equa-
tions are not well known, but where the wavelet coefÔ¨Åcients can be a rigorous approach to identify
and exploit multiscale patterns.
ACKNOWLEDGMENTS
This work has been authored by employees of Triad National Security, LLC which operates Los
Alamos National Laboratory (LANL) under Contract No. 89233218CNA000001 with the U.S. De-
partment of Energy/National Nuclear Security Administration. Authors have been supported by
LANL‚Äôs LDRD program, project number 20190058DR. Author 1 also thanks the Center for Non-
linear Studies at LANL for support and acknowledges the ASC/LANL Darwin cluster for GPU
computing infrastructure.
REFERENCES
Michael Chertkov, Alain Pumir, and Boris I Shraiman. Lagrangian tetrad dynamics and the phe-
nomenology of turbulence. Physics of Ô¨Çuids , 11(8):2394‚Äì2410, 1999.
Min S Chong, Anthony E Perry, and Brian J Cantwell. A general classiÔ¨Åcation of three-dimensional
Ô¨Çow Ô¨Åelds. Physics of Fluids A: Fluid Dynamics , 2(5):765‚Äì777, 1990.
Don Daniel, Daniel Livescu, and Jaiyoung Ryu. Reaction analogy based forcing for incompressible
scalar turbulence. Physical Review Fluids , 3(9):094602, 2018.
GE Elsinga and I Marusic. Universal aspects of small-scale motions in turbulence. Journal of Fluid
Mechanics , 662:514‚Äì539, 2010.
R Everson, L Sirovich, and KR Sreenivasan. Wavelet analysis of the turbulent jet. Physics Letters
A, 145(6-7):314‚Äì322, 1990.
Marie Farge. Wavelet transforms and their applications to turbulence. Annual review of Ô¨Çuid me-
chanics , 24(1):395‚Äì458, 1992.
Marie Farge, Giulio Pellegrino, and Kai Schneider. Coherent vortex extraction in 3d turbulent Ô¨Çows
using orthogonal wavelets. Physical Review Letters , 87(5):054501, 2001.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural infor-
mation processing systems , pp. 2672‚Äì2680, 2014.
Oliver Hennigh. Lat-net: compressing lattice boltzmann Ô¨Çow simulations using deep neural net-
works. arXiv preprint arXiv:1705.09036 , 2017.
Insung Ihm and Sanghun Park. Wavelet-based 3d compression scheme for interactive visualization
of very large volume data. In Computer graphics forum , volume 18, pp. 3‚Äì15. Wiley Online
Library, 1999.
Ryan King, Oliver Hennigh, Arvind Mohan, and Michael Chertkov. From deep to physics-informed
learning of turbulence: Diagnostics. arXiv preprint arXiv:1810.07785 , 2018.
Gregory R Lee, Ralf Gommers, Filip Waselewski, Kai Wohlfahrt, and Aaron O‚ÄôLeary. Pywavelets:
A python package for wavelet analysis. Journal of Open Source Software , 4(36):1237, 2019.
Shaomeng Li, Nicole Marsaglia, Christoph Garth, Jonathan Woodring, John Clyne, and Hank
Childs. Data reduction techniques for simulation, visualization and data analysis. In Computer
Graphics Forum , volume 37, pp. 422‚Äì447. Wiley Online Library, 2018.
D Livescu, J Mohd-Yusof, MR Petersen, and JW Grove. Cfdns: a computer code for direct numerical
simulation of turbulent Ô¨Çows. Los Alamos National Laboratory Technical Report No. LA-CC-09-
100, 2009.
5Published as a conference paper at ICLR 2020
Charles Meneveau. Analysis of turbulence in the orthonormal wavelet representation. Journal of
Fluid Mechanics , 232:469‚Äì520, 1991.
Charles Meneveau and Joseph Katz. Scale-invariance and turbulence models for large-eddy simula-
tion. Annual Review of Fluid Mechanics , 32(1):1‚Äì32, 2000.
Arvind Mohan, Don Daniel, Michael Chertkov, and Daniel Livescu. Compressed convolutional
lstm: An efÔ¨Åcient deep learning framework to model high Ô¨Ådelity 3d turbulence. arXiv preprint
arXiv:1903.00033 , 2019.
Jonathan T Overpeck, Gerald A Meehl, Sandrine Bony, and David R Easterling. Climate data
challenges in the 21st century. science , 331(6018):700‚Äì702, 2011.
Fernando Port ¬¥e-Agel, Charles Meneveau, and Marc B Parlange. A scale-dependent dynamic model
for large-eddy simulation: application to a neutral atmospheric boundary layer. Journal of Fluid
Mechanics , 415:261‚Äì284, 2000.
Jesus Pulido, Daniel Livescu, Jonathan Woodring, James Ahrens, and Bernd Hamann. Survey and
analysis of multiresolution methods for turbulence data. Computers & Fluids , 125:39‚Äì58, 2016.
Flemming Friche Rodler. Wavelet based 3d compression with fast random access for very large
volume data. In Proceedings. Seventh PaciÔ¨Åc Conference on Computer Graphics and Applications
(Cat. No. PR00293) , pp. 108‚Äì117. IEEE, 1999.
Omer San and Romit Maulik. Extreme learning machine for reduced order modeling of turbulent
geophysical Ô¨Çows. Physical Review E , 97(4):042322, 2018.
Kai Schneider, NK-R Kevlahan, and Marie Farge. Comparison of an adaptive wavelet method
and nonlinearly Ô¨Åltered pseudospectral methods for two-dimensional turbulence. Theoretical and
computational Ô¨Çuid dynamics , 9(3-4):191‚Äì206, 1997.
Zhen-Su She and Emmanuel Leveque. Universal scaling laws in fully developed turbulence. Physi-
cal review letters , 72(3):336, 1994.
Sawan Suman and Sharath S Girimaji. Velocity gradient invariants and local Ô¨Çow-Ô¨Åeld topology in
compressible turbulence. Journal of Turbulence , (11):N2, 2010.
Kiwon Um, Xiangyu Hu, and Nils Thuerey. Liquid splash modeling with neural networks. In
Computer Graphics Forum , volume 37, pp. 171‚Äì182. Wiley Online Library, 2018.
Maximilian Werhahn, You Xie, Mengyu Chu, and Nils Thuerey. A multi-pass gan for Ô¨Çuid Ô¨Çow
super-resolution. arXiv preprint arXiv:1906.01689 , 2019.
Steffen Wiewel, Moritz Becher, and Nils Thuerey. Latent space physics: Towards learning the
temporal evolution of Ô¨Çuid Ô¨Çow. In Computer Graphics Forum , volume 38, pp. 71‚Äì82. Wiley
Online Library, 2019.
Jin-Long Wu, Karthik Kashinath, Adrian Albert, Dragos Chirila, Heng Xiao, et al. Enforcing sta-
tistical constraints in generative adversarial networks for modeling chaotic dynamical systems.
arXiv preprint arXiv:1905.06841 , 2019.
You Xie, Erik Franz, Mengyu Chu, and Nils Thuerey. tempogan: A temporally coherent, volumetric
gan for super-resolution Ô¨Çuid Ô¨Çow. ACM Transactions on Graphics (TOG) , 37(4):95, 2018.
SHI Xingjian, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and Wang-chun Woo.
Convolutional lstm network: A machine learning approach for precipitation nowcasting. In Ad-
vances in neural information processing systems , pp. 802‚Äì810, 2015.
6Published as a conference paper at ICLR 2020
(a) Instantaneous turbulent ki-
netic energy
(b) Reynolds number (based on
Taylor microscale)
 (c) Individual velocity variances
Figure 3: Representative Statistics of the Simulation
A 3D H OMOGENEOUS ISOTROPIC TURBULENCE DATASET AND TRAINING
The dataset consists of a 3D Direct Numerical Simulation (DNS) of homogeneous, isotropic tur-
bulence, in a box of size 1283. We denote this dataset as HIT for the remainder of this work. We
provide a brief overview of the simulation and its physics in this section, and a detailed discussion
can be found in Daniel et al. (2018). The ScalarHIT dataset is obtained using the incompressible
version of the CFDNS (Livescu et al., 2009) code, which uses a classical pseudo-spectral algorithm.
We solve the incompressible Navier-Stokes equations:
@xivi= 0; @ tvi+vj@xjvi= 1
@xip+vi+fv
i;
wherefvis a low band forcing, restricted to small wavenumbers k < 1:5[1]. The 1283pseudo-
spectral simulations are dealiased using a combination of phase-shifting and truncation to achieve a
maximum resolved wavenumber of kmax=p
2=312860.
For illustration, Figure 3a shows the turbulent kinetic energy at a time instant. Figure 3b shows
the variation in the Taylor-microscale based Reynolds number with the eddy turnover time, which
characterizes the large turbulence scales. Finally, the variances in all 3velocity components are
shown in Fig. 3c. Based on the sampling rate, each eddy turnover time consists of 33 snapshots.
The training dataset uses 22snapshots0 0:75and test dataset also consists of 22 snapshots in
4 4:75.
B S OME DIAGNOSTIC TESTS OF TURBULENCE
We now brieÔ¨Çy describe 2basic tests of 3D turbulence which are used as ‚Äúdiagnostic‚Äù metrics in
this work, for the accuracy of the Ô¨Çow predicted by the trained model.
B.1 4=5KOLMOGOROV LAW AND THE ENERGY SPECTRA
The main statement of the Kolmogorov theory of turbulence is that asymptotically in the inertial
range, i.e. at Lr, whereLis the largest, so-called energy-containing scale of turbulence
andis the smallest scale of turbulence, so-called Kolmogorov (viscous) scale, F(r)does not
depend onr. Moreover, the so-called 4=5-law states for the third-order moment of the longitudinal
velocity increment
Lr:S(i;j;k )
3rirjrk
r3= 4
5"r; (1)
where"=D(i;j;i;j)
2=2is the kinetic energy dissipation also equal to the energy Ô¨Çux.
Self-similarity hypothesis extended from the third moment to the second moment results in the
expectation that within the inertial range, Lr, the second moment of velocity increment scales
as,S2(r)vL(r=L)2=3. This feature is typically tested by plotting the energy spectra of turbulence
(expressed via S2(r)) in the wave vector domain, e.g. as shown in the results section.
7Published as a conference paper at ICLR 2020
B.2 I NTERMITTENCY OF VELOCITY GRADIENT
Consequently from Eqn. 1, the estimation of the moments of the velocity gradient results in
DnSn()
n: (2)
This relation is strongly affected by intermittency for large values of n(i.e. extreme non-Gaussian
behavior) of turbulence, and is a valuable test of small scale behavior.
B.3 S TATISTICS OF COARSE -GRAINED VELOCITY GRADIENTS :Q RPLANE .
Isolines of probability in the Q Rplane, expressing intimate features of the turbulent Ô¨Çow topology,
has a nontrivial shape documented in the literature. See Ref. (Chertkov et al., 1999) and references
therein. Different parts of the Q Rplane are associated with different structures of the Ô¨Çow.
Thus, lower right corner (negative QandR), which has higher probability than other quadrants,
corresponds to a pancake type of structure (two expanding directions, one contracting) with the
direction of rotation (vorticity) aligned with the second eigenvector of the stress. This tear-drop
shape of the probability isoline becomes more prominent with decrease of the coarse-graining scale.
Here, we study the Q Rplane coarse-grained/Ô¨Åltered at different scales, to account for large scale
(r= 32 ), inertial (r= 8), and small scale ( r= 1) behaviors. This allows us to selectively analyze
the accuracy of our predictions at different scales, since we are interested in modeling primarily the
large and inertial ranges.
8