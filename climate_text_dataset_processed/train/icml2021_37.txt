Attention For Damage Assessment
Tashnim Chowdhury1Maryam Rahnemoonfar1
Abstract
Due to climate change the hurricanes are getting
stronger and having longer impacts. To reduce
the detrimental effects of these hurricanes faster
and accurate assessments of damages are essential
to the rescue teams. Like other computer vision
techniques semantic segmentation can identify the
damages and help in proper and prompt damage
assessment. Current segmentation methods can be
classiﬁed into attention and non-attention based
methods. Existing non-attention based methods
suffers from low accuracy and therefore atten-
tion based methods are becoming popular. Self-
attention based methods can map the mutual re-
lationship and dependencies among pixels of an
image and thus improve semantic segmentation
accuracy. In this paper, we present a self-attention
semantic segmentation method on UA V imageries
to assess the damages inﬂicted by a natural dis-
aster. The proposed method outperforms four
state-of-art segmentation methods both quantita-
tively and qualitatively with a mean IoU score of
84:03%.
1. Introduction
Recently there have been numerous natural disasters which
have brought both personal injuries and economic losses to
several countries all over the world. In 2020 alone USA has
inﬂicted with 22 natural disasters which have cost around
96.4 billions dollars (noa). Current tropical storms are per-
sisting far longer and doing more damage than in the past.
In 2017, USA’ fourth largest city Houston, Texas, was in-
undated when Hurricane Harvey settled over the city for
several days, and was dumped with 127 billion tonnes of
water (Van Oldenborgh et al., 2017). Moisture from warm
and tropical oceans acts as the fuel of the hurricanes that
drives the intense winds. Due to climate change, the air over
1Computer Vision and Remote Sensing Laboratory (Bina
Lab), University of Maryland Baltimore County, Baltimore,
MD, USA. Correspondence to: Maryam Rahnemoonfar
<maryam@umbc.edu >.
Tackling Climate Change with Machine Learning Workshop at
ICML 2021.the oceans can hold more of this moisture and intensify the
storms at sea. Consequently, when these storms reach land,
the hurricanes should decay very quickly due to lack of fuel
from the seas. However, the timescale of decay of the North
Atlantic land-falling hurricanes has almost doubled over
the past 50 years due to climate change (Li & Chakraborty,
2020). According to (Li & Chakraborty, 2020), the slower
decay is fuelled by an increased amount of moisture that is
stocked in the hurricane from its passage over ocean prior
to landfall.
In this scenario, during and even after a natural disaster,
a proper assessment of the damages is imperative which
can facilitate the rescue efforts. Semantic segmentation,
a fundamental task in computer vision, aims at assigning
semantic labels to each pixels of an image. It can assist in
rescue efforts by providing quick and accurate damage as-
sessment. DCNNs (Deep Convolutional Neural Networks)
has gained popularity in semantic segmentation because of
its improved performance compared to traditional computer
vision techniques (Chen et al., 2017; 2018; Paszke et al.,
2016; Zhao et al., 2017). Besides non-disaster scenarios,
the potential of DCNNs are also being utilized by several
researchers (Lopez-Fuentes et al., 2017; Doshi et al., 2018;
Rahnemoonfar et al., 2018; Rudner et al., 2019; Gupta &
Shah, 2020; Gupta et al., 2020; Zhu et al., 2020) in natu-
ral disaster damage assessment. Different DCNN seman-
tic segmentation methods have been proposed including
encoder-decoder and pyramid based methods (Ronneberger
et al., 2015; Zhao et al., 2017; Paszke et al., 2016; Chen
et al., 2018). Besides these methods, self-attention based
methods are showing excellent performance. Self-attention
mechanism captures the spatial dependencies between any
two positions of the feature maps and thus contribute to the
mutual improvement (Fu et al., 2019).
In this work, we implement a self-attention based seman-
tic segmentation method named ReDNetPlus on a natural
disaster dataset FloodNet (Rahnemoonfar et al., 2021). Our
results show that our method performs considerably better
than four other segmentation methods including both atten-
tion and non-attention based methods. This suggests that
our approach is feasible and promising.Attention For Damage Assessment
Figure 1. Illustration of after disaster scenes of FloodNet dataset. First row shows original image and the second row shows the
corresponding annotations.
2. Related Works
2.1. Self Attention Method
State-of-art semantic segmentation methods can be classi-
ﬁed into encoder-decoder based method (Ronneberger et al.,
2015), pyramid pooling based method (Zhao et al., 2017;
Chen et al., 2018), and attention based method (Huang et al.,
2019; Fu et al., 2019). Encoder-decoder based methods like
U-Net adopt local context from middle and lower level fea-
tures through encoder-decoder architecture. These methods
generate sharp object boundaries or small details based on
local context and make high resolution prediction. On the
other hand, pyramid based modules (Zhao et al., 2017; Chen
et al., 2018) create global context using pooling based oper-
ations like global average pooling, pyramid pooling (Zhao
et al., 2017), and atrous convolution (Chen et al., 2018).
These methods generate rich global contextual information
at different resolutions or scales. In computer vision, self-
attention module calculates the context at one position as
weighted sum of all positions in a sentence or an image.
Several self-attention based works (Huang et al., 2019; Fu
et al., 2019; Yuan & Wang, 2018) have been proposed in
computer vision ﬁeld. These approaches use different self-
attention mechanisms to aggregate contextual information
in order to augment feature representation. Authors in (Fu
et al., 2019) propose a position attention module along with
a channel attention module to capture interdependencies
of features among spatial and channels dimension respec-
tively. (Huang et al., 2019) proposes a criss-cross attention
module to gather contextual information in spatial domain.
The work in (Yuan & Wang, 2018) calculates object based
contexts using self-attention based mechanism.2.2. Natural Disaster Damage Assessment
Different research works have attempted to assess the dam-
ages inﬂicted by different natural disasters by implementing
and proposing different deep learning methods. Authors in
(Doshi et al., 2018) perform segmentation on satellite im-
ages to detect maximal damaged areas. Rahnemoonfar et al.
in (Rahnemoonfar et al., 2018) propose a densely connected
recurrent neural network in order to segment UA V images
for ﬂood area detection. Multi3Net is proposed in (Rudner
et al., 2019) for rapid segmentation of ﬂooded buildings
by fusing multiresolution, multisensor, and multitemporal
satellite imageries. RescueNet is proposed by Gupta et al.
in (Gupta & Shah, 2020) for joint building segmentation.
To assess the damages of the buildings a multilevel instance
segmentation method named MSNet is proposed by Zhu et
al.in (Zhu et al., 2020).
In this work, ReDNetPlus is applied on FloodNet (Rah-
nemoonfar et al., 2021) dataset which is a high resolution
UA V dataset collected after hurricane Harvey. Unlike ex-
isting segmentation methods proposed for natural disaster
damage assessment, we perform segmentation not only on
buildings and roads but also on pools, vehicles, trees, and
grass.
3. Dataset
FloodNet (Rahnemoonfar et al., 2021) is collected with
small UA V platform, DJI Mavic Pro quadcopters, after Hur-
ricane Harvey . Hurricane Harvey has made disasterous
impact near Texas and Louisiana on August, 2017, as a
Category 4 hurricane. The FloodNet consists of imagery
taken from several ﬂights conducted between August 30
- September 04, 2017, at Ford Bend County in Texas andAttention For Damage Assessment
                     reshape  and transpose
reshapesoftmax
reshapeCxHxW CxHxWreshapeAB
C
DMatrix Multiplication
Element-wise Sum
Figure 2. The details of the position attention module.
ResNetPosition
Attention
Module
Position
Attention
ModuleSum Fusion
U-Net UpsampleConcatente
Figure 3. Overview of ReDNetPlus. The network consists of two
position attention modules (PAMs) and an U-Net.
other directly impacted areas. All ﬂights were ﬂown at
200 feet AGL, as compared to manned assets which nor-
mally ﬂy at 500 feet AGL or higher. FloodNet has in total
2343 images have been annotated with 9 classes which in-
clude building-ﬂooded, building-non-ﬂooded, road-ﬂooded,
road-non-ﬂooded, water, tree, vehicle, pool, and grass. A
buildings is classiﬁed as ﬂooded when at least one side of
a building is touching the ﬂood water. Although we have
classes created for ﬂooded buildings and roads, to distin-
guish between natural water and ﬂood water, “water” class
has been created which represents any natural water body
like river and lake. For the classiﬁcation task, each image is
classiﬁed either “ﬂooded” or “non-ﬂooded”. If more than
30% area of an image is occupied by ﬂood water then that
area is classiﬁed as ﬂooded, otherwise non-ﬂooded.
4. Method
4.1. Position Attention Module (PAM) and ReDNet
Local receptive ﬁeld is calculated by convolutional opera-
tions. However, lack of global context results in intra-class
inconsistency, and eventually hurts the recognition accuracy
of network models (Fu et al., 2019). We use ResNet-101
(He et al., 2016) as base recognition model. Different stages
of the ResNet-101 has different recognition capabilities.
Smaller receptive ﬁeld of lower stages can encode ﬁne spa-
tial information but semantic consistency is poor. On otherhand, larger receptive ﬁeld of higher stages is able to main-
tain good semantic consistency but results in poor encoding
of spatial information (Yu et al., 2018). Keeping this in
mind, a self-attention network which combines feature ex-
traction from both lower and higher stages of ResNet-101 is
implemented.
The self-attention block is a position attention module
(PAM) which creates global context over local features.
Two position attention modules use two different feature
maps of ResNet-101 (layer 2 and layer 3), and generate
two self-attention maps which are rich in global contextual
information. Position attention module is shown in Figure 2.
Given a local feature map Awith dimension CHW,
three new feature maps are generated using a convolution
layer with similar shape. Matrix multiplication is performed
on transpose of BandC. Then using a softmax layer spatial
attention map Sis calculated using the following formula.
sji=exp(BiCj)PN
i=1exp(BiCj)(1)
Then matrix multiplication is performed between transpose
ofSandD. The output from the matrix multiplication is
multiplied with . Finally element-wise sum is performed
with feature Ato generate ﬁnal output with shape CH
W. This architecture is coined as ReDNet (a ResNet (He
et al., 2016) based Dual attention Network).
4.2. ReDNetPlus
The two position attention modules are generated using the
methodology discussed in section 4.1. These two modules
are placed in parallel and their attention maps are added to-
gether using element-wise sum operation which constitutes
ReDNet architecture.
The ReDNetPlus segmentation network implements a
smaller U-Net (Ronneberger et al., 2015) along with ReD-
Net. The output from the U-Net is added to the output from
the sum of two position attention maps and ﬁnally passed
through a fully connected layer. The output of fully con-
nected layer generates the segmentation map of the input
image.
The visual interpretation of the ReDNetPlus network is
shown in Figure 3. The ﬁnal self-attention map generated
from two PAMs contains global contextual information. On
the other hand, the U-Net generates local context map and
later is added to the global context map generated from the
self-attention modules.
5. Experiments
PyTorch has been used for implementation of segmentation
network. As hardware we use NVIDIA GeForce RTX 2080Attention For Damage Assessment
Figure 4. Visual comparison of PSPNet, Attention U-Net, and ReDNetPlus on FloodNet test set.
Table 1. Per-class intersection over union (in %) and their mean value (mIoU) on FloodNet testing set.
Method Building FloodedBuilding Non
FloodedRoad FloodedRoad Non
FloodedWater Tree Vehicle Pool Grass mIoU
ENet(Paszke et al., 2016) 21.82 41.41 14.76 52.53 47.14 62.56 26.21 16.57 75.57 39.84
DeepLabv3+(Chen et al., 2018) 28.10 78.10 32.00 81.10 73.00 74.50 33.60 40.00 87.10 58.61
PSPNet(Zhao et al., 2017) 65.61 90.92 78.69 90.90 91.25 89.17 54.83 66.37 95.45 80.35
Attention U-Net (Oktay et al., 2018) 64.82 86.14 28.20 92.35 77.74 90.95 54.20 71.82 95.29 73.50
ReDNetPlus 80.99 91.76 88.90 91.90 95.56 91.20 48.68 70.90 96.39 84.03
Ti GPU and Intel Core i9 CPU. We use “poly” learning rate
with base learning rate 0.001. Momentum, weight decay,
and power are set to 0.9, 0.0001, and 0.9 respectively. For
augmentation we use random shufﬂing, scaling, ﬂipping,
and random rotation which help models to avoid overﬁtting.
During training, we resize the images to 713 713 since
large crop size is useful for the high resolution images. For
semantic segmentation we use mean IoU (Intersection over
Union) as evaluation metric.
6. Results And Discussion
Table 1 shows the performance evaluation of the ReDNet-
Plus compared to other state-of-art methods on FloodNet
dataset (Rahnemoonfar et al., 2021). The result includes
comparison with both non-attention based methods such
as ENet (Paszke et al., 2016), DeepLabv3+ (Chen et al.,
2018), and PSPNet (Zhao et al., 2017), and attention based
method such as Attention U-Net (Oktay et al., 2018). Non
attention based methods perform worse than attention based
methods except in class “vehicle”. In class “vehicle” PSP-
Net performs best among all methods. Attention U-Net
shows improved performance in all classes specially in seg-
menting small objects. Although Attention U-Net showsbetter performance than PSPNet in most of the cases, due to
its lower performance in class “Road Flooded”, its overall
performance is lower than PSPNet by 6:85%.
ReDNetPlus combines self-attention based global feature
map with local feature map produced by U-Net. Al-
though this method does not present superior performance
in smaller object classes, it provides excellent performance
in other classes which includes bigger and ﬂooded objects.
ReDNetPlus shows superior performance with Mean IoU
84:03% outperforming Attention U-Net by 10:53% and
PSPNet by 3:68%.
Qualitative results are shown in Figure 4. In this ﬁgure sam-
ples of evaluated segmentation from top three performing
methods (PSPNet, Attention U-Net, ReDNetPlus) are pre-
sented. It can be seen that segmentation results from these
three methods are very close to the original ground truths.
7. Conclusion
Climate change is highly associated with stronger and more
dangerous hurricanes. Current research works are imple-
menting deep learning based computer vision techniques
to assess the damages after any natural disaster. Fast andAttention For Damage Assessment
accurate assessment is instrumental in this scenario to re-
duce the detrimental impacts. In this work we implement a
self-attention based semantic segmentation method named
ReDNetPlus on a natural disaster dataset called FloodNet.
We compare the method with state-of-art non-attention and
attention based methods. The result indicates that ReD-
NetPlus performs superior than other methods. From the
experiments it is evident that combining attention map pro-
duced using lower level feature maps, and local context map
produced using U-Net can signiﬁcantly improve the segmen-
tation of ﬂooded objects. The achieved higher accuracy in
damage assessment indicates promising application of deep
learning techniques in reducing harmful impacts of climate
change.
References
Noaa national centers for environmental information (ncei).
u.s. billion-dollar weather and climate disasters. https:
//www.ncdc.noaa.gov/billions/events .
Accessed: 2021-05-25.
Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., and
Yuille, A. L. Deeplab: Semantic image segmentation with
deep convolutional nets, atrous convolution, and fully
connected crfs. IEEE transactions on pattern analysis
and machine intelligence , 40(4):834–848, 2017.
Chen, L.-C., Zhu, Y ., Papandreou, G., Schroff, F., and Adam,
H. Encoder-decoder with atrous separable convolution
for semantic image segmentation. In Proceedings of the
European conference on computer vision (ECCV) , pp.
801–818, 2018.
Doshi, J., Basu, S., and Pang, G. From satellite imagery to
disaster insights. arXiv preprint arXiv:1812.07033 , 2018.
Fu, J., Liu, J., Tian, H., Li, Y ., Bao, Y ., Fang, Z., and Lu,
H. Dual attention network for scene segmentation. In
Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition , pp. 3146–3154, 2019.
Gupta, A., Watson, S., and Yin, H. Deep learning-based
aerial image segmentation with open data for disaster
impact assessment. arXiv preprint arXiv:2006.05575 ,
2020.
Gupta, R. and Shah, M. Rescuenet: Joint building segmenta-
tion and damage assessment from satellite imagery. arXiv
preprint arXiv:2004.07312 , 2020.
He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learn-
ing for image recognition. In Proceedings of the IEEE
conference on computer vision and pattern recognition ,
pp. 770–778, 2016.Huang, Z., Wang, X., Huang, L., Huang, C., Wei, Y ., and
Liu, W. Ccnet: Criss-cross attention for semantic seg-
mentation. In Proceedings of the IEEE International
Conference on Computer Vision , pp. 603–612, 2019.
Li, L. and Chakraborty, P. Slower decay of landfalling
hurricanes in a warming world. Nature , 587(7833):230–
234, 2020.
Lopez-Fuentes, L., Rossi, C., and Skinnemoen, H. River
segmentation for ﬂood monitoring. In 2017 IEEE Inter-
national Conference on Big Data (Big Data) , pp. 3746–
3749. IEEE, 2017.
Oktay, O., Schlemper, J., Folgoc, L. L., Lee, M., Heinrich,
M., Misawa, K., Mori, K., McDonagh, S., Hammerla,
N. Y ., Kainz, B., et al. Attention u-net: Learning where to
look for the pancreas. arXiv preprint arXiv:1804.03999 ,
2018.
Paszke, A., Chaurasia, A., Kim, S., and Culurciello, E. Enet:
A deep neural network architecture for real-time semantic
segmentation. arXiv preprint arXiv:1606.02147 , 2016.
Rahnemoonfar, M., Murphy, R., Miquel, M. V ., Dobbs, D.,
and Adams, A. Flooded area detection from uav images
based on densely connected recurrent neural networks. In
IGARSS 2018-2018 IEEE International Geoscience and
Remote Sensing Symposium , pp. 1788–1791. IEEE, 2018.
Rahnemoonfar, M., Chowdhury, T., Sarkar, A., Varshney,
D., Yari, M., and Murphy, R. Floodnet: A high resolution
aerial imagery dataset for post ﬂood scene understanding.
IEEE Access , 2021.
Ronneberger, O., Fischer, P., and Brox, T. U-net: Convolu-
tional networks for biomedical image segmentation. In In-
ternational Conference on Medical image computing and
computer-assisted intervention , pp. 234–241. Springer,
2015.
Rudner, T. G., Rußwurm, M., Fil, J., Pelich, R., Bischke, B.,
Kopa ˇckov ´a, V ., and Bili ´nski, P. Multi3net: segmenting
ﬂooded buildings via fusion of multiresolution, multisen-
sor, and multitemporal satellite imagery. In Proceedings
of the AAAI Conference on Artiﬁcial Intelligence , vol-
ume 33, pp. 702–709, 2019.
Van Oldenborgh, G. J., Van Der Wiel, K., Sebastian, A.,
Singh, R., Arrighi, J., Otto, F., Haustein, K., Li, S., Vec-
chi, G., and Cullen, H. Attribution of extreme rainfall
from hurricane harvey, august 2017. Environmental Re-
search Letters , 12(12):124009, 2017.
Yu, C., Wang, J., Peng, C., Gao, C., Yu, G., and Sang, N.
Learning a discriminative feature network for semantic
segmentation. In Proceedings of the IEEE conference on
computer vision and pattern recognition , pp. 1857–1866,
2018.Attention For Damage Assessment
Yuan, Y . and Wang, J. Ocnet: Object context network for
scene parsing. arXiv preprint arXiv:1809.00916 , 2018.
Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. Pyramid scene
parsing network. In Proceedings of the IEEE conference
on computer vision and pattern recognition , pp. 2881–
2890, 2017.
Zhu, X., Liang, J., and Hauptmann, A. Msnet: A mul-
tilevel instance segmentation network for natural disas-
ter damage assessment in aerial videos. arXiv preprint
arXiv:2006.16479 , 2020.