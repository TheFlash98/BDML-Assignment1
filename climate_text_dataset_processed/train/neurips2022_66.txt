A Global Classification Model for Cities using ML
Doron Hazan Mohamed Habashy Mohanned ElKholy Omer Mousa
MIT MIT MIT American University in Cairo
doronh@mit.edu Habashy@mit.edu Mohanned@mit.edu omermousa@aucegypt.edu
Norhan Bayomi Matias Williams John Fernandez
MIT MIT MIT
nourhan@mit.edu Mwill88@mit.edu fernande@mit.edu
Abstract
This paper develops a novel data set for three key resources use; namely, food, 1
water, and energy, for 9000 cities globally. The data set is then utilized to develop 2
a clustering approach as a starting point towards a global classification model. 3
This novel clustering approach aims to contribute to developing an inclusive view 4
of resource efficiency for all urban centers globally. The proposed clustering 5
algorithm is comprised of three steps: first, outlier detection to address specific city 6
characteristics, then a Variational Autoencoder (V AE), and finally, Agglomerative 7
Clustering (AC) to improve the classification results. Our results show that this 8
approach is more robust and yields better results in creating delimited clusters with 9
high Calinski-Harabasz Index scores and Silhouette Coefficient than other baseline 10
clustering methods. 11
1 Introduction 12
Cities are both the drivers of climate change and the major component of the solution. Yet, many 13
cities are lacking direction toward a climate-positive and sustainable future. The latest IPCC report 14
has underlined the role of international climate networks between urban centers [ 1], [2] such as city 15
networks. The main limitation to achieving efficient city networks is that many cities are relatively 16
small and lack the resources to know what solution set is most appropriate for them and how to 17
connect to other cities to share their stories and journey toward sustainability. This is problematic 18
as smaller cities face different barriers from their global counterparts [ 3], and these cities are likely 19
to define urbanization’s future, especially in the Global South [ 4]. This paper directly addresses 20
this dichotomy by using machine learning to develop a global classification approach for cities 21
into various profiles based on quantitative characteristics that can enhance the understanding of 22
urbanization pathways. 23
Related Work: Most cities’ classification studies have mostly focused on hierarchical data-driven 24
methods and do not move beyond comparing a limited number of cities with territorial similarities or 25
development levels [ 5]. To our knowledge, a clustering approach for cities worldwide has not been 26
fully explored in the literature to date. Such global classification has been challenging due to the lack 27
of available data on a global scale. Thus, this paper develops a novel data set and a broad definition 28
of city boundaries to develop a clustering approach for 9000 cities worldwide. The work presented in 29
this paper is divided into two key components. First, the development of global prediction models for 30
resource use (energy, water, food) for 9000 cities globally to fulfill the current gap in data needs to 31
achieve inclusive clustering of cities. Second, a novel clustering approach that performs better than 32
Submitted to Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022.baseline clustering and identifies possible city networks that can aid in the global climate change 33
discussion needs and resource efficiency opportunities. 34
2 Data and Methods 35
2.0.1 Data 36
In this paper, we developed a machine learning approach to predict energy, water, and food consump- 37
tion for a total of 9,000 cities around the world. This data - for a comprehensive 9000 cities around 38
the world - simply does not exist. Thus, we collected resource data for a subset of cities around 39
the world and processed each dataset to construct our predictive models. For further information 40
regarding the data, methods, and evaluations, refer to appendices A, B. Figure 2 portrays our decision 41
flow process with picking the best resource estimation model. 42
2.0.2 Methods 43
Energy Consumption Model : To generate a comprehensive energy estimation model, we used city 44
light radiance as a proxy. We found that city light radiance captured in satellite images approximates 45
well the energy consumption of cities, so we employed a city light radiance proportion model that 46
estimates the consumption of a specific city based on the city’s light radiance percentage of the whole 47
country multiplied by the country’s population proportion and total energy consumption following 48
previous work in [ 6], [7], [8] using equation 1. Our model selection analysis is presented in appendix 49
A.2 50
Ecapita/city
i =Lcity
i
Lcountry
j×Pcountry
j
Pcity
i∗Ecapita/country
j (1)
Licorresponds to light radiance, Pito population, Eito energy, and Ejto National Average Energy 51
consumption for country jthat includes city i. 52
Water Consumption Model : To remedy the lack of observational data for water consumption, we 53
limited our model search space to models that work well with little data. Inspired by Fan et al. [ 9], we 54
performed feature selection to pick a subset of features that first, accurately depict water consumption, 55
second, are generalizable enough to be used for 9,000 cities. For example, the number of washing 56
machines per household was used in [ 9], but could not be used for 9,000 cities simply because it is 57
unavailable for this large set of cities. The model that was picked to estimate water consumption was 58
Extremely Randomized Trees (ERT) [ 10], which is similar to other tree based ensemble algorithms 59
such as random forests, but was found to perform and generalize better. The ERT model incorporated 60
total population, land area (from [ 11]), precipitation (from [ 12]), temperature (from [ 13]), and water 61
price (from [ 14]) which corresponded to our two aforementioned conditions. For further information 62
refer to appendix A.3. 63
Food Consumption Model : Findings from the literature indicated that the city’s food consumption 64
is highly correlated with population. These findings prompted us to develop a population proportion 65
model to estimate food consumption following the same approach in [ 8]. We define food consumption 66
as the average daily consumption of calories. The population proportion output is then used to 67
estimate food consumption via linear regression as seen in equation 2. For further information, refer 68
to appendix A.4. 69
Fcapita/city
i =ˆβ0+ˆβ1(Pcity
i
Pcountry
j×Fcountry
j ) +ϵi (2)
PiandFicorrespond to population and food consumption, respectively. β’s are regression coefficients 70
andϵiis the error for city i.FjandPjcorrespond to food consumption and population for country j 71
that includes city i 72
22.0.3 Initial Results and Evaluation 73
The predictions of our models correspond to an estimation of energy, water, and food consumption 74
across 9,000 cities around the world. These predictions form a novel dataset that leverages the power 75
of machine learning research. To quantify the performance of each model (i.e. our new dataset), 76
we used three benchmarks: standard regression metrics (MAPE and R2on the out of sample set), 77
statistical characteristics (e.g. comparing mean, median, etc. between the original data and the 78
predicted data), and a Ratio Score metric B.3 which we have developed specifically for this task. 79
Table 1 presents the results for MAPE, R2, and Ratio Score benchmarks used to compare the ground 80
truth dataset and the predicted set, evaluated on the test set. Our comprehensive benchmark on the 81
new dataset and models’ performance is described in appendix B. We discuss he limitations of our 82
predictions in B.4. 83
Table 1: Evaluation of the predicted dataset on the out of sample test set
Dataset/Predictions Benchmark
Resource/Metric MAPE R2Ratio Score
Energy 67.7% 0.77 89.5%
Water 13% 0.63 20.3%
Food 22.5% 0.71 30.2%
2.0.4 Clustering 84
The second step is to use outputs from the resource use prediction models to develop the global 85
classification. Here, we developed the clustering approach over three key components: 1) outlier 86
detection (OD), 2) encoding with Variational AutoEncoders (V AE) [ 15], and 3) agglomerative 87
clustering [ 16]. The intuition behind using an outlier detector is that some variables like population 88
and area obey Zipf’s Law [ 17], where there is an exponential increase in the values of the variables 89
for major cities per country. Therefore, through the outlier detector, we exclude the highest x% 90
(xis determined empirically) of the data in the attributes of interest. This step has allowed us to 91
separate the data into an outlier and a non-outlier group based on the attributes we want. Next, we 92
apply a V AE based transformation [ 15] before applying the clustering algorithm. Training a V AE 93
as a pre-processing step makes it possible to perform a non-linear transformation that encodes the 94
data into a finer, more separated, and denoised representation. We train the V AE until convergence 95
to reconstruct the input data using KL-Divergence and Mean Square error objectives, then use the 96
encoder part to transform the data (to the V AE latent space). We use the Adam optimizer [ 18] with a 97
learning rate of 0.001 for training. For the clustering algorithm, we try the standard AC and other 98
standard clustering methods, which are included in appendix C. 99
3 Initial Clustering Results 100
To assess the performance of the proposed approach, clusters are evaluated using the Calinski- 101
Harabasz Index (CHI) [ 19] and the Silhouette Coefficient (SC) [ 20]. These are standard ways of 102
evaluating clustering as they measure how dispersed/close the points in the clusters are to each other. 103
CHI is unbounded while SC ranges from -1 to 1. Scores for our method with V AE, and without V AE 104
(namely "Direct Clustering") are shown in Table 2. 105
Table 2: Evaluation of different combination of clustering. The higher score the better.
Clustering Algorithm Performance
Metric/Algorithm AC only OD+AC OD+V AE+AC
Calinski-Harabasz Index 4345.80 2546.07 42495.66
Silhouette Coefficient 0.45 0.17 0.47
As the table demonstrates the results of the approaches, the V AE + OD + AC (extracting outliers, 106
passing them to V AE and clustering them) produced the highest score for CHI ( ∼9.7 times more than 107
3just using AC). Thus, our analysis suggests that our novel, three fold clustering method performs 108
better classification on our novel dataset than baseline clustering. For visualization and interpretability, 109
we use spider plots to visualize the per-cluster mean of the attributes. This makes it easier to interpret 110
the attributes that the clusters were divided based on. Figure 1 shows three example clusters in the 111
outlier group. For instance, cluster two includes cities at the top 500 range in food consumption 112
and medium range in water use, like Oklahoma (US), Nashville (US), Columbus (US), Buenos 113
Aires (ARG), and London (UK). Many cities of this cluster are already working together to address 114
climate change under the C40. Each city has drafted plans according to their needs; however, why 115
couldn’t they write plans together when they have similar needs? This is one way our proposed global 116
clustering approach can help cities address their climate challenges. 117
Figure 1: Spider plots for the three example clusters in the outliers group
4 Conclusion 118
The proposed global clustering approach for cities using ML techniques has two practical implications. 119
First, it will provide space for a comprehensive assessment of cities globally and help identify the 120
aggregate contribution of urban areas to global climate challenges. Second, global clustering of cities 121
will allow the comparison between cities with similar features and derive pathways for sustainable 122
urban growth, resource efficiency, and climate change challenges. The data presented in this paper 123
are novel and unique as they are fulfilling gaps in data scarcity for the majority of cities globally that 124
limits the opportunities for resource efficiency and sustainable urban growth. This assessment for 125
resource use in all cities globally has not been done before, and we believe it will pave the way for a 126
better understanding of opportunities for resource efficiency globally and aid better policy design. 127
The goal for future work is the investigation and identification of ‘track shifting’ mechanisms and 128
policy interventions that could facilitate urban sustainability. 129
References 130
[1]Michele Acuto and Benjamin Leffel. Understanding the global ecosystem of city networks. Urban Studies , 131
58(9):1758–1774, 2021. 132
[2]Harriet Bulkeley, Michele M Betsill, Daniel Compagnon, Thomas Hale, Matthew J Hoffmann, Peter 133
Newell, and Matthew Paterson. Transnational governance: charting new directions post-paris, 2018. 134
[3]Jeroen Van der Heijden. Cities and sub-national governance: High ambitions, innovative instruments and 135
polycentric collaborations. 2018. 136
[4]UN Desa. Revision of world urbanization prospects. UN Department of Economic and Social Affairs , 16, 137
2018. 138
[5]Jennifer Robinson. Cities in a world of cities: The comparative gesture. International journal of urban 139
and regional research , 35(1):1–23, 2011. 140
[6]Christopher D Elvidge, Kimberly E Baugh, Sharolyn J Anderson, Paul C Sutton, and Tilottama Ghosh. 141
The night light development index (nldi): a spatially explicit measure of human development from satellite 142
data. Social Geography , 7(1):23–35, 2012. 143
[7]Hongwei Xiao, Zhongyu Ma, Zhifu Mi, John Kelsey, Jiali Zheng, Weihua Yin, and Min Yan. Spatio- 144
temporal simulation of energy consumption in china’s provinces based on satellite night-time light data. 145
Applied Energy , 231:1070–1078, 2018. 146
4[8]Isabel M Horta and James Keirstead. Downscaling aggregate urban metabolism accounts to local districts. 147
Journal of Industrial Ecology , 21(2):294–306, 2017. 148
[9]Liangxin Fan, Lingtong Gai, Yan Tong, and Ruihua Li. Urban water consumption and its influencing 149
factors in china: Evidence from 286 cities. Journal of Cleaner Production , 166:124–133, 2017. 150
[10] Pierre Geurts, Damien Ernst, and Louis Wehenkel. Extremely randomized trees. Machine learning , 151
63(1):3–42, 2006. 152
[11] M Schiavina, A Moreno-Monroy, L Maffenini, and P Veneri. Ghsl-oecd functional urban areas. Technical 153
report, JRC Technical Report, 2019. 154
[12] Amy McNally et al. Fldas noah land surface model l4 global monthly 0.1 ×0.1 degree (merra-2 and chirps). 155
Atmos. Compos. Water Energy Cycles Clim. Var , 2018. 156
[13] Zhengming Wan, Simon Hook, and Glynn Hulley. Mod11a2 modis/terra land surface tempera- 157
ture/emissivity 8-day l3 global 1km sin grid v006. Nasa Eosdis Land Processes Daac , 10(10.5067), 158
2015. 159
[14] M Adamovic. Methodology and motivation for numbeo. numbeo. Inc., Belgrade, Serbia (www. numbeo. 160
com) , 2021. 161
[15] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 , 162
2013. 163
[16] Daniel Müllner. Modern hierarchical, agglomerative clustering algorithms. arXiv preprint arXiv:1109.2378 , 164
2011. 165
[17] Sidra Arshad, Shougeng Hu, and Badar Nadeem Ashraf. Zipf’s law and city size distribution: A survey of 166
the literature and future research agenda. Physica A: Statistical mechanics and its applications , 492:75–92, 167
2018. 168
[18] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint 169
arXiv:1412.6980 , 2014. 170
[19] Tadeusz Calinski. A dendrite method for cluster analysis. Communication in statistics , 3:1–27, 1974. 171
[20] Peter J Rousseeuw. Silhouettes: a graphical aid to the interpretation and validation of cluster analysis. 172
Journal of computational and applied mathematics , 20:53–65, 1987. 173
[21] Artessa Niccola D Saldivar-Sali. A global typology of cities: Classification tree analysis of urban resource 174
consumption . PhD thesis, Massachusetts Institute of Technology, 2010. 175
[22] RI McDonald. City water map (version 2.2). Knowledge Network for Biocomplexity , 2016. 176
[23] Euromonitor International. Passport consumers. https://www.euromonitor.com/ , 2015. 177
[24] Richard G Newell, Yifei Qian, and Daniel Raimi. Global energy outlook 2015. Technical report, national 178
bureau of economic research, 2016. 179
[25] Alina Zaharia, Maria Claudia Diaconeasa, Laura Brad, Georgiana-Raluca L ˘adaru, and Corina Ioan ˘as,. Fac- 180
tors influencing energy consumption in the context of sustainable development. Sustainability , 11(15):4147, 181
2019. 182
[26] Husi Letu, Masanao Hara, Hiroshi Yagi, Kazuhiro Naoki, Gegen Tana, Fumihiko Nishio, and Okada 183
Shuhei. Estimating energy consumption from night-time dmps/ols imagery after correcting for saturation 184
effects. International journal of remote sensing , 31(16):4443–4458, 2010. 185
[27] Paul Guinness and Brenda Walpole. Environmental systems and societies for the IB diploma coursebook . 186
Cambridge University Press, 2015. 187
[28] Lenka Slavíková, Vít ˇezslav Mal `y, Michael Rost, Lubomír Petružela, and Ond ˇrej V ojá ˇcek. Impacts of 188
climate variables on residential water consumption in the czech republic. Water Resources Management , 189
27(2):365–379, 2013. 190
[29] Rosa Duarte, Vicente Pinilla, and Ana Serrano. Is there an environmental kuznets curve for water use? a 191
panel smooth transition regression approach. Economic Modelling , 31:518–527, 2013. 192
[30] Geoffrey J Syme, Quanxi Shao, Murni Po, and Eddy Campbell. Predicting and understanding home garden 193
water use. Landscape and Urban Planning , 68(1):121–128, 2004. 194
[31] Kirsten Davies, Corinna Doolan, Robin Van Den Honert, and Rose Shi. Water-saving impacts of smart 195
meter technology: An empirical 5 year, whole-of-community study in sydney, australia. Water Resources 196
Research , 50(9):7348–7358, 2014. 197
[32] Bradley Jorgensen, Michelle Graymore, and Kevin O’Toole. Household water use behavior: An integrated 198
model. Journal of environmental management , 91(1):227–236, 2009. 199
[33] Dianne Neumark-Sztainer, Mary Story, Cheryl Perry, and Mary Anne Casey. Factors influencing food 200
choices of adolescents: findings from focus-group discussions with adolescents. Journal of the American 201
dietetic association , 99(8):929–937, 1999. 202
5[34] Jan-Benedict EM Steenkamp. Food consumption behavior. ACR European Advances , 1993. 203
[35] Molly C Bernhard, Peng Li, David B Allison, and Julia M Gohlke. Warm ambient temperature decreases 204
food intake in a simulated office setting: a pilot randomized controlled trial. Frontiers in nutrition , 2:20, 205
2015. 206
[36] The Global Economy. Economic data. https://www.theglobaleconomy.com/ , 2022. 207
[37] X Jin and J Han. K-medoids clustering, encyclopedia of machine learning, 2010. 208
[38] Todd K Moon. The expectation-maximization algorithm. IEEE Signal processing magazine , 13(6):47–60, 209
1996. 210
[39] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning 211
research , 9(11), 2008. 212
6Appendix A Data and Model Selection 213
A.1 Data 214
In this paper, we developed a machine learning approach to predict energy, water, and food consump- 215
tion for a total of 9,000 cities around the world. That resulted in three models, each specialized in 216
predicting one resource component using particular sets of features. We adopted a novel approach 217
that relied on different data sources like city night light radiance from satellite images, population, 218
land area, and others, and we used these variables as a proxy to estimate energy, water, and food 219
consumption models. For each model, we experimented and expanded on similar work that was done 220
before in literature, such as choosing variables, using ML models and proportion (non ML) models, 221
and evaluated them using the benchmarks we designed. 222
Figure 2: Model & feature selection decision flow
Previous energy, food, and water consumption data per city - for a comprehensive 9000 cities around 223
the world - simply does not exist. Thus, we collected resource data for a subset of cities around the 224
world and processed each dataset to construct our predictive models. We used [ 21] to obtain energy 225
use values for 155 cities, and [ 22] to obtain water use for 172 cities. For food, we used [ 23]. Since 226
the data and context varied greatly between the three resources, we treated each case separately and 227
designed our predictive models accordingly. 228
A.2 Energy 229
Data: Countries report their energy consumption values each year [ 24]. However, little information 230
is reported on the city-level, especially for the units outside the OECD region. We used a random 231
sample of 157cities [ 21] that included the average electricity use per capita in kWh for the year of 232
2012 . 233
Feature Selection and Prepossessing: There are many variables that intuitively correlate with 234
energy consumption such as the available income resources and the location of the city. Horta and 235
Keirstea [ 8] attempted downscaling the energy consumption from the country to city-level before, 236
but they performed their analysis on London and near-London cities only. Yet, they mentioned 237
several approaches to tackle this challenge such as fitting population-proportion or regression models. 238
We gathered information based on the literature of what affects the energy consumption, and we 239
found out that population, GDP per capita, green house gas emissions, and temperature, [ 25] were 240
the biggest four indicators of energy consumption [ 6], [7]. Therefore, we tried to gather as much 241
information on these variables as possible in one universal dataset to perform our analysis. The list of 242
the final variables included: population, population density, area, percentage of area covered by water, 243
percentage of area covered by land, average temperature, city-light radiance, and some vegetation 244
indices. Our methodology was to look for variables that are available for the 9000 cities, so we can 245
generalize our findings. 246
The selection criteria for these variables are based on the following steps 247
1.Try different statistical feature selection methods (namely, forward selection, backward 248
selection, and best subset), manually look for features that are consistently top performing 249
across different those feature selection ways, pick them as our best subset. 250
2.Out of this best subset of features, pick those who can be used for 9000 cities (i.e. if we 251
have a value for each city in our city list of 9000 cities). 252
7Model Selection: Inspired by the work done in [ 8], we replicated the proposed methods; namely 253
a linear regression with population model, and a multivariate regression with population and area. 254
We benchmarked them with a proportion model we designed using city-light radiance based on a 255
previous study by Letu et al[ 26]. We created that model by estimating the proportion of the city light 256
radiance of the city to its entire country then multiplied by the total consumption for the country. This 257
method estimated energy consumption values for an entire city. Moreover, we wanted to replicate 258
this approach on the capita-level to see if our assumptions hold. 259
Chosen Model: City-Light Proportion per capita As tables 3, 4 suggest, the city-light proportion 260
model performed better than the regression ones on the city-scale and the capita-scale across all our 261
statistical metrics presented in B.1. Tables 3, 4 portray our results. The scores are the average of the 262
metric on 10 different random test sets, and each evaluation on one test set was done via 10-cross 263
validation 264
Table 3: Model Performance evaluated on a test set on energy consumption per capita
Model Benchmark Energy per Capita
Model/Metric MAPE R2Ratio Score
Linear Regression with city light and land 193.8% 0.07 234%
Linear Regression with population and land 212% 0.05 264.8%
Population Proportion Model 67.7% 0.77 89.5%
Table 4: Model Performance evaluated on a test set on energy consumption per city
Model Benchmark Energy City-Level
Model/Metric MAPE R2Ratio Score
Linear Regression with city light and land 58.9% 0.73 89.7%
Linear Regression with land and population 99.9% 0.03 634.5%
Population Proportion Model 67.7% 0.52 89.5%
A note on the results: While the results we obtained for energy consumption are not relative high 265
(compared to food and water), they are consistent. Our proportion model suggests a linear correlation 266
between our estimation and the ground truth value, albeit a relatively high error rate (MAPE, ratio 267
score). The main challenge was energy consumption was the very little data points we had (157 data 268
points), which restricted our use of more advanced ML. 269
A.3 Water 270
Data: Since water consumption data per city for a broad range such as 9000 is not available, we used 271
Urban Household Water Consumption Data [ 22], which provided water consumption data (liters per 272
capita per day) for years 2014 and 2015. The data corresponded to 289 data points, of which 119 273
were for 2014 and 170 for 2016. Out of all 289 data points, there were 172 unique cities. 274
Feature Selection and Prepossessing: Previous studies have suggested various drivers of water 275
consumption. Domestic water use is highly complex and diverse because it can be affected by many 276
factors. For example, one view is that water consumption is highly affected by population: with 277
increasing city population, global water consumption in cities has increased by approximately six-fold, 278
which was twice the rate of population growth [ 27]. Other views are climate and meteorology [ 28], 279
socio-demographic profiles [ 29], household characteristics [ 30], water availability and conservation 280
[31], and pricing and policies [ 32]. To determine the right subset of features for our water consumption 281
model, we generated a comprehensive dataset by combining the water consumption data we had 282
with the Euromonitor data [ 23], which provided us with 62 different features, which span across 283
domains such as socioeconomic, meteorological factors, water supply, etc. The water consumption 284
data we used and Euromonitor data did not align perfectly (i.e. some cities were in one dataset but 285
not the other, and vice versa), thus we had to eliminate cities with no information. The finalized 286
dataset included 172 datapoints across 62 features. To our understanding, using proportion models to 287
8estimate water consumption was not supported in the literature review, thus we focused on machine 288
learning models. 289
Our feature selection process included two steps: 290
1.Try different statistical feature selection methods (e.g. Recursive Feature Elimination with 291
random forest regressor), manually look for features that are consistently top performing 292
across different those feature selection ways, pick them as our best subset. 293
2.Out of this best subset of features, pick those who can be used for 9000 cities (i.e. if we 294
have a value for each city in our city list of 9000 cities) 295
Our methodology is summarized as following: after trying different types of feature selection 296
processes (namely, wrapper: Recursive Feature Elimination with different types of estimators, 297
embedded: lasso regression) we picked a subset that consisted of precipitation, GDP per capita, death 298
rate, land area, population growth, water price, temperature, birth rates, Consumer Price Index, total 299
population. 300
Among those, we selected only those which we have information for 9000 cities. For example, death 301
rates was consistently found to be a strong predictor for water consumption, but many cities around 302
the world do not provide that data. Our finalized subset of features included precipitation (2015), 303
land temperature (two meters above the ground, for 2015), land area (2015), total population (2015), 304
and water price (in retail stores, a value that was similar between cities within the same country). 305
This dataset was normalized, since city values, naturally, have a wide range. Outliers in these 306
scenarios are meaningful and thus were not excluded. The water consumption distribution was right 307
skewed as shown in figure 3, thus the models were evaluated on a log scale of the water consumption. 308
Figure 3: Water Consumption Distribution. The vertical red line shows the mean, which is 165.36
Model Selection: Post picking the best subset of features to estimate water consumption, we tried 309
numerous machine learning models. The main challenge was the lack of data (total 172 points), 310
which had two consequences: first, it disabled us from using large deep learning models that are data 311
hungry. Second, it forced us to focus on a search space of "simple" (classical ML) models with low 312
variance (better generalization), even at the expense of high bias (error). We split the data into train 313
9(80%) and test (20%). We trained the various models on the train data and evaluated it on the test 314
data using k cross validation where k = 10. Since we dealt with so little data, we wanted to control 315
for the case that a random selection of cities for the train and test split does affect the performance 316
(i.e. it may be the chance that a specific random split generated great performance while a different 317
random one did not). To control for that, we evaluated each model on 10 different data splits (i.e. 318
changing the seed number). The results are presented in table 5. We used a baseline model for each 319
model we tested. 320
Table 5: Model Performance evaluated on a test set. The scores are the average of the metric on 10
different random test sets, and each evaluation on one test set was done via 10-cross validation
Model Benchmark Water
Model/Metric MAPE R2Ratio Score
Linear Regression 26.5% 0.257 38%
Ridge regression 26.5% 0.255 38%
K Nearest Neighbors 20.3% 0.409 27.8%
Support Vector Machines (linear) 25.8% 0.259 43.6%
Support Vector Machines (polynomial) 58% 0.26 35.4%
Support Vector Machines (radial) 19.4% 0.497 25.7%
Decision Trees 28.4% 0.133 25.7%
Random Forest 15.3% 0.589 19.7%
Extremely Randomized Trees 13.6% 0.625 20.3%
Extreme Gradient Boosting 14.8% 0.542 21.9%
Multi-layered Perceptron 30.8% 0.274 37.1%
Chosen Model: Extremely Randomized Trees (ERT): Unlike random forests, ERT’s use the 321
same training set for training all trees and split a node based on both variable index and variable 322
splitting value, while random forests only splits by variable value. This makes ERTs both more 323
computationally efficient and generalizable than random forests - which is crucial in our setting since 324
we predict 9,000 values using solely 172 data points. 325
A.4 Food 326
Data: To estimate the food consumption for the 9000 cities, we used Euronmonitor International 327
data [ 23]. It has information on 1220 cities worldwide, which seemed to be an adequate sample to 328
investigate. The information is available for many years, for consistency sake, we used values for 329
2015. 330
Feature Selection and Prepossessing: We relied heavily on the literature to identify which factors 331
influence food behaviors. Some studies [ 33][34] revealed that economic, social, and physical factors 332
are the major determinant of food consumption for individuals. Another study also pointed out the 333
location and temperature affects people’s appetite. [ 35]. Thus, we tried looking for data that include 334
information on these variables at Euromonitor and Global Economy [ 36]. Some elements on the 335
list included: housing expenditure, communication expenditure, health-related expenditure, average 336
household number, birth rate, inflation, and growth rate. The feature selection method for food was 337
similar to energy and food: we checked the statistical significance of the the variables we had in our 338
dataset and looked for highest performing set of variables. Additionally, we picked the subset of 339
features that can be applied to the 9000 cities. 340
Model Selection: Since the food model was developed simultaneously with the water model, we 341
first attempted to take similar regression and proportion strategies. We tried regression models and 342
proportion models based on our energy estimations and city light as described in the energy section A. 343
The regression model results were relatively satisfying. However, we wanted a more robust approach 344
to food. We relied heavily on refining our definition of food consumption. Do we think of it as the 345
expenditure on food and/or food supplies? Intake of protein? Intake of fats? Intake of calories? We 346
decided to define food consumption as the average daily consumption of calories. 347
10Chosen Model: Population Proportion per capita We constructed several models using data from 348
the Global Economy [ 36] employing each definition of food consumption, and the best one that had 349
the highest R-squared, lowest MAPE, and lowest score in ratio test was the population proportion 350
model of average intake of calories as shown in these results presented in tables 6, 7. The scores are 351
the average of the metric on 10 different random test sets, and each evaluation on one test set was 352
done via 10-cross validation 353
Table 6: Model Performance evaluated on a test set for food consumption per capita
Model Benchmark Food per Capita
Model/Metric MAPE R2Ratio Score
Linear Regression with population 44.1% 0.06 63.8%
Linear Regression with population and land 44% 0.062 61.6%
Population Proportion Model 26.5% 0.681 31%
Linear Regression Population Proportion Model 22.5% 0.711 30.2%
Table 7: Model Performance evaluated on a test set for food consumption per city
Model Benchmark Food City-Level
Model/Metric MAPE R2Ratio Score
Linear Regression with population 51.3% 0.55 131.9%
Linear Regression with population and land 79% 0.67 138.5%
Population Proportion Model 26.5% 0.95 31%
11Appendix B Evaluation Criteria for the novel Resource Dataset 354
The predictions of energy, water, and food consumption of 9000 cities enabled constructing a novel 355
data set that entails resource consumption of cities on a global scale. Since this data is new, we 356
wanted to benchmark it through three different approaches: standard regression metrics (MAPE and 357
R2on the out of sample set), statistical characteristics (comparing mean, median, range, variance 358
between the original data and the predicted data), and a Ratio Score metric 1 which we have developed 359
specifically for this task. 360
Out of these three evaluation metrics, standard regression metrics and Ratio Score are presented in 361
table 1. 362
B.1 Standard Regression Metrics 363
We evaluate our model across all counties in the test year with data. We use two standard regression 364
metrics: MAPE and R2. 365
MAPE (Mean Absolute Percentage Error) is commonly used as a loss function for regression problems 366
and in model evaluation, and it has a very intuitive interpretation in terms of relative error, which is 367
why we chose it over other similar metrics such as RMSE and MAE which are less intuitive. It is the 368
sum of the individual absolute errors divided by the true values: 369
MAPE =1
NX
i∈T|yi−pi|
yi
Where Nis total number for cities in the test set T,yiis the true value for city iandpiis the predicted 370
value for city i. 371
R2is a measure of how much the variation in the data can be explained by the model predictions. 372
Formally, 373
R2= 1−P
i∈T(yi−pi)2
P
i∈T(yi−y)2
where yis the average value across the entire test set T. The top of the fraction corresponds to the 374
sum of the squared residuals (RSS: difference between true yield and model prediction). The bottom 375
is the total sum of squares (TSS: the difference between the true value and the average value across 376
the test set), which is proportional to the overall variance of the test set. 377
B.2 Statistical Characteristics Benchmark 378
The statistical characteristics of the original data we possessed and our novel data is presented in 379
table 8. We observe that the mean and median are similar, but the range and standard deviation is 380
wider in the original dataset. We believe this happens because the models were trained on very few 381
data points, while making predictions for a many more data points. This motivates the importance of 382
picking the right predictive model based on how well it generalizes on the out of sample data set. 383
B.3 Ratio Score Metric 384
The Ratio Score metric we have developed was created to depict how well each predictive model 385
captures the ratio between resource consumption of cities. Table 9 shows an example that was made 386
to show the Ratio Score between two cities for reference. When we used Ratio Score to evaluate our 387
models, we used the average Ratio Score on the out of sample dataset. We define a good Ratio Score 388
to be below 30%. Ratio Score metric is presented in algorithm 1. In words, the Ratio Score Metric 389
for city icalculates the true and predicted ratio between city iin the test set and all the other cities 390
12Table 8: Data set benchmark via statistical characteristics.
Data Set Benchmark
Measurement/Dataset Original Data Our Novel Predicted Data
Mean (Energy) 3014.533 3075.545
Mean (Water) 165.36 166.08
Mean (Food) 10406618 11267953
Median (Energy) 1582.5 2328.9
Median (Water) 148 160.91
Median (Food) 9011173 9954047
Min (Energy) 158 197.5
Min (Water) 71 96.47
Min (Food) 2758824 4198104
Max (Energy) 26790 23657.35
Max (Water) 538.0 326.57
Max (Food) 34192000 29303875
sd (Energy) 3642.505 3294.618
sd (Water) 71.27 31.18
sd (Food) 5621284 4723401
(numbered 1...N, if the test set includes Ncities) in that set except for city i. Then, it calculates the 391
MAPE between the true and the predicted Ratio Scores, and averages through all cities. 392
Table 9: Ratio Score for water consumption between two cities. The MAPE is calculated by
|true−predicted |
true, for example|171−188.92|
171= 10 .48%. Ratio is calculated by dividing the values
between cities, for example, true ratio here is171
220= 0.78
Data Set Benchmark
City/Value True Value Predicted
ValueMAPE True Ratio Predicted Ratio
Geneva (Switzerland) 171 188.92 10.48%0.78 0.77Tokyo (Japan) 220 244.93 11.33%
Algorithm 1: Ratio Score
1T={y1, ...yN}: true testing data
2P={y1, ...yN}: predictions on testing data
3R= 0: Ratio Score
4Initialize Ri
true: a vector of length N−1
5Initialize Ri
prediction : a vector of length N−1
6forcity name i∈ T do
7 forcity name j∈ T, j̸=ido
8 Compute Ri
true= (Ti
Tj)∀j∈ T, j̸=i
9 Compute Ri
prediction = (Pi
Pj)∀j∈ P, j̸=i
10 end
11 Compute Ri
error =|Ri
true−Ri
predicted |
Ri
true
12 Update R=R+Ri
error
13end
14Return R
B.4 Limitations: 393
Each model has its limitations based on the dataset available. The energy model doesn’t accurately 394
represent super-mega cities like Texas, NY , and LA since the light radiance doesn’t go beyond a 395
specific point. That is, a city will use more energy, but it is bright enough that more consumption 396
13doesn’t get captured in the satellite images. For water, since we worked with very few data points 397
(172 total, 138 used for training), we need to make sure the distribution of cities is generalizable 398
enough; namely, it represents a comprehensive set of countries and cities to match (or at least be 399
close to) the 9000 cities we used to predict. This, unfortunately, is not under our control since water 400
consumption data is very scarce. Regarding food, the consumption of calories doesn’t capture the 401
individual variations of the type of consumed food, i.e. healthy or junk. We assume that the only 402
variation in the city consumption is their population and the food sources available. 403
14Appendix C Clustering 404
We experimented other standard clustering techniques such as: K-Means algorithm (KM) [ 37] and 405
Gaussian Mixture Models (EM) [ 38] and compared the results of the combination with the Outlier 406
Detection (OD) and Variational Autoencoders (V AE) and reported the results, seen in table 10. As 407
seen in the paper, our proposed three-fold clustering of (1) outlier detection (2) V AE (3) agglomerative 408
clustering performs best, both in terms of CHI and SC. Figure 4 shows the spatial distribution for 1100 409
cities identified in the outliers group over five clusters. It can be noted that the outliers group mostly 410
included major cities in the developed North, parts of the United States, West-Northern Europe, and 411
major cities in Asia. 412
Table 10: Silhouette Coefficient outputs and Calinski-Harabasz Index for the tested methods
Calinski-Harabasz Index Silhouette Coefficient
Algorithm/Method with V AE Direct Clustering with V AE Direct Clustering
K Means 39851.71 5031.95 0.315 0.368
Agglomerative 42495.66 4345.80 0.466 0.452
Gaussian Mixture 8190.34 1312.97 0.206 0.0252
Figure 4: Spatial distribution of the outliers group
Figure 5: Spider plots for the five main clusters in the outliers group
15Figure 6: t-SNE using AC
Figure 7: t-SNE using OD+V AE+AC
In addition, we provided t-SNE [ 39] plots to visually analyze the performance of the clustering 413
algorithms we tested. t-SNE is a visualizing algorithm that visualizes multi-dimensional data by 414
projecting them to a 2D space. This is the 2D representation of the t-SNE algorithm. As shown 415
in figures 7, 6 and aligned with our quantitative metrics (Calinski-Harabasz Index and Silhouette 416
Coefficien), V AE clustering has much clearer, and more separable clusters, suggesting it performs 417
better than an alternative, baseline clustering approach. 418
16