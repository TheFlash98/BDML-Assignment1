Being the Fire A CNN-Based Reinforcement Learning
Method to Learn How Fires Behave Beyond the
Limits of Physics-Based Empirical Models
William L. Ross
Department of Earth, Energy, and Environmental Sciences
Stanford University
Stanford, CA 94305
wlross@stanford.edu
Abstract
Wildland Ô¨Åres pose an increasing threat in light of anthropogenic climate change. 1
Fire-spread models play an underpinning role in many areas of research across this 2
domain, from emergency evacuation to insurance analysis. We study paths towards 3
advancing such models through deep reinforcement learning. Aggregating 21 Ô¨Åre 4
perimeters from the Western United States in 2017, we construct 11-layer raster 5
images representing the state of the Ô¨Åre area. A convolution neural network based 6
agent is trained ofÔ¨Çine on one million sub-images to create a generalizable baseline 7
for predicting the best action - burn or not burn - given the then-current state on 8
a particular Ô¨Åre edge. A series of online, TD(0) Monte Carlo Q-Learning based 9
improvements are made with Ô¨Ånal evaluation conducted on a subset of holdout Ô¨Åre 10
perimeters. We examine the performance of the learned agent/model against the 11
FARSITE Ô¨Åre-spread model. We also make available a novel data set and propose 12
more informative evaluation metrics for future progress. 13
1 Introduction 14
The performance of Ô¨Åre-spread models, which aim to predict the spatial spreading process of an active 15
Ô¨Åre across a given area, is important to protecting our communities from wildÔ¨Åre. Most contemporary 16
Ô¨Åre spread models can be traced back to a single 1972 paper ‚Äì A Mathematical Model for Predicting 17
Fire Spread in Wildland Fuels ‚Äì authored by Richard Rothermel [1]. While Wells (2008) points out 18
that the Rothermel Model‚Äôs empirical, physically-informed approach is "still running like a champ", 19
many experts recognize that the model is now being asked to do things it was never meant to do [2]. 20
The last decade has seen marked progress in the Ô¨Åelds of deep learning and reinforcement learning 21
and has spurred a new era for machine learning and artiÔ¨Åcial intelligence [3,4]. In the Ô¨Åeld of 22
deep learning, convolutional neural networks exhibit unique predictive ability in image recognition 23
tasks, including those that use remote sensing [5,6]. Deep reinforcement learning, meanwhile, has 24
demonstrated the ability to solve complex optimization problems dynamically and over time in the 25
presence of uncertainty [7]. 26
Combining these techniques, there is initial evidence to suggest that deep reinforcement learning can 27
be used to learn wildÔ¨Åre dynamic models from historic observations and remote sensing data. We 28
extend the work of Subramanian and Crowley ‚Äì Using Spatial RL to Build Forest WildÔ¨Åre Dynamics 29
Models From Satellite Images ‚Äì in hopes of unifying the latest remote sensing data, machine learning 30
algorithms, and physical techniques to advance Ô¨Åre spread modeling [8]. 31
Tackling Climate Change with Machine Learning: workshop at NeurIPS 2021.2 Review of Literature 32
2.1 Fire-Spread Modeling and Prediction 33
The vast majority of today‚Äôs Ô¨Åre-spread models represent small changes to individual characteristics 34
within the framework provided by Rothermel. Models such as FARSITE and BehavePlus are 35
widely adopted in commercial and government work today but typically focus on improving select 36
parameters, with incremental progress in each new generation [9,10]. But the reality in the words of 37
Rothermel pupil Brett Butler, is that "(these models describe) very well a Ô¨Åre burning in a Ô¨Åeld of 38
wheat. As you get further away from that uniformity, the less accurate (they) become [11]." 39
Among the most meaningful areas of such progress has been the improvement of topographic wind 40
speed modeling. Because most wildÔ¨Åres do not burn in a Ô¨Åeld of wheat, understanding how wind 41
changes speed in complex topography is important to assessing speed and direction of Ô¨Åre spread. 42
Wagenbrenner et al. (2016) make use of physical conservation of mass and momentum to downscale 43
surface wind predictions or measurements in complex terrains [12]. While such solvers are intended to 44
improve the Rothermel framework, they yield equally useful inputs for machine learned approaches. 45
2.2 Machine Learning and Remote Sensing in Fire-Spread Models 46
The science of remote sensing has advanced as the resolution, coverage, and frequency of such data 47
improves [13]. Government funded projects such as Landsat 8 (2013) and Sentinel 1-A/B (2014-16) 48
provide high resolution (20-30m) data at a consistent frequency [14,15]. Private companies such as 49
Planet provide further coverage through projects like RapidEye (5m) and Planetscope (3m), both of 50
which provide data from much of the planet on a daily frequency or better. 51
Such data has opened the door for the use of machine learning in various applications in widlÔ¨Åre. For 52
example, Zhang et al. (2011) provide a hybrid model that makes use of satellite imagery and is now 53
used in the Canadian Forest Fire Weather Index (FWI) [16]. The use of sequential models in the form 54
of markov decision processes (MDP) offers another path forward particularly relevant to Ô¨Åre-spread 55
models. In Subramanian and Crowley (2019), a number of methods including Q-Learning, monte 56
carlo tree search, and deep reinforcement learning are identiÔ¨Åed as promising opportunities. 57
3 Problem Formulation/Methods 58
We evaluate the spread of wildÔ¨Åre in a grid-based 30m resolution environment on the USGS Con- 59
tiguous Albers Equal Area Conic coordinate reference system as an MDP S,A,P,R. Our continuous 60
state space, S, represents the then-current state of a given cell on the Ô¨Åre edge as represented by an 61
11x3x3 raster of that cell and all adjacent cells. 10 layers represent constants over the observation 62
period and 1 layer represents the dynamic condition of where the Ô¨Åre has or has not spread at a given 63
time step T. Our binary action space, A, is a simple burn, not burn choice for each unburned grid 64
cell on the Ô¨Åre edge at each time step. Our transition probability Pis represented as a convolutional 65
neural network (CNN) and estimates the likelihood that a burn or not burn action will maximize our 66
reward R- the negative binary cross-entropy loss of the CNN at each time step. 67
All code and data used for model/agent training and analysis are publicly available for reuse: github. 68
com/wlross/Being_The_Fire_Final . 69
3.1 Data Acquisition and Processing 70
Critical to this approach is the state space as represented by historical data from each Ô¨Åre perimeter. A 71
total of 42 Ô¨Åre perimeters representing a T=0 and T=Final perimeter for each of 21 Ô¨Åres (see Appendix 72
A) from the 2017 wildÔ¨Åre season in the Western United States were collected via GeoMAC [17]. 73
Fires were manually curated to ensure consistent measurement methodologies and a geographical, 74
topographical, and fuel load distribution consistent with the full set of 7418 GeoMAC perimeters 75
from the 2017 Ô¨Åre season. 76
For each Ô¨Åre boundary, a bounding-box representing the edges at T=Final was created and gridded 77
into 30m cells. For each grid point, 10 data characteristics were gathered from several sources 78
including: Planet 5m Resolution RapidEye Program - Red (1), Green (2), Blue (3), Red Edge (4), and 79
2Near Infrared (5) Imagery, US Geological Survey - 30m Resolution Topography, National Weather 80
Service - Average Wind Speed and Direction (7,8) and Maximum Wind Speed and Direction (9,10) 81
[18,19,20]. All values were imputed to the Ô¨Ånal 30m resolution grid using mean or nearest neighbor 82
approaches as appropriate. 83
3.2 Training and Evaluation 84
In order to train our agent, two distinct phases of model training were used. The initial ofÔ¨Çine training 85
approach was introduced to increase the generalizability of the online model. The ofÔ¨Çine environment 86
was also used for experimentation and hyper-parameter tuning as detailed in Appendix B. The model 87
architecture used in both ofÔ¨Çine and online training is visualized as follows: 88
Figure 1: Model architecture for convolutional neural network and TD(0) Monte Carlo Q-Learning
For online training, weights from ofÔ¨Çine training were transferred and additional training was 89
conducted using a TD(0) Monte Carlo Q-Learning algorithm. The reinforcement learning aspect of 90
this approach was consistent with the work of Subramanian and Crowley with the primary difference 91
being the CNN representation of the agent and the use of more, higher resolution data layers. 92
Results for Ô¨Ånal evaluation were generated using the trained agent on the four holdout Ô¨Åres. In 93
parallel, the FlamMap 6 package was used to generate benchmark data via the FARSITE model using 94
default parameters and landscape Ô¨Åles available via the LANDFIRE program [21]. 95
4 Analysis of Results 96
4.1 Quantitative Model Performance 97
Quantitative model performance was measured using the Weighted Average F-1 Score as the primary 98
metric, recognizing that accuracy measures may overstate performance of "under-burn" or "over- 99
burn" models depending on the denominator used. For this research, all grid squares within the 100
bounding box that were not already ignited at T=0 were used for analysis in order to fairly weight both 101
"under-burn" and "over-burn" behaviors. Results were not compared to Subramanian and Crowley 102
as the accuracy metrics presented did not provide a reasonable means for direct comparison and 103
reproducing this work was challenging. 104
Table 1: Reinforcement Learning (RL) and FARSITE (FS) Model Performance
Reinforcement Learning FARSITE Benchmark
Fire Name Precision Recall F-1 Precision Recall F-1
Buck .82 .78 .74 .64 .45 .44
Highline .77 .69 .59 .62 .43 .39
Pinal .84 .84 .81 .84 .20 .08
Sulfur .78 .72 .64 .79 .73 .74
Weighted average 0s and 1s in t=0 unburned sample area
3The RL-Model outperformed the FARSITE model on 3/4 test Ô¨Åres, though both had low F-1 scores. 105
In general, this was due to "under-burn" by the RL Model (low class 1 recall) and "over-burn" by 106
the FARSITE model (low class 0 recall). Both methods performed similarly on class 0 precision but 107
the RL model signiÔ¨Åcantly outperformed the FARSITE model on class 1 precision, providing some 108
evidence of a better "Ô¨Åt" by the RL model. 109
4.2 Qualitative Model Performance 110
Given the relatively low F-1 scores exhibited by both the RL and FARSITE model, a smoothing func- 111
tion was applied to the Ô¨Åre perimeter so that the Ô¨Ånal Ô¨Åre boundaries could be inspected qualitatively. 112
This is consistent with expected use in the Ô¨Åeld - see Appendix C. 113
In both cases, models appeared to be performing in ways consistent with our understanding of 114
physical Ô¨Åre spread - burn was driven by wind direction, slope, and vegetation and obstructed by 115
roads, rivers, and lakes. A visual inspection of the Ô¨Åre spread patterns provides some indication of 116
superior performance by the RL model. For instance, the Ô¨Åre road present in the Highline Ô¨Åre and the 117
river present in the Pinal both seem to have inÔ¨Çuenced a closer Ô¨Åt to the ground truth data for the RL 118
model when compared to FARSITE, which crossed these boundaries easily - see Figure 2. 119
Figure 2: RL + FARSITE Models of Highline and Pinal Fires from Test Set
5 Discussion 120
The reality of Ô¨Åre spread models is that they are attempting to model highly stochastic physical 121
processes. But given such models serve as a critical building block for climate adaptation to wildland 122
Ô¨Åres, progress is important. When compared to existing methods like FARSITE, the results of this 123
work support continued exploration of deep reinforcement learning approaches in this domain. 124
The CNN-based RL methods proposed in this paper have the advantage of tailwinds in both machine 125
learning research and remote sensing data availability. One challenge to progress, however, is the 126
availability of remote sensing data at high resolution and high frequency. Notably, these dependencies 127
are often also present (and sometimes less obvious) when working with physical models. 128
Another source of challenge in this direction is the lack of standardization. Metrics like accuracy that 129
have been previously reported lack sufÔ¨Åcient context for determining model performance. The use 130
of metrics like the weighted average F-1 score, which factors in both "under-burn" and "over-burn", 131
alongside qualitative assessments provide an opportunity to establish new benchmarks. 132
It is clear that reinforcement learning methods for Ô¨Åre-spread modeling are not without their chal- 133
lenges. Still, this work demonstrates the potential for learned methods to, over time, add value to 134
progress in Ô¨Åre-spread modeling. 135
4References 136
[1] Rothermel, Richard C. A mathematical model for predicting Ô¨Åre spread in wildland fuels. V ol. 115. 137
Intermountain Forest Range Experiment Station, Forest Service, US Department of Agriculture, 1972. 138
[2] Wells, Gail. "The Rothermel Fire-Spread Model: still running like a champ." (2008). 139
[3] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. "Deep learning." nature 521.7553 (2015): 436-444. 140
[4] Watkins, Christopher JCH, and Peter Dayan. "Q-learning." Machine learning 8.3-4 (1992): 279-292. 141
[5] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classiÔ¨Åcation with deep convolutional 142
neural networks." Advances in neural information processing systems 25 (2012): 1097-1105. 143
[6] Zhang, Wei, Ping Tang, and Lijun Zhao. "Remote sensing image scene classiÔ¨Åcation using CNN-CapsNet." 144
Remote Sensing 11.5 (2019): 494. 145
[7] Mnih, V olodymyr, et al. "Playing atari with deep reinforcement learning." arXiv preprint arXiv:1312.5602 146
(2013). 147
[8] Subramanian, Sriram Ganapathi, and Mark Crowley. "Learning forest wildÔ¨Åre dynamics from satellite 148
images using reinforcement learning." Conference on reinforcement learning and decision making. Ann Arbor 149
MI, 2017. 150
[9] Finney, Mark A. FARSITE, Fire Area Simulator‚Äìmodel development and evaluation. No. 4. US Department 151
of Agriculture, Forest Service, Rocky Mountain Research Station, 1998. 152
[10] Andrews, Patricia L. "BehavePlus Ô¨Åre modeling system: past, present, and future." In: Proceedings of 7th 153
Symposium on Fire and Forest Meteorology; 23-25 October 2007, Bar Harbor, Maine. Boston, MA: American 154
Meteorological Society. 13 p.. 2007. 155
[11] Gabbert, Bill. "Throwback Thursday: The origin of the model for predicting the spread of wildland Ô¨Åres." 156
In: WildÔ¨Åre Today, June 2018. 157
[12] Wagenbrenner, Natalie S., et al. "Downscaling surface wind predictions from numerical weather prediction 158
models in complex terrain with WindNinja." Atmospheric Chemistry and Physics 16.8 (2016): 5229-5241. 159
[13] Sandau, Rainer, and Klaus Brie√ü. "Potential for advancements in remote sensing using small satellites." 160
The International Archives of the (2008). 161
[14] Williams, Darrel L., Samuel Goward, and Terry Arvidson. "Landsat." Photogrammetric Engineering 162
Remote Sensing 72.10 (2006): 1171-1178. 163
[15] Torres, Ramon, et al. "GMES Sentinel-1 mission." Remote Sensing of Environment 120 (2012): 9-24. 164
[16] Zhang, Jia-Hua, et al. "Detection, emission estimation and risk prediction of forest Ô¨Åres in China using 165
satellite sensors and simulation models in the past three decades‚ÄîAn overview." International journal of 166
environmental research and public health 8.8 (2011): 3156-3178. 167
[17] Walters, Sandra P., Norma J. Schneider, and John D. Guthrie. "Geospatial Multi-Agency Coordination 168
(GeoMAC) Wildland Fire Perimeters, 2008." US Geological Survey Data Series 612.6 (2011). 169
[18] Marta, Santa. "Planet Imagery Product SpeciÔ¨Åcations." Planet Labs: San Francisco, CA, USA (2018): 91. 170
[19] Gesch, Dean, et al. "The national elevation dataset." Photogrammetric engineering and remote sensing 68.1 171
(2002): 5-32. 172
[20] Glahn, Harry R., and David P. Ruth. "The new digital forecast database of the National Weather Service." 173
Bulletin of the American Meteorological Society 84.2 (2003): 195-202. 174
[21] Rollins, Matthew G. "LANDFIRE: a nationally consistent vegetation, wildland Ô¨Åre, and fuel assessment." 175
International Journal of Wildland Fire 18.3 (2009): 235-249. 176
5Appendix A - Sample of 21 Fires from 2017 Western US Fire Season 177
Train Fires
Powerline - ID - Jul Cove - CA - Jul Oak - CA - Aug
Swiss Helms - AZ - Jun Steele - CA - Jul Indian Ridge - ID - Sep
Creek - CA - Dec Preacher - NV - Jul Cub Creek - MT - Sep
Saddle - AZ - Jun Little Hogback - MT - Aug Mammoth Cave - ID - Aug
Gutzler - CO - Jul North Pelican - OR - Aug Helena - CA - Oct
Sheep - AZ - Jul Nena Springs - OR - Au
Test Fires
Pinal - AZ - May
Highline - AZ - June
Sulfur - CA - Oct
Buck - CA - Sept
Appendix B - Details around model hyper parameters for training 178
The neural network‚Äôs input was a 3x3 cell array with 11 bands. The Ô¨Årst convolutional layer creates 32 Ô¨Ålters of 179
the 3x3x11 with a kernel size of 2x2 and the second convolutional layer creates an additional 64 2x2 Ô¨Ålters. The 180
third layer is fully connected with 64 neurons followed by a dropout layer of .4. The fourth layer consists of 128 181
fully connected neurons followed by a dropout layer of .2. The Ô¨Åfth, sixth, and seventh/output layers are fully 182
connected with 64, 32, and 1 neurons respectively. The ReLU activation function is used for all layers with the 183
exception of the binary output, which uses a sigmoid function. Binary cross-entropy loss is used with the adam 184
optimizer in both the ofÔ¨Çine and online setting with epochs, batch size, learning rates ( ), and class weights 185
speciÔ¨Åed below. 186
For ofÔ¨Çine training, a random sample of one million 3x3x11 images was assembled across all Ô¨Åres. The eleventh 187
band of data representing the then-current state of the Ô¨Åre was substitute with random noise. The model was 188
trained over 300 epochs with a batch size of 40, and a learning rate of =1e-5. Class weights of 1 (no burn) and 189
4 (burn) to account for the uneven distribution of the randomly generated dataset and to maximize recall of the 190
burned area. This approach was thought to be advantaged when moved to the online environment. 191
The agent/model made burn or no burn decisions for each cell and the Ô¨Åre edge over a number of iterations 192
equal to 1.7 times the maximum wind speed. This Ô¨Åxed parameter was determined via an independent linear 193
regression of the number of cells burned in a Ô¨Åxed period as a function of the maximum wind speed of the Ô¨Åre, 194
regardless of directional change. For each online session, predictions were initiated as random ( =1) and allowed 195
to become increasingly -greedy with an exponential decay function where =.75 for each iterative model/agent 196
update. 197
Model/agent updates were performed online after every 10,000 predictions/decisions. The model was trained at 198
each iteration over 80 epochs with a batch size of 400 and a learning rate of =1e-3. Class weights of 1 (no 199
burn) and 2.3 (burn) were used as these values were inversely proportional to their respective frequencies in a 200
random sample of the online training data. 201
6Appendix C - Example of gridded vs smooth RL output 202
Figure 3: Raw vs Smooothed RL Model Prediction for Buck Fire
Appendix D - Example of RL vs FARSITE on RapidEye imagery 203
Figure 4: Imagery of site of Sulfur Fire via RapidEye program with RL and FARSITE predictions
7